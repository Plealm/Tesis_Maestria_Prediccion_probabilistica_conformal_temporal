{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7966bbd6",
   "metadata": {},
   "source": [
    "# Analisis Simulacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86610207",
   "metadata": {},
   "source": [
    "## Analisis General - Simulación Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc245af6",
   "metadata": {},
   "source": [
    "### Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378a602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tabla Comparativa de Modelos (Basada en MEDIA) ---\n",
      "             Modelo  General     ARMA     ARIMA    SETAR Mejor_Escenario\n",
      "Block Bootstrapping 4.275512 0.947365 11.251901 0.627270           SETAR\n",
      "    Sieve Bootstrap 0.570491 0.547725  0.547481 0.616268           ARIMA\n",
      "               LSPM 0.845497 0.811287  1.064804 0.660398           SETAR\n",
      "              LSPMW 1.572319 0.960743  3.079645 0.676570           SETAR\n",
      "              AREPD 3.880255 0.936671 10.031183 0.672910           SETAR\n",
      "               MCPS 1.562693 0.759453  3.231805 0.696822           SETAR\n",
      "            AV-MCPS 1.588747 0.740911  3.341841 0.683490           SETAR\n",
      "             DeepAR 1.836024 0.568693  4.329124 0.610255            ARMA\n",
      "         EnCQR-LSTM 2.454851 0.843920  5.850490 0.670144           SETAR\n",
      "\n",
      "--- Tabla Comparativa de Modelos (Basada en MEDIANA) ---\n",
      "             Modelo  General     ARMA    ARIMA    SETAR Mejor_Escenario\n",
      "Block Bootstrapping 0.989417 0.653853 5.275960 0.540499           SETAR\n",
      "    Sieve Bootstrap 0.504848 0.483753 0.487997 0.535568            ARMA\n",
      "               LSPM 0.617954 0.617367 0.813400 0.551614           SETAR\n",
      "              LSPMW 0.803709 0.671465 1.666194 0.559561           SETAR\n",
      "              AREPD 0.987714 0.650945 4.398461 0.566293           SETAR\n",
      "               MCPS 0.682918 0.620742 1.251044 0.596578           SETAR\n",
      "            AV-MCPS 0.674426 0.604950 1.243175 0.587368           SETAR\n",
      "             DeepAR 0.579363 0.510069 1.029325 0.531675            ARMA\n",
      "         EnCQR-LSTM 0.932454 0.637626 3.123052 0.559208           SETAR\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Leer los archivos\n",
    "arma_df = pd.read_excel(\"./datos/Simulacion/Base/resultados_140_ARMA_FINAL.xlsx\")\n",
    "arima_df = pd.read_excel(\"./datos/Simulacion/Base/resultados_140_ARIMA_FINAL.xlsx\")\n",
    "setar_df = pd.read_excel(\"./datos/Simulacion/Base/resultados_140_SETAR_FINAL.xlsx\")\n",
    "\n",
    "# 2. Asignar la columna ESCENARIO a cada dataframe\n",
    "arma_df['ESCENARIO'] = \"Lineal Estacionario\"\n",
    "arima_df['ESCENARIO'] = \"Lineal No estacionario\"\n",
    "setar_df['ESCENARIO'] = \"No lineal Estacionario\"\n",
    "\n",
    "# 3. Juntarlos uno bajo el otro (Concatenar)\n",
    "df_total = pd.concat([arma_df, arima_df, setar_df], ignore_index=True)\n",
    "\n",
    "# Seleccionar solo las columnas requeridas\n",
    "columnas_deseadas = [\n",
    "    \"Paso\", \"Config\", \"Dist\", \"Var\", \"Block Bootstrapping\", \n",
    "    \"Sieve Bootstrap\", \"LSPM\", \"LSPMW\", \"AREPD\", \"MCPS\", \n",
    "    \"AV-MCPS\", \"DeepAR\", \"EnCQR-LSTM\", \"ESCENARIO\"\n",
    "]\n",
    "df_total = df_total[columnas_deseadas]\n",
    "\n",
    "# Definimos cuáles son las columnas que representan a los modelos predictivos\n",
    "modelos = [\n",
    "    \"Block Bootstrapping\", \"Sieve Bootstrap\", \"LSPM\", \"LSPMW\", \n",
    "    \"AREPD\", \"MCPS\", \"AV-MCPS\", \"DeepAR\", \"EnCQR-LSTM\"\n",
    "]\n",
    "\n",
    "# 4. Guardar el dataframe consolidado\n",
    "df_total.to_excel(\"./datos/Simulacion/Base/dataframe_consolidado.xlsx\", index=False)\n",
    "\n",
    "# 5. Generar y mostrar las tablas (Media y Mediana)\n",
    "metricas = {'MEDIA': 'mean', 'MEDIANA': 'median'}\n",
    "\n",
    "for nombre_metrica, funcion in metricas.items():\n",
    "    # Calculamos el valor general según la métrica (mean o median)\n",
    "    if funcion == 'mean':\n",
    "        resumen_general = df_total[modelos].mean()\n",
    "        resumen_escenarios = df_total.groupby('ESCENARIO')[modelos].mean().T\n",
    "    else:\n",
    "        resumen_general = df_total[modelos].median()\n",
    "        resumen_escenarios = df_total.groupby('ESCENARIO')[modelos].median().T\n",
    "\n",
    "    # Construimos la tabla final para esta métrica\n",
    "    tabla_resumen = pd.DataFrame(index=modelos)\n",
    "    tabla_resumen['General'] = resumen_general\n",
    "    tabla_resumen['ARMA'] = resumen_escenarios['Lineal Estacionario']\n",
    "    tabla_resumen['ARIMA'] = resumen_escenarios['Lineal No estacionario']\n",
    "    tabla_resumen['SETAR'] = resumen_escenarios['No lineal Estacionario']\n",
    "\n",
    "    # Determinar el Mejor_Escenario (valor mínimo entre los tres escenarios)\n",
    "    escenarios_cols = ['ARMA', 'ARIMA', 'SETAR']\n",
    "    tabla_resumen['Mejor_Escenario'] = tabla_resumen[escenarios_cols].idxmin(axis=1)\n",
    "\n",
    "    # Imprimir resultado\n",
    "    print(f\"\\n--- Tabla Comparativa de Modelos (Basada en {nombre_metrica}) ---\")\n",
    "    print(tabla_resumen.reset_index().rename(columns={'index': 'Modelo'}).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc9573",
   "metadata": {},
   "source": [
    "### Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b90efcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo orden de modelos (basado en Lineal No Estacionario (ARIMA)):\n",
      "1. Sieve Bootstrap: 0.5475\n",
      "2. LSPMW: 1.0636\n",
      "3. LSPM: 1.0648\n",
      "4. MCPS: 3.2318\n",
      "5. AV-MCPS: 3.3418\n",
      "6. DeepAR: 4.3291\n",
      "7. EnCQR-LSTM: 5.8505\n",
      "8. AREPD: 10.0312\n",
      "9. Block Bootstrapping: 11.2519\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\n",
      "================================================================================\n",
      "✓ Gráfica 1.1 guardada\n",
      "✓ Gráfica 1.2 guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 2: ANÁLISIS POR CONFIG\n",
      "================================================================================\n",
      "✓ Gráfica 2.1 guardada\n",
      "✓ Gráfica 2.1.a guardada\n",
      "✓ Gráfica 2.1.b guardada\n",
      "✓ Gráfica 2.1.c guardada\n",
      "✓ Gráfica 2.2 guardada\n",
      "✓ Gráfica 2.2.a guardada\n",
      "✓ Gráfica 2.2.b guardada\n",
      "✓ Gráfica 2.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 3: ANÁLISIS POR DIST\n",
      "================================================================================\n",
      "✓ Gráfica 3.1 guardada\n",
      "✓ Gráfica 3.1.a guardada\n",
      "✓ Gráfica 3.1.b guardada\n",
      "✓ Gráfica 3.1.c guardada\n",
      "✓ Gráfica 3.2 guardada\n",
      "✓ Gráfica 3.2.a guardada\n",
      "✓ Gráfica 3.2.b guardada\n",
      "✓ Gráfica 3.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 4: ANÁLISIS POR VAR\n",
      "================================================================================\n",
      "✓ Gráfica 4.1 guardada\n",
      "✓ Gráfica 4.1.a guardada\n",
      "✓ Gráfica 4.1.b guardada\n",
      "✓ Gráfica 4.1.c guardada\n",
      "✓ Gráfica 4.2 guardada\n",
      "✓ Gráfica 4.2.a guardada\n",
      "✓ Gráfica 4.2.b guardada\n",
      "✓ Gráfica 4.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\n",
      "================================================================================\n",
      "✓ Gráfica 5.1 guardada\n",
      "✓ Gráfica 5.1.a guardada\n",
      "✓ Gráfica 5.1.b guardada\n",
      "✓ Gráfica 5.1.c guardada\n",
      "✓ Gráfica 5.2 guardada\n",
      "✓ Gráfica 5.2.a guardada\n",
      "✓ Gráfica 5.2.b guardada\n",
      "✓ Gráfica 5.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\n",
      "================================================================================\n",
      "✓ Gráfica 8 (5.7)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10)  guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .a guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .b guardada: Subplots por Modelo\n",
      "✓ Gráfica 8 (5.7) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 9 (5.8) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 10 (5.9) .c guardada: Subplots por Modelo\n",
      "✓ Gráfica 11 (5.10) .c guardada: Subplots por Modelo\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO POR ESCENARIO\n",
      "================================================================================\n",
      "✓ Gráfica 6.1 guardada (ordenada de menor a mayor CV)\n",
      "\n",
      "================================================================================\n",
      "EJECUTANDO ANÁLISIS DM: GENERAL Y POR FAMILIA DE PROCESOS\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ANÁLISIS DM GENERAL (TODOS LOS ESCENARIOS)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total de escenarios únicos: 420\n",
      "Total de modelos: 9\n",
      "Total de comparaciones por escenario: 36\n",
      "✓ Tabla de p-valores guardada: 420 escenarios × 36 comparaciones\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GENERANDO BOXPLOTS DE P-VALORES EXTREMOS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3 Comparaciones con MENORES p-valores promedio:\n",
      "  Sieve Bootstrap vs AV-MCPS: 0.0899\n",
      "  Sieve Bootstrap vs MCPS: 0.0921\n",
      "  DeepAR vs AREPD: 0.1013\n",
      "\n",
      "3 Comparaciones con MAYORES p-valores promedio:\n",
      "  AV-MCPS vs EnCQR-LSTM: 0.3169\n",
      "  MCPS vs AV-MCPS: 0.3965\n",
      "  LSPMW vs LSPM: 0.4499\n",
      "✓ Gráfica 6.3 guardada: Boxplot de p-valores extremos [GENERAL]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GENERANDO MATRIZ DE PORCENTAJE DE SIGNIFICANCIA CON BONFERRONI\n",
      "--------------------------------------------------------------------------------\n",
      "Tipo de análisis: GENERAL\n",
      "α nominal: 0.05\n",
      "α Bonferroni: 0.00139\n",
      "✓ Gráfica 6.4 guardada: Matriz de significancia (F<C) [GENERAL]\n",
      "✓ Excel 6.4 guardado: Matriz y resumen estadístico [GENERAL]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ANÁLISIS DM PARA: Lineal Estacionario (ARMA)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total de escenarios únicos: 140\n",
      "Total de modelos: 9\n",
      "Total de comparaciones por escenario: 36\n",
      "✓ Tabla de p-valores guardada: 140 escenarios × 36 comparaciones\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GENERANDO BOXPLOTS DE P-VALORES EXTREMOS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3 Comparaciones con MENORES p-valores promedio:\n",
      "  Sieve Bootstrap vs MCPS: 0.0293\n",
      "  Sieve Bootstrap vs AV-MCPS: 0.0324\n",
      "  MCPS vs DeepAR: 0.0520\n",
      "\n",
      "3 Comparaciones con MAYORES p-valores promedio:\n",
      "  AV-MCPS vs EnCQR-LSTM: 0.4295\n",
      "  MCPS vs AV-MCPS: 0.4834\n",
      "  LSPMW vs LSPM: 0.4978\n",
      "✓ Gráfica 6.3.a guardada: Boxplot de p-valores extremos [ARMA]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GENERANDO MATRIZ DE PORCENTAJE DE SIGNIFICANCIA CON BONFERRONI\n",
      "--------------------------------------------------------------------------------\n",
      "Tipo de análisis: ARMA\n",
      "α nominal: 0.05\n",
      "α Bonferroni: 0.00139\n",
      "✓ Gráfica 6.4.a guardada: Matriz de significancia (F<C) [ARMA]\n",
      "✓ Excel 6.4.a guardado: Matriz y resumen estadístico [ARMA]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ANÁLISIS DM PARA: Lineal No Estacionario (ARIMA)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total de escenarios únicos: 140\n",
      "Total de modelos: 9\n",
      "Total de comparaciones por escenario: 36\n",
      "✓ Tabla de p-valores guardada: 140 escenarios × 36 comparaciones\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GENERANDO BOXPLOTS DE P-VALORES EXTREMOS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3 Comparaciones con MENORES p-valores promedio:\n",
      "  Sieve Bootstrap vs Block Bootstrapping: 0.0030\n",
      "  DeepAR vs Block Bootstrapping: 0.0046\n",
      "  LSPM vs Block Bootstrapping: 0.0078\n",
      "\n",
      "3 Comparaciones con MAYORES p-valores promedio:\n",
      "  LSPMW vs MCPS: 0.2203\n",
      "  MCPS vs AV-MCPS: 0.2754\n",
      "  LSPMW vs LSPM: 0.4408\n",
      "✓ Gráfica 6.3.b guardada: Boxplot de p-valores extremos [ARIMA]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GENERANDO MATRIZ DE PORCENTAJE DE SIGNIFICANCIA CON BONFERRONI\n",
      "--------------------------------------------------------------------------------\n",
      "Tipo de análisis: ARIMA\n",
      "α nominal: 0.05\n",
      "α Bonferroni: 0.00139\n",
      "✓ Gráfica 6.4.b guardada: Matriz de significancia (F<C) [ARIMA]\n",
      "✓ Excel 6.4.b guardado: Matriz y resumen estadístico [ARIMA]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ANÁLISIS DM PARA: No lineal Estacionario (SETAR)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total de escenarios únicos: 140\n",
      "Total de modelos: 9\n",
      "Total de comparaciones por escenario: 36\n",
      "✓ Tabla de p-valores guardada: 140 escenarios × 36 comparaciones\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GENERANDO BOXPLOTS DE P-VALORES EXTREMOS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3 Comparaciones con MENORES p-valores promedio:\n",
      "  MCPS vs DeepAR: 0.1693\n",
      "  AREPD vs Block Bootstrapping: 0.1799\n",
      "  MCPS vs Block Bootstrapping: 0.1903\n",
      "\n",
      "3 Comparaciones con MAYORES p-valores promedio:\n",
      "  Sieve Bootstrap vs DeepAR: 0.3833\n",
      "  LSPMW vs LSPM: 0.4112\n",
      "  MCPS vs AV-MCPS: 0.4307\n",
      "✓ Gráfica 6.3.c guardada: Boxplot de p-valores extremos [SETAR]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GENERANDO MATRIZ DE PORCENTAJE DE SIGNIFICANCIA CON BONFERRONI\n",
      "--------------------------------------------------------------------------------\n",
      "Tipo de análisis: SETAR\n",
      "α nominal: 0.05\n",
      "α Bonferroni: 0.00139\n",
      "✓ Gráfica 6.4.c guardada: Matriz de significancia (F<C) [SETAR]\n",
      "✓ Excel 6.4.c guardado: Matriz y resumen estadístico [SETAR]\n",
      "\n",
      "================================================================================\n",
      "PROCESO COMPLETADO\n",
      "================================================================================\n",
      "\n",
      "Mejoras implementadas:\n",
      "1. ✓ Orden consistente en gráficas 1.1 y 1.2\n",
      "2. ✓ Formato de 2 decimales en heatmap 2.2 general\n",
      "3. ✓ Solo Coeficiente de Variación en gráfica 6.1 (ordenado menor a mayor)\n",
      "4. ✓ Test Diebold-Mariano POR ESCENARIO INDIVIDUAL\n",
      "5. ✓ Tabla de p-valores por escenario (Escenarios × Comparaciones)\n",
      "6. ✓ Boxplot de 3 menores y 3 mayores p-valores\n",
      "7. ✓ Matriz de % de significancia estadística\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE INTERACCIONES (Carpeta: Interacciones/)\n",
      "================================================================================\n",
      "8. ✓ Config × Var: Heatmaps por modelo (matriz 3×3)\n",
      "9. ✓ Config × Dist: Heatmaps por modelo (matriz 3×3)\n",
      "10. ✓ Dist × Paso: Gráficas de líneas por distribución\n",
      "11. ✓ Dist × Var: Gráficas de líneas por distribución\n",
      "12. ✓ Config × Paso: Gráficas de líneas por configuración\n",
      "13. ✓ Var × Horizonte: Gráficas de líneas por varianza\n",
      "================================================================================\n",
      "\n",
      "ARCHIVOS GENERADOS:\n",
      "  - 6.2_dm_test_por_escenarios.xlsx: Tabla completa de p-valores\n",
      "  - 6.3_boxplot_pvalores_extremos.png: Distribución de p-valores extremos\n",
      "  - 6.4_matriz_significancia_porcentual.png: Heatmap de % significancia\n",
      "  - 6.4_matriz_significancia.xlsx: Matriz y resumen estadístico\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración general\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Crear carpeta de resultados\n",
    "output_dir = Path(\"./Resultados_analisis/Simulacion_base\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Crear carpeta de interacciones\n",
    "interactions_dir = output_dir / \"Interacciones\"\n",
    "interactions_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_excel(\"./datos/Simulacion/Base/dataframe_consolidado.xlsx\")\n",
    "\n",
    "# 1) CAMBIO DE NOMBRES DE ESCENARIOS\n",
    "df['ESCENARIO'] = df['ESCENARIO'].replace({\n",
    "    \"Lineal Estacionario\": \"Lineal Estacionario (ARMA)\",\n",
    "    \"Lineal No estacionario\": \"Lineal No Estacionario (ARIMA)\",\n",
    "    \"No lineal Estacionario\": \"No lineal Estacionario (SETAR)\"\n",
    "})\n",
    "\n",
    "# Identificar columnas de modelos\n",
    "var_cols = ['Paso', 'Config', 'Dist', 'Var', 'ESCENARIO']\n",
    "original_model_cols = [col for col in df.columns if col not in var_cols]\n",
    "\n",
    "# 2) ORGANIZAR MODELOS POR RENDIMIENTO EN \"Lineal No Estacionario (ARIMA)\" (Menor a mayor)\n",
    "target_scenario = \"Lineal No Estacionario (ARIMA)\"\n",
    "model_order_scores = df[df['ESCENARIO'] == target_scenario][original_model_cols].mean().sort_values()\n",
    "model_cols = list(model_order_scores.index)\n",
    "\n",
    "print(\"Nuevo orden de modelos (basado en Lineal No Estacionario (ARIMA)):\")\n",
    "for i, m in enumerate(model_cols, 1):\n",
    "    print(f\"{i}. {m}: {model_order_scores[m]:.4f}\")\n",
    "\n",
    "# Mapeo de escenarios\n",
    "escenarios_map = {\n",
    "    'Lineal Estacionario (ARMA)': 'Lineal Estacionario (ARMA)',\n",
    "    'Lineal No Estacionario (ARIMA)': 'Lineal No Estacionario (ARIMA)',\n",
    "    'No lineal Estacionario (SETAR)': 'No lineal Estacionario (SETAR)'\n",
    "}\n",
    "\n",
    "# Definir colores para cada modelo\n",
    "palette = sns.color_palette(\"husl\", len(model_cols))\n",
    "model_colors = {model: palette[i] for i, model in enumerate(model_cols)}\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_performance_by_scenario():\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    scenarios = [\"Lineal Estacionario (ARMA)\", \"Lineal No Estacionario (ARIMA)\", \"No lineal Estacionario (SETAR)\"]\n",
    "    x = np.arange(len(model_cols))\n",
    "    width = 0.25 \n",
    "    \n",
    "    scenario_colors = {\n",
    "        'Lineal Estacionario (ARMA)': '#5D3FD3',    \n",
    "        'Lineal No Estacionario (ARIMA)': '#808080', \n",
    "        'No lineal Estacionario (SETAR)': '#00A36C'  \n",
    "    }\n",
    "    \n",
    "    for idx, scenario in enumerate(scenarios):\n",
    "        means = [df[df['ESCENARIO'] == scenario][model].mean() for model in model_cols]\n",
    "        position = x + (idx - 1) * width\n",
    "        \n",
    "        bars = ax.bar(position, means, width, label=scenario, \n",
    "                     color=scenario_colors[scenario], alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.2f}', ha='center', va='bottom', fontsize=7, rotation=0)\n",
    "    \n",
    "    ax.set_xlabel('Modelo (Ordenados por desempeño en ARIMA)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Rendimiento de Modelos por Escenario (ECRPS)', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_cols, rotation=45, ha='right', fontsize=9)\n",
    "    ax.legend(loc='upper left', ncol=1, fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '1.1_rendimiento_por_escenario.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 1.1 guardada\")\n",
    "\n",
    "plot_performance_by_scenario()\n",
    "\n",
    "def plot_relative_performance():\n",
    "    base_scenario = 'Lineal Estacionario (ARMA)'\n",
    "    scenarios_compare = ['Lineal No Estacionario (ARIMA)', 'No lineal Estacionario (SETAR)']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    y = np.arange(len(model_cols))\n",
    "    height = 0.35  \n",
    "    \n",
    "    for idx, scenario in enumerate(scenarios_compare):\n",
    "        changes = []\n",
    "        for model in model_cols:\n",
    "            base_value = df[df['ESCENARIO'] == base_scenario][model].mean()\n",
    "            scenario_value = df[df['ESCENARIO'] == scenario][model].mean()\n",
    "            pct_change = ((scenario_value - base_value) / base_value) * 100\n",
    "            changes.append(pct_change)\n",
    "        \n",
    "        position = y + idx * height\n",
    "        bars = ax.barh(position, changes, height, label=scenario, alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        for bar, val in zip(bars, changes):\n",
    "            width = bar.get_width()\n",
    "            ax.text(width + (1 if width > 0 else -1), bar.get_y() + bar.get_height()/2.,\n",
    "                   f'{val:+.1f}%', ha='left' if val > 0 else 'right', \n",
    "                   va='center', fontsize=7)\n",
    "    \n",
    "    ax.set_yticks(y + height / 2)\n",
    "    ax.set_yticklabels(model_cols, fontsize=10)\n",
    "    ax.set_xlabel('Cambio Relativo (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Cambio Relativo en ECRPS vs. {base_scenario}', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=1.5)\n",
    "    ax.legend(loc='best', fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '1.2_cambio_relativo_escenario_base.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 1.2 guardada\")\n",
    "\n",
    "plot_relative_performance()\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 2: ANÁLISIS POR CONFIG\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 2: ANÁLISIS POR CONFIG\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_zscore_heatmap_config(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Z-scores de ECRPS por Configuración ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Z-scores de ECRPS por Configuración (General)'\n",
    "    \n",
    "    pivot_data = data_filtered.groupby('Config')[model_cols].mean()\n",
    "    z_scores = pivot_data.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(z_scores.T, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, cbar_kws={'label': 'Z-score'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Configuración', fontsize=11)\n",
    "    ax.set_ylabel('Modelo', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'2.1{suffix}_zscore_config.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 2.1{suffix} guardada\")\n",
    "\n",
    "plot_zscore_heatmap_config()\n",
    "plot_zscore_heatmap_config('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_zscore_heatmap_config('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_zscore_heatmap_config('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_config(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Configuración ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Configuración (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Config')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    fmt = '.2f' if suffix == '' else '.4f'\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt=fmt, cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Configuración', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'2.2{suffix}_variabilidad_config.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 2.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_config()\n",
    "plot_variability_config('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_config('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_config('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 3: ANÁLISIS POR DIST\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 3: ANÁLISIS POR DIST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_zscore_heatmap_dist(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Z-scores de ECRPS por Distribución ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Z-scores de ECRPS por Distribución (General)'\n",
    "    \n",
    "    pivot_data = data_filtered.groupby('Dist')[model_cols].mean()\n",
    "    z_scores = pivot_data.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(z_scores.T, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, cbar_kws={'label': 'Z-score'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Distribución', fontsize=11)\n",
    "    ax.set_ylabel('Modelo', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'3.1{suffix}_zscore_dist.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 3.1{suffix} guardada\")\n",
    "\n",
    "plot_zscore_heatmap_dist()\n",
    "plot_zscore_heatmap_dist('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_zscore_heatmap_dist('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_zscore_heatmap_dist('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_dist(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Distribución ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Distribución (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Dist')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Distribución', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'3.2{suffix}_variabilidad_dist.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 3.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_dist()\n",
    "plot_variability_dist('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_dist('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_dist('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 4: ANÁLISIS POR VAR\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 4: ANÁLISIS POR VAR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_evolution_var(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Evolución de ECRPS por Varianza ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Evolución de ECRPS por Varianza (General)'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    var_values = sorted(data_filtered['Var'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means = []\n",
    "        for var in var_values:\n",
    "            mean_val = data_filtered[data_filtered['Var'] == var][model].mean()\n",
    "            means.append(mean_val)\n",
    "        \n",
    "        ax.plot(var_values, means, marker='o', label=model, color=model_colors[model],\n",
    "                linewidth=2.5, markersize=7, alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('Varianza', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', fontsize=9, ncol=2, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'4.1{suffix}_evolucion_var.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 4.1{suffix} guardada\")\n",
    "\n",
    "plot_evolution_var()\n",
    "plot_evolution_var('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_evolution_var('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_evolution_var('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_var(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Varianza ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Varianza (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Var')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Varianza', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'4.2{suffix}_variabilidad_var.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 4.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_var()\n",
    "plot_variability_var('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_var('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_var('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_evolution_paso(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Evolución de ECRPS por Horizonte de Pronóstico ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Evolución de ECRPS por Horizonte de Pronóstico (General)'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means = []\n",
    "        for paso in pasos:\n",
    "            mean_val = data_filtered[data_filtered['Paso'] == paso][model].mean()\n",
    "            means.append(mean_val)\n",
    "        \n",
    "        ax.plot(pasos, means, marker='o', label=model, color=model_colors[model],\n",
    "                linewidth=2.5, markersize=7, alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('Horizonte de Pronóstico', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', fontsize=9, ncol=2, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'5.1{suffix}_evolucion_paso.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.1{suffix} guardada\")\n",
    "\n",
    "plot_evolution_paso()\n",
    "plot_evolution_paso('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_evolution_paso('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_evolution_paso('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_paso(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Horizonte ({scenario})'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Horizonte (General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Paso')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Horizonte de Pronóstico', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'5.2{suffix}_variabilidad_paso.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_paso()\n",
    "plot_variability_paso('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_paso('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_paso('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Función auxiliar para configurar el grid de modelos\n",
    "def get_model_grid_axes(n_models):\n",
    "    n_cols = 3\n",
    "    n_rows = (n_models + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows))\n",
    "    return fig, axes.flatten(), n_rows, n_cols\n",
    "\n",
    "# INTERACCIÓN 3 (Lista 8): DIST × PASO - Subplots por Modelo\n",
    "def plot_interaction_dist_paso(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Dist × Paso por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, n_rows, n_cols = get_model_grid_axes(len(model_cols))\n",
    "    dists = sorted(data_filtered['Dist'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_dist = sns.color_palette(\"viridis\", len(dists))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for d_idx, dist in enumerate(dists):\n",
    "            means = [data_filtered[(data_filtered['Dist'] == dist) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='o', label=dist, color=colors_dist[d_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Distribución\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.7{suffix}_interaccion_dist_paso_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 8 (5.7) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 4 (Lista 9): DIST × VAR - Subplots por Modelo\n",
    "def plot_interaction_dist_var(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Dist × Var por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    dists = sorted(data_filtered['Dist'].unique())\n",
    "    vars_val = sorted(data_filtered['Var'].unique())\n",
    "    colors_dist = sns.color_palette(\"magma\", len(dists))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for d_idx, dist in enumerate(dists):\n",
    "            means = [data_filtered[(data_filtered['Dist'] == dist) & (data_filtered['Var'] == v)][model].mean() for v in vars_val]\n",
    "            ax.plot(vars_val, means, marker='s', label=dist, color=colors_dist[d_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Varianza')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Distribución\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.8{suffix}_interaccion_dist_var_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 9 (5.8) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 5 (Lista 10): CONFIG × PASO - Subplots por Modelo\n",
    "def plot_interaction_config_paso(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Config × Paso por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    configs = sorted(data_filtered['Config'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_conf = sns.color_palette(\"tab10\", len(configs))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for c_idx, config in enumerate(configs):\n",
    "            means = [data_filtered[(data_filtered['Config'] == config) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='^', label=config, color=colors_conf[c_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Config\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.9{suffix}_interaccion_config_paso_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 10 (5.9) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "# INTERACCIÓN 6 (Lista 11): VAR × HORIZONTE - Subplots por Modelo\n",
    "def plot_interaction_var_horizonte(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title = f'Interacción Var × Horizonte por Modelo ({\"General\" if not scenario else scenario})'\n",
    "    \n",
    "    fig, axes, _, _ = get_model_grid_axes(len(model_cols))\n",
    "    vars_val = sorted(data_filtered['Var'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    colors_var = sns.color_palette(\"rocket\", len(vars_val))\n",
    "\n",
    "    for idx, model in enumerate(model_cols):\n",
    "        ax = axes[idx]\n",
    "        for v_idx, var in enumerate(vars_val):\n",
    "            means = [data_filtered[(data_filtered['Var'] == var) & (data_filtered['Paso'] == p)][model].mean() for p in pasos]\n",
    "            ax.plot(pasos, means, marker='d', label=f'Var {var}', color=colors_var[v_idx], linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'Modelo: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Horizonte (Paso)')\n",
    "        ax.set_ylabel('ECRPS Promedio')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(title=\"Varianza\", fontsize=8)\n",
    "\n",
    "    for i in range(len(model_cols), len(axes)): axes[i].set_visible(False)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.10{suffix}_interaccion_var_horizonte_modelos.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 11 (5.10) {suffix} guardada: Subplots por Modelo\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# EJECUCIÓN DE LAS NUEVAS FUNCIONES\n",
    "# ====================================================================================\n",
    "\n",
    "for sc_name, sc_suf in [ (None, ''), ('Lineal Estacionario (ARMA)', '.a'), \n",
    "                        ('Lineal No Estacionario (ARIMA)', '.b'), \n",
    "                        ('No lineal Estacionario (SETAR)', '.c') ]:\n",
    "    plot_interaction_dist_paso(sc_name, sc_suf)\n",
    "    plot_interaction_dist_var(sc_name, sc_suf)\n",
    "    plot_interaction_config_paso(sc_name, sc_suf)\n",
    "    plot_interaction_var_horizonte(sc_name, sc_suf)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO POR ESCENARIO\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO POR ESCENARIO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_robustness():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    cv_data = []\n",
    "    for model in model_cols:\n",
    "        cv = df[model].std() / df[model].mean()\n",
    "        cv_data.append((model, cv))\n",
    "    \n",
    "    cv_df = pd.DataFrame(cv_data, columns=['Modelo', 'CV'])\n",
    "    \n",
    "    # Ordenar de menor a mayor CV para coherencia\n",
    "    cv_df = cv_df.sort_values('CV')\n",
    "    \n",
    "    colors_cv = ['#2ecc71' if cv < cv_df['CV'].median() else '#e74c3c' \n",
    "                 for cv in cv_df['CV']]\n",
    "    \n",
    "    bars = ax.barh(cv_df['Modelo'], cv_df['CV'], color=colors_cv, alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    for bar, cv in zip(bars, cv_df['CV']):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.001, bar.get_y() + bar.get_height()/2.,\n",
    "               f'{cv:.4f}', ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Coeficiente de Variación', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Robustez: Coeficiente de Variación\\n(Ordenado de menor a mayor - Menor valor indica mayor estabilidad)', \n",
    "                  fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.axvline(x=cv_df['CV'].median(), color='black', linestyle='--', linewidth=1.5, alpha=0.5, label='Mediana')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '6.1_robustez_coeficiente_variacion.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 6.1 guardada (ordenada de menor a mayor CV)\")\n",
    "\n",
    "plot_robustness()\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano con fixed-smoothing asymptotics (Coroneo & Iacone, 2020)\n",
    "    \"\"\"\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    if T < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    u = d - d_bar\n",
    "    m = max(1, int(np.floor(T**(1/3))))\n",
    "    \n",
    "    from scipy.fft import fft\n",
    "    fft_u = fft(u)\n",
    "    periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "    \n",
    "    if m >= len(periodogram) - 1:\n",
    "        m = len(periodogram) - 2\n",
    "    \n",
    "    sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "    \n",
    "    if sigma_hat_sq <= 0:\n",
    "        sigma_hat_sq = np.var(d, ddof=1) / T\n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0, 0\n",
    "    \n",
    "    dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "    df = 2 * m\n",
    "    hln_dm_stat = dm_stat\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "\n",
    "def create_scenario_description(row):\n",
    "    \"\"\"\n",
    "    Crea una descripción del escenario basada en sus características\n",
    "    \"\"\"\n",
    "    escenario = row['ESCENARIO']\n",
    "    config = row['Config']\n",
    "    dist = row['Dist']\n",
    "    var = row['Var']\n",
    "    \n",
    "    # Mapear nombres completos\n",
    "    escenario_map = {\n",
    "        'Lineal Estacionario (ARMA)': 'ARMA',\n",
    "        'Lineal No Estacionario (ARIMA)': 'ARIMA',\n",
    "        'No lineal Estacionario (SETAR)': 'SETAR'\n",
    "    }\n",
    "    \n",
    "    escenario_short = escenario_map.get(escenario, escenario)\n",
    "    \n",
    "    return f\"{escenario_short}_Config{config}_Dist{dist}_Var{var}\"\n",
    "\n",
    "\n",
    "def dm_test_by_scenarios(scenario_filter=None, suffix=''):\n",
    "    \"\"\"\n",
    "    Realiza el test DM por cada escenario individual con corrección de Bonferroni\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    scenario_filter : str or None\n",
    "        Si se especifica ('Lineal Estacionario (ARMA)', etc.), filtra solo esos escenarios\n",
    "    suffix : str\n",
    "        Sufijo para los archivos generados\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    if scenario_filter:\n",
    "        print(f\"ANÁLISIS DM PARA: {scenario_filter}\")\n",
    "    else:\n",
    "        print(\"ANÁLISIS DM GENERAL (TODOS LOS ESCENARIOS)\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Filtrar datos si es necesario\n",
    "    if scenario_filter:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario_filter].copy()\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "    \n",
    "    # Crear identificador único para cada escenario\n",
    "    data_filtered['Escenario_ID'] = data_filtered.apply(create_scenario_description, axis=1)\n",
    "    \n",
    "    # Obtener lista de escenarios únicos\n",
    "    unique_scenarios = data_filtered['Escenario_ID'].unique()\n",
    "    n_scenarios = len(unique_scenarios)\n",
    "    n_models = len(model_cols)\n",
    "    \n",
    "    print(f\"\\nTotal de escenarios únicos: {n_scenarios}\")\n",
    "    print(f\"Total de modelos: {n_models}\")\n",
    "    print(f\"Total de comparaciones por escenario: {n_models * (n_models - 1) // 2}\")\n",
    "    \n",
    "    # Matriz para almacenar todos los p-valores\n",
    "    all_pvalues = []\n",
    "    scenario_names = []\n",
    "    comparison_names = []\n",
    "    \n",
    "    # Matriz para contar cuántas veces la media de fila > columna\n",
    "    all_mean_comparisons = []\n",
    "    \n",
    "    # Generar nombres de comparaciones\n",
    "    for i in range(n_models):\n",
    "        for j in range(i+1, n_models):\n",
    "            comparison_names.append(f\"{model_cols[i]} vs {model_cols[j]}\")\n",
    "    \n",
    "    # Realizar test DM para cada escenario\n",
    "    for scenario_id in unique_scenarios:\n",
    "        scenario_data = data_filtered[data_filtered['Escenario_ID'] == scenario_id]\n",
    "        \n",
    "        # Extraer características del escenario\n",
    "        scenario_info = scenario_data.iloc[0]\n",
    "        \n",
    "        pvalues_row = []\n",
    "        mean_comp_row = []\n",
    "        \n",
    "        # Comparar todos los pares de modelos\n",
    "        for i in range(n_models):\n",
    "            for j in range(i+1, n_models):\n",
    "                model1 = model_cols[i]\n",
    "                model2 = model_cols[j]\n",
    "                \n",
    "                errors1 = scenario_data[model1].values\n",
    "                errors2 = scenario_data[model2].values\n",
    "                \n",
    "                h_forecast = int(scenario_info['Paso'])\n",
    "                \n",
    "                _, p_val, _ = modified_diebold_mariano_test(errors1, errors2, h=h_forecast)\n",
    "                pvalues_row.append(p_val)\n",
    "                \n",
    "                # Comparar medias (1 si media1 > media2, 0 si no)\n",
    "                mean1 = np.mean(errors1)\n",
    "                mean2 = np.mean(errors2)\n",
    "                mean_comp_row.append(1 if mean1 > mean2 else 0)\n",
    "        \n",
    "        all_pvalues.append(pvalues_row)\n",
    "        all_mean_comparisons.append(mean_comp_row)\n",
    "        scenario_names.append(scenario_id)\n",
    "    \n",
    "    # Crear DataFrame con todos los p-valores\n",
    "    pvalues_df = pd.DataFrame(all_pvalues, columns=comparison_names, index=scenario_names)\n",
    "    mean_comp_df = pd.DataFrame(all_mean_comparisons, columns=comparison_names, index=scenario_names)\n",
    "    \n",
    "    # Guardar en Excel\n",
    "    excel_filename = f'6.2{suffix}_dm_test_por_escenarios.xlsx'\n",
    "    with pd.ExcelWriter(output_dir / excel_filename) as writer:\n",
    "        pvalues_df.to_excel(writer, sheet_name='P_valores_por_escenario')\n",
    "        \n",
    "        # Agregar hoja con información de escenarios\n",
    "        scenario_info_list = []\n",
    "        for scenario_id in scenario_names:\n",
    "            scenario_data = data_filtered[data_filtered['Escenario_ID'] == scenario_id].iloc[0]\n",
    "            scenario_info_list.append({\n",
    "                'Escenario_ID': scenario_id,\n",
    "                'Tipo': scenario_data['ESCENARIO'],\n",
    "                'Config': scenario_data['Config'],\n",
    "                'Dist': scenario_data['Dist'],\n",
    "                'Var': scenario_data['Var'],\n",
    "                'Paso': scenario_data['Paso']\n",
    "            })\n",
    "        scenario_info_df = pd.DataFrame(scenario_info_list)\n",
    "        scenario_info_df.to_excel(writer, sheet_name='Info_Escenarios', index=False)\n",
    "    \n",
    "    print(f\"✓ Tabla de p-valores guardada: {n_scenarios} escenarios × {len(comparison_names)} comparaciones\")\n",
    "    \n",
    "    # BOXPLOT DE LOS 3 MENORES Y 3 MAYORES P-VALORES\n",
    "    plot_extreme_pvalues_boxplot(pvalues_df, comparison_names, suffix)\n",
    "    \n",
    "    # MATRIZ DE PORCENTAJE DE SIGNIFICANCIA CON BONFERRONI Y % MEDIA MAYOR\n",
    "    create_significance_matrix(pvalues_df, mean_comp_df, comparison_names, n_scenarios, suffix)\n",
    "    \n",
    "    return pvalues_df, comparison_names\n",
    "\n",
    "\n",
    "def plot_extreme_pvalues_boxplot(pvalues_df, comparison_names, suffix=''):\n",
    "    \"\"\"\n",
    "    Crea boxplots de las 3 comparaciones con menores y mayores p-valores promedio\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"GENERANDO BOXPLOTS DE P-VALORES EXTREMOS\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Determinar tipo de análisis\n",
    "    analysis_type = {\n",
    "        '': 'GENERAL',\n",
    "        '.a': 'ARMA',\n",
    "        '.b': 'ARIMA',\n",
    "        '.c': 'SETAR'\n",
    "    }\n",
    "    tipo = analysis_type.get(suffix, 'GENERAL')\n",
    "    \n",
    "    # Calcular p-valor promedio para cada comparación\n",
    "    mean_pvalues = pvalues_df.mean().sort_values()\n",
    "    \n",
    "    # Seleccionar 3 menores y 3 mayores\n",
    "    lowest_3 = mean_pvalues.head(3)\n",
    "    highest_3 = mean_pvalues.tail(3)\n",
    "    \n",
    "    selected_comparisons = list(lowest_3.index) + list(highest_3.index)\n",
    "    \n",
    "    print(f\"\\n3 Comparaciones con MENORES p-valores promedio:\")\n",
    "    for comp in lowest_3.index:\n",
    "        print(f\"  {comp}: {lowest_3[comp]:.4f}\")\n",
    "    \n",
    "    print(f\"\\n3 Comparaciones con MAYORES p-valores promedio:\")\n",
    "    for comp in highest_3.index:\n",
    "        print(f\"  {comp}: {highest_3[comp]:.4f}\")\n",
    "    \n",
    "    # Crear boxplot\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    data_to_plot = [pvalues_df[comp].values for comp in selected_comparisons]\n",
    "    \n",
    "    bp = ax.boxplot(data_to_plot, labels=selected_comparisons, patch_artist=True,\n",
    "                    showmeans=True, meanline=True)\n",
    "    \n",
    "    # Colorear: menores en verde, mayores en rojo\n",
    "    colors = ['#2ecc71'] * 3 + ['#e74c3c'] * 3\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.6)\n",
    "    \n",
    "    # Calcular alpha de Bonferroni\n",
    "    n_comparisons = len(comparison_names)\n",
    "    alpha_bonferroni = 0.05 / n_comparisons\n",
    "    \n",
    "    # Línea de significancia\n",
    "    ax.axhline(y=0.05, color='black', linestyle='--', linewidth=2, label='α = 0.05 (nominal)')\n",
    "    ax.axhline(y=alpha_bonferroni, color='red', linestyle='--', linewidth=1.5, \n",
    "               label=f'α = {alpha_bonferroni:.5f} (Bonferroni)', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Comparación entre Modelos', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('P-valor', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Distribución de P-valores [{tipo}]: 3 Menores y 3 Mayores Comparaciones\\n(Menor p-valor = Mayor evidencia de diferencia significativa)', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticklabels(selected_comparisons, rotation=45, ha='right', fontsize=9)\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Añadir anotaciones de media\n",
    "    medians = [np.median(data) for data in data_to_plot]\n",
    "    for i, (median, comp) in enumerate(zip(medians, selected_comparisons)):\n",
    "        ax.text(i+1, median, f'{median:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'6.3{suffix}_boxplot_pvalores_extremos.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Gráfica 6.3{suffix} guardada: Boxplot de p-valores extremos [{tipo}]\")\n",
    "\n",
    "\n",
    "def create_significance_matrix(pvalues_df, mean_comp_df, comparison_names, n_scenarios, suffix=''):\n",
    "    \"\"\"\n",
    "    Crea matriz de % de veces que el p-valor es significativo con Bonferroni\n",
    "    y % de veces que la media de fila < columna (F < C)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"GENERANDO MATRIZ DE PORCENTAJE DE SIGNIFICANCIA CON BONFERRONI\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Determinar tipo de análisis\n",
    "    analysis_type = {\n",
    "        '': 'GENERAL',\n",
    "        '.a': 'ARMA',\n",
    "        '.b': 'ARIMA',\n",
    "        '.c': 'SETAR'\n",
    "    }\n",
    "    tipo = analysis_type.get(suffix, 'GENERAL')\n",
    "    \n",
    "    alpha = 0.05\n",
    "    n_models = len(model_cols)\n",
    "    n_comparisons = len(comparison_names)\n",
    "    alpha_bonferroni = alpha / n_comparisons\n",
    "    \n",
    "    print(f\"Tipo de análisis: {tipo}\")\n",
    "    print(f\"α nominal: {alpha}\")\n",
    "    print(f\"α Bonferroni: {alpha_bonferroni:.5f}\")\n",
    "    \n",
    "    # Matriz de porcentaje de significancia\n",
    "    significance_matrix = np.zeros((n_models, n_models))\n",
    "    \n",
    "    # Matriz de porcentaje de veces que media fila < media columna\n",
    "    mean_lower_matrix = np.zeros((n_models, n_models))\n",
    "    \n",
    "    # Procesar cada comparación\n",
    "    for comparison in comparison_names:\n",
    "        # Extraer nombres de modelos\n",
    "        parts = comparison.split(' vs ')\n",
    "        model1 = parts[0]\n",
    "        model2 = parts[1]\n",
    "        \n",
    "        idx1 = model_cols.index(model1)\n",
    "        idx2 = model_cols.index(model2)\n",
    "        \n",
    "        # Calcular porcentaje de veces que es significativo (Bonferroni)\n",
    "        pvalues = pvalues_df[comparison].values\n",
    "        significant_count = np.sum(pvalues < alpha_bonferroni)\n",
    "        percentage_sig = (significant_count / len(pvalues)) * 100\n",
    "        \n",
    "        # Calcular porcentaje de veces que media1 < media2\n",
    "        # Asumiendo que mean_comp_df tiene 1 si m1 > m2 y 0 si m1 < m2\n",
    "        mean_comparisons = mean_comp_df[comparison].values\n",
    "        percentage_mean1_greater = (np.sum(mean_comparisons) / len(mean_comparisons)) * 100\n",
    "        \n",
    "        # Invertimos la lógica para obtener F < C\n",
    "        percentage_mean1_lower = 100 - percentage_mean1_greater\n",
    "        percentage_mean2_lower = percentage_mean1_greater # Porque si m1 > m2, entonces m2 < m1\n",
    "        \n",
    "        # Llenar matrices\n",
    "        significance_matrix[idx1, idx2] = percentage_sig\n",
    "        significance_matrix[idx2, idx1] = percentage_sig\n",
    "        \n",
    "        mean_lower_matrix[idx1, idx2] = percentage_mean1_lower\n",
    "        mean_lower_matrix[idx2, idx1] = percentage_mean2_lower\n",
    "    \n",
    "    # Crear DataFrames\n",
    "    significance_df = pd.DataFrame(significance_matrix, \n",
    "                                   index=model_cols, \n",
    "                                   columns=model_cols)\n",
    "    \n",
    "    mean_lower_df = pd.DataFrame(mean_lower_matrix,\n",
    "                                 index=model_cols,\n",
    "                                 columns=model_cols)\n",
    "    \n",
    "    # Crear matriz combinada para anotaciones\n",
    "    combined_annot = np.empty((n_models, n_models), dtype=object)\n",
    "    for i in range(n_models):\n",
    "        for j in range(n_models):\n",
    "            if i == j:\n",
    "                combined_annot[i, j] = '-'\n",
    "            else:\n",
    "                sig_val = significance_matrix[i, j]\n",
    "                mean_val = mean_lower_matrix[i, j]\n",
    "                \n",
    "                # Cambiado a F < C\n",
    "                combined_annot[i, j] = f'Sig: {sig_val:.1f}%\\nF<C: {mean_val:.1f}%'\n",
    "    \n",
    "    # Visualizar como heatmap\n",
    "    fig, ax = plt.subplots(figsize=(16, 14))\n",
    "    \n",
    "    # Usamos RdYlGn (Rojo a Verde). En error, F < C alto es bueno (Verde)\n",
    "    sns.heatmap(significance_df, annot=combined_annot, fmt='', cmap='RdYlGn', \n",
    "                center=50, vmin=0, vmax=100,\n",
    "                cbar_kws={'label': '% Significancia (p < α Bonferroni)'},\n",
    "                ax=ax, linewidths=0.5, linecolor='gray', annot_kws={'fontsize': 8})\n",
    "    \n",
    "    title_text = f'Matriz de Significancia Estadística [{tipo}]\\n'\n",
    "    title_text += f'Sig: % Significancia (α={alpha_bonferroni:.5f}) | F<C: % Fila < Columna (Mejor)'\n",
    "    \n",
    "    ax.set_title(title_text, fontsize=13, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Modelo (Columna)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo (Fila)', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'6.4{suffix}_matriz_significancia_porcentual.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar en Excel\n",
    "    excel_filename = f'6.4{suffix}_matriz_significancia.xlsx'\n",
    "    with pd.ExcelWriter(output_dir / excel_filename) as writer:\n",
    "        significance_df.to_excel(writer, sheet_name='Porcentaje_Significancia')\n",
    "        mean_lower_df.to_excel(writer, sheet_name='Porcentaje_Media_Menor')\n",
    "        \n",
    "        # Resumen estadístico\n",
    "        summary_stats = []\n",
    "        for model in model_cols:\n",
    "            idx = model_cols.index(model)\n",
    "            sig_values = [significance_matrix[idx, j] for j in range(n_models) if j != idx]\n",
    "            mean_values = [mean_lower_matrix[idx, j] for j in range(n_models) if j != idx]\n",
    "            \n",
    "            summary_stats.append({\n",
    "                'Modelo': model,\n",
    "                'Significancia_Promedio_%': np.mean(sig_values),\n",
    "                'Media_Menor_Promedio_% (F<C)': np.mean(mean_values),\n",
    "                'Media_Menor_Mediana_% (F<C)': np.median(mean_values),\n",
    "                'ECRPS_Promedio': df[model].mean() if suffix == '' else df[df['ESCENARIO'] == {'': '', '.a': 'Lineal Estacionario (ARMA)', '.b': 'Lineal No Estacionario (ARIMA)', '.c': 'No lineal Estacionario (SETAR)'}[suffix]][model].mean()\n",
    "            })\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_stats)\n",
    "        summary_df = summary_df.sort_values('ECRPS_Promedio')\n",
    "        summary_df.to_excel(writer, sheet_name='Resumen_por_Modelo', index=False)\n",
    "        \n",
    "        # Información metodológica\n",
    "        method_info = pd.DataFrame({\n",
    "            'Parámetro': ['Tipo de análisis', 'Alpha nominal', 'Alpha Bonferroni', \n",
    "                          'Número comparaciones', 'Número escenarios', 'Test estadístico', 'Métrica Comparativa'],\n",
    "            'Valor': [tipo, alpha, alpha_bonferroni, n_comparisons, n_scenarios, \n",
    "                      'Diebold-Mariano modificado (HLN)', 'F < C (Fila menor que Columna)']\n",
    "        })\n",
    "        method_info.to_excel(writer, sheet_name='Metodologia', index=False)\n",
    "    \n",
    "    print(f\"✓ Gráfica 6.4{suffix} guardada: Matriz de significancia (F<C) [{tipo}]\")\n",
    "    print(f\"✓ Excel 6.4{suffix} guardado: Matriz y resumen estadístico [{tipo}]\")\n",
    "    \n",
    "    return significance_df, mean_lower_df\n",
    "\n",
    "\n",
    "# EJECUTAR ANÁLISIS DM: GENERAL Y POR FAMILIA\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EJECUTANDO ANÁLISIS DM: GENERAL Y POR FAMILIA DE PROCESOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Análisis General\n",
    "dm_test_by_scenarios(scenario_filter=None, suffix='')\n",
    "\n",
    "# 2. Análisis por ARMA\n",
    "dm_test_by_scenarios(scenario_filter='Lineal Estacionario (ARMA)', suffix='.a')\n",
    "\n",
    "# 3. Análisis por ARIMA\n",
    "dm_test_by_scenarios(scenario_filter='Lineal No Estacionario (ARIMA)', suffix='.b')\n",
    "\n",
    "# 4. Análisis por SETAR\n",
    "dm_test_by_scenarios(scenario_filter='No lineal Estacionario (SETAR)', suffix='.c')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESO COMPLETADO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nMejoras implementadas:\")\n",
    "print(\"1. ✓ Orden consistente en gráficas 1.1 y 1.2\")\n",
    "print(\"2. ✓ Formato de 2 decimales en heatmap 2.2 general\")\n",
    "print(\"3. ✓ Solo Coeficiente de Variación en gráfica 6.1 (ordenado menor a mayor)\")\n",
    "print(\"4. ✓ Test Diebold-Mariano POR ESCENARIO INDIVIDUAL\")\n",
    "print(\"5. ✓ Tabla de p-valores por escenario (Escenarios × Comparaciones)\")\n",
    "print(\"6. ✓ Boxplot de 3 menores y 3 mayores p-valores\")\n",
    "print(\"7. ✓ Matriz de % de significancia estadística\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS DE INTERACCIONES (Carpeta: Interacciones/)\")\n",
    "print(\"=\"*80)\n",
    "print(\"8. ✓ Config × Var: Heatmaps por modelo (matriz 3×3)\")\n",
    "print(\"9. ✓ Config × Dist: Heatmaps por modelo (matriz 3×3)\")\n",
    "print(\"10. ✓ Dist × Paso: Gráficas de líneas por distribución\")\n",
    "print(\"11. ✓ Dist × Var: Gráficas de líneas por distribución\")\n",
    "print(\"12. ✓ Config × Paso: Gráficas de líneas por configuración\")\n",
    "print(\"13. ✓ Var × Horizonte: Gráficas de líneas por varianza\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nARCHIVOS GENERADOS:\")\n",
    "print(f\"  - 6.2_dm_test_por_escenarios.xlsx: Tabla completa de p-valores\")\n",
    "print(f\"  - 6.3_boxplot_pvalores_extremos.png: Distribución de p-valores extremos\")\n",
    "print(f\"  - 6.4_matriz_significancia_porcentual.png: Heatmap de % significancia\")\n",
    "print(f\"  - 6.4_matriz_significancia.xlsx: Matriz y resumen estadístico\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71c0b0",
   "metadata": {},
   "source": [
    "## Analisis Diferenciado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88955e",
   "metadata": {},
   "source": [
    "### Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "249b1e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla Comparativa de Desempeño (Promedios):\n",
      "                         ARIMA  ARIMA_Diff Mejor_Escenario\n",
      "Modelo                                                    \n",
      "AREPD                10.031183    0.704149      ARIMA_Diff\n",
      "AV-MCPS               3.324007    0.654257      ARIMA_Diff\n",
      "Block Bootstrapping  11.251601    0.666133      ARIMA_Diff\n",
      "DeepAR                4.329124    0.561822      ARIMA_Diff\n",
      "EnCQR-LSTM            6.112344    0.880288      ARIMA_Diff\n",
      "LSPM                  1.064804    0.648039      ARIMA_Diff\n",
      "LSPMW                 3.079645    0.767172      ARIMA_Diff\n",
      "MCPS                  3.218168    0.677471      ARIMA_Diff\n",
      "Sieve Bootstrap       0.547481    0.546020      ARIMA_Diff\n",
      "\n",
      "Archivo de unión guardado en: ./datos/Simulacion/Diferenciado/resultados_UNION_ARIMA.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Cargar los archivos\n",
    "path_diff = \"./datos/Simulacion/Diferenciado/resultados_140_ARIMA_CON_DIFERENCIACION.xlsx\"\n",
    "path_no_diff = \"./datos/Simulacion/Diferenciado/resultados_140_ARIMA_FINAL.xlsx\"\n",
    "\n",
    "arima_Diff_df = pd.read_excel(path_diff)\n",
    "arima_df = pd.read_excel(path_no_diff)\n",
    "\n",
    "# 2. Agregar la columna 'Diferenciacion' al dataframe que no la tiene\n",
    "arima_df['Diferenciacion'] = 'No'\n",
    "\n",
    "# 3. Unir los dataframes (uno debajo del otro)\n",
    "# El orden de las columnas se ajustará automáticamente\n",
    "df_unido = pd.concat([arima_Diff_df, arima_df], ignore_index=True)\n",
    "\n",
    "# 4. Guardar la unión en la misma carpeta\n",
    "path_salida = \"./datos/Simulacion/Diferenciado/resultados_UNION_ARIMA.xlsx\"\n",
    "df_unido.to_excel(path_salida, index=False)\n",
    "\n",
    "# 5. Crear la tabla comparativa (Resumen)\n",
    "# Definimos las métricas/modelos a comparar\n",
    "modelos_metricas = [\n",
    "    'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', \n",
    "    'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap'\n",
    "]\n",
    "\n",
    "# Calculamos el promedio para cada caso\n",
    "resumen_no_diff = arima_df[modelos_metricas].mean()\n",
    "resumen_diff = arima_Diff_df[modelos_metricas].mean()\n",
    "\n",
    "# Construir el DataFrame comparativo\n",
    "tabla_comparativa = pd.DataFrame({\n",
    "    'ARIMA': resumen_no_diff,\n",
    "    'ARIMA_Diff': resumen_diff\n",
    "})\n",
    "\n",
    "# Determinar el mejor escenario (el que tenga el valor menor, asumiendo que son errores)\n",
    "tabla_comparativa['Mejor_Escenario'] = np.where(\n",
    "    tabla_comparativa['ARIMA'] < tabla_comparativa['ARIMA_Diff'], \n",
    "    'ARIMA', \n",
    "    'ARIMA_Diff'\n",
    ")\n",
    "\n",
    "# Formatear la tabla para que se vea limpia\n",
    "tabla_comparativa.index.name = 'Modelo'\n",
    "tabla_comparativa = tabla_comparativa.sort_index()\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Tabla Comparativa de Desempeño (Promedios):\")\n",
    "print(tabla_comparativa.to_string())\n",
    "\n",
    "print(f\"\\nArchivo de unión guardado en: {path_salida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08864bc2",
   "metadata": {},
   "source": [
    "### Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3ee6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Datos cargados: (3360, 19)\n",
      "✓ Columnas: ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', 'Distribución', 'Varianza', 'Modalidad', 'Valor_Observado', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
      "✓ Modelos identificados: ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
      "✓ Valores únicos de d: [np.int64(1)]\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS: MISMO MÉTODO CON DIFF VS SIN DIFF\n",
      "CORRECCIÓN DE BONFERRONI POR ESCENARIOS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS: MISMO MÉTODO, CON DIFF VS SIN DIFF POR ESCENARIO\n",
      "CORRECCIÓN DE BONFERRONI APLICADA\n",
      "================================================================================\n",
      "\n",
      "✓ Escenarios únicos detectados: 140\n",
      "✓ α nominal: 0.05\n",
      "✓ α Bonferroni: 0.000357\n",
      "✓ Criterio: p < 0.000357 para significancia\n",
      "\n",
      "\n",
      "============================================================\n",
      "Procesando: AREPD\n",
      "============================================================\n",
      "  ✓ Escenarios evaluados: 140\n",
      "  ✓ Escenarios significativos (Bonferroni): 59 (42.1%)\n",
      "  ✓ ECRPS promedio Sin Diff: 10.0312\n",
      "  ✓ ECRPS promedio Con Diff: 0.7046\n",
      "  ✓ Cambio porcentual: +92.98%\n",
      "\n",
      "============================================================\n",
      "Procesando: AV-MCPS\n",
      "============================================================\n",
      "  ✓ Escenarios evaluados: 140\n",
      "  ✓ Escenarios significativos (Bonferroni): 3 (2.1%)\n",
      "  ✓ ECRPS promedio Sin Diff: 3.3034\n",
      "  ✓ ECRPS promedio Con Diff: 0.6629\n",
      "  ✓ Cambio porcentual: +79.93%\n",
      "\n",
      "============================================================\n",
      "Procesando: Block Bootstrapping\n",
      "============================================================\n",
      "  ✓ Escenarios evaluados: 140\n",
      "  ✓ Escenarios significativos (Bonferroni): 79 (56.4%)\n",
      "  ✓ ECRPS promedio Sin Diff: 11.2519\n",
      "  ✓ ECRPS promedio Con Diff: 0.6660\n",
      "  ✓ Cambio porcentual: +94.08%\n",
      "\n",
      "============================================================\n",
      "Procesando: DeepAR\n",
      "============================================================\n",
      "  ✓ Escenarios evaluados: 140\n",
      "  ✓ Escenarios significativos (Bonferroni): 14 (10.0%)\n",
      "  ✓ ECRPS promedio Sin Diff: 3.2069\n",
      "  ✓ ECRPS promedio Con Diff: 0.5626\n",
      "  ✓ Cambio porcentual: +82.46%\n",
      "\n",
      "============================================================\n",
      "Procesando: EnCQR-LSTM\n",
      "============================================================\n",
      "  ✓ Escenarios evaluados: 140\n",
      "  ✓ Escenarios significativos (Bonferroni): 51 (36.4%)\n",
      "  ✓ ECRPS promedio Sin Diff: 6.0051\n",
      "  ✓ ECRPS promedio Con Diff: 0.7088\n",
      "  ✓ Cambio porcentual: +88.20%\n",
      "\n",
      "============================================================\n",
      "Procesando: LSPM\n",
      "============================================================\n",
      "  ✓ Escenarios evaluados: 140\n",
      "  ✓ Escenarios significativos (Bonferroni): 0 (0.0%)\n",
      "  ✓ ECRPS promedio Sin Diff: 1.0648\n",
      "  ✓ ECRPS promedio Con Diff: 0.6477\n",
      "  ✓ Cambio porcentual: +39.17%\n",
      "\n",
      "============================================================\n",
      "Procesando: LSPMW\n",
      "============================================================\n",
      "  ✓ Escenarios evaluados: 140\n",
      "  ✓ Escenarios significativos (Bonferroni): 0 (0.0%)\n",
      "  ✓ ECRPS promedio Sin Diff: 1.0636\n",
      "  ✓ ECRPS promedio Con Diff: 0.6536\n",
      "  ✓ Cambio porcentual: +38.55%\n",
      "\n",
      "============================================================\n",
      "Procesando: MCPS\n",
      "============================================================\n",
      "  ✓ Escenarios evaluados: 140\n",
      "  ✓ Escenarios significativos (Bonferroni): 10 (7.1%)\n",
      "  ✓ ECRPS promedio Sin Diff: 3.2318\n",
      "  ✓ ECRPS promedio Con Diff: 0.6855\n",
      "  ✓ Cambio porcentual: +78.79%\n",
      "\n",
      "============================================================\n",
      "Procesando: Sieve Bootstrap\n",
      "============================================================\n",
      "  ✓ Escenarios evaluados: 140\n",
      "  ✓ Escenarios significativos (Bonferroni): 0 (0.0%)\n",
      "  ✓ ECRPS promedio Sin Diff: 0.5475\n",
      "  ✓ ECRPS promedio Con Diff: 0.5449\n",
      "  ✓ Cambio porcentual: +0.46%\n",
      "\n",
      "================================================================================\n",
      "✓ RESUMEN GUARDADO EN: Resultados_analisis\\Simulacion_diff\\RESUMEN_ConDiff_vs_SinDiff_por_Metodo_Bonferroni.xlsx\n",
      "================================================================================\n",
      "\n",
      "\n",
      "=== Generando gráfico de resumen ===\n",
      "✓ Gráfico de resumen guardado\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERANDO TABLA DETALLADA POR ESCENARIO\n",
      "================================================================================\n",
      "  Procesando detalle de: AREPD\n",
      "  Procesando detalle de: AV-MCPS\n",
      "  Procesando detalle de: Block Bootstrapping\n",
      "  Procesando detalle de: DeepAR\n",
      "  Procesando detalle de: EnCQR-LSTM\n",
      "  Procesando detalle de: LSPM\n",
      "  Procesando detalle de: LSPMW\n",
      "  Procesando detalle de: MCPS\n",
      "  Procesando detalle de: Sieve Bootstrap\n",
      "\n",
      "✓ DETALLE GUARDADO EN: Resultados_analisis\\Simulacion_diff\\DETALLE_Escenarios_ConDiff_vs_SinDiff_Bonferroni.xlsx\n",
      "\n",
      "\n",
      "=== Generando gráficos de barras con valores por d ===\n",
      "\n",
      "=== Generando Heatmap d vs Modelo ===\n",
      "\n",
      "================================================================================\n",
      "✓ ANÁLISIS COMPLETADO EXITOSAMENTE\n",
      "✓ Resultados en: Resultados_analisis\\Simulacion_diff\n",
      "✓ Gráficos en: Resultados_analisis\\Simulacion_diff\\Graficos_Analisis\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.fft import fft\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Configuración inicial\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# ====================================================================================\n",
    "# TEST DIEBOLD-MARIANO CON FIXED-M ASYMPTOTICS\n",
    "# ====================================================================================\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano con fixed-smoothing asymptotics (Coroneo & Iacone, 2020)\n",
    "    \n",
    "    Usa Fixed-m asymptotics (kernel Daniell) que es más robusto en muestras pequeñas\n",
    "    y mantiene buen desempeño en muestras grandes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    errors1, errors2 : array-like\n",
    "        Errores de pronóstico (ECRPS) de los dos modelos\n",
    "    h : int\n",
    "        Horizonte de pronóstico (forecast horizon)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hln_dm_stat : float\n",
    "        Estadístico con fixed-m asymptotics\n",
    "    p_value : float\n",
    "        P-valor usando distribución t-Student con 2m grados de libertad\n",
    "    dm_stat : float\n",
    "        Estadístico DM original (para referencia)\n",
    "    \"\"\"\n",
    "    # Calcular diferencial de pérdida\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    if T < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    # Desviaciones de la media\n",
    "    u = d - d_bar\n",
    "    \n",
    "    # Fixed-m: bandwidth recomendado en el paper\n",
    "    m = max(1, int(np.floor(T**(1/3))))\n",
    "    \n",
    "    # Calcular periodograma\n",
    "    fft_u = fft(u)\n",
    "    periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "    \n",
    "    # WPE con kernel de Daniell: promedio de primeros m periodogramas\n",
    "    # (excluyendo frecuencia 0)\n",
    "    if m >= len(periodogram) - 1:\n",
    "        m = len(periodogram) - 2\n",
    "    \n",
    "    sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "    \n",
    "    if sigma_hat_sq <= 0:\n",
    "        # Fallback: usar varianza simple\n",
    "        sigma_hat_sq = np.var(d, ddof=1) / T\n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0, 0\n",
    "    \n",
    "    # Estadístico DM\n",
    "    dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "    \n",
    "    # Fixed-m asymptotics: límite es t-Student con 2m grados de libertad\n",
    "    df = 2 * m\n",
    "    hln_dm_stat = dm_stat\n",
    "    \n",
    "    # P-valor usando t-Student\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "# ====================================================================================\n",
    "# 1. PREPARACIÓN DE DIRECTORIOS\n",
    "# ====================================================================================\n",
    "output_dir = Path(\"./Resultados_analisis/Simulacion_diff\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "plots_dir = output_dir / \"Graficos_Analisis\"\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "path_excel = \"./datos/Simulacion/Diferenciado/resultados_140_ARIMA_AMBAS_MODALIDADES.xlsx\"\n",
    "try:\n",
    "    df = pd.read_excel(path_excel)\n",
    "    print(f\"✓ Datos cargados: {df.shape}\")\n",
    "    print(f\"✓ Columnas: {df.columns.tolist()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error crítico: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Identificar columnas\n",
    "var_cols = ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', 'Distribución', \n",
    "            'Varianza', 'Modalidad', 'Valor_Observado']\n",
    "model_cols = [col for col in df.columns if col not in var_cols]\n",
    "\n",
    "print(f\"✓ Modelos identificados: {model_cols}\")\n",
    "print(f\"✓ Valores únicos de d: {sorted(df['d'].unique())}\")\n",
    "\n",
    "# ====================================================================================\n",
    "# FUNCIÓN PRINCIPAL: ANÁLISIS MISMO MÉTODO CON/SIN DIFF POR ESCENARIO\n",
    "# ====================================================================================\n",
    "def run_within_method_comparison_by_scenario():\n",
    "    \"\"\"\n",
    "    Compara MISMO método en MISMO escenario: Con_Diff vs Sin_Diff\n",
    "    NUNCA compara entre métodos diferentes\n",
    "    \n",
    "    Formato salida:\n",
    "    Método | ECRPS sin diff | ECRPS con diff | Cambio % | % Escenarios Significativos\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISIS: MISMO MÉTODO, CON DIFF VS SIN DIFF POR ESCENARIO\")\n",
    "    print(\"CORRECCIÓN DE BONFERRONI APLICADA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Identificar escenarios únicos (combinaciones únicas de características)\n",
    "    scenario_cols = ['d', 'ARMA_base', 'Distribución', 'Varianza']\n",
    "    df['Escenario_ID'] = df[scenario_cols].astype(str).agg('|'.join, axis=1)\n",
    "    \n",
    "    unique_scenarios = df['Escenario_ID'].unique()\n",
    "    n_scenarios = len(unique_scenarios)\n",
    "    \n",
    "    # Corrección de Bonferroni\n",
    "    alpha_nominal = 0.05\n",
    "    alpha_bonferroni = alpha_nominal / n_scenarios\n",
    "    \n",
    "    print(f\"\\n✓ Escenarios únicos detectados: {n_scenarios}\")\n",
    "    print(f\"✓ α nominal: {alpha_nominal}\")\n",
    "    print(f\"✓ α Bonferroni: {alpha_bonferroni:.6f}\")\n",
    "    print(f\"✓ Criterio: p < {alpha_bonferroni:.6f} para significancia\\n\")\n",
    "    \n",
    "    # Almacenar resultados finales por método\n",
    "    final_results = []\n",
    "    \n",
    "    # Procesar cada método independientemente\n",
    "    for model in model_cols:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Procesando: {model}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        scenario_tests = []\n",
    "        \n",
    "        # Para cada escenario, comparar Con_Diff vs Sin_Diff del MISMO método\n",
    "        for scenario_id in unique_scenarios:\n",
    "            scenario_data = df[df['Escenario_ID'] == scenario_id]\n",
    "            \n",
    "            # Extraer errores del MISMO método en ambas modalidades\n",
    "            sin_diff_errors = scenario_data[scenario_data['Modalidad'] == 'SIN_DIFF'][model].values\n",
    "            con_diff_errors = scenario_data[scenario_data['Modalidad'] == 'CON_DIFF'][model].values\n",
    "            \n",
    "            # Validar que hay datos suficientes\n",
    "            if len(sin_diff_errors) < 2 or len(con_diff_errors) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Calcular promedios del escenario\n",
    "            mean_sin = sin_diff_errors.mean()\n",
    "            mean_con = con_diff_errors.mean()\n",
    "            \n",
    "            # Test DM: comparando MISMO método Con vs Sin Diff\n",
    "            dm_stat, p_value, _ = modified_diebold_mariano_test(sin_diff_errors, con_diff_errors, h=1)\n",
    "            \n",
    "            # ¿Es significativo con corrección Bonferroni?\n",
    "            is_significant_bonferroni = p_value < alpha_bonferroni\n",
    "            \n",
    "            # Guardar resultado del escenario\n",
    "            scenario_tests.append({\n",
    "                'escenario': scenario_id,\n",
    "                'mean_sin_diff': mean_sin,\n",
    "                'mean_con_diff': mean_con,\n",
    "                'dm_stat': dm_stat,\n",
    "                'p_value': p_value,\n",
    "                'significant_bonferroni': is_significant_bonferroni\n",
    "            })\n",
    "        \n",
    "        # Convertir a DataFrame\n",
    "        scenario_df = pd.DataFrame(scenario_tests)\n",
    "        \n",
    "        # Calcular métricas agregadas\n",
    "        n_total_scenarios = len(scenario_df)\n",
    "        n_significant = scenario_df['significant_bonferroni'].sum()\n",
    "        pct_significant = (n_significant / n_total_scenarios * 100) if n_total_scenarios > 0 else 0\n",
    "        \n",
    "        # Promedios globales (todos los escenarios)\n",
    "        global_mean_sin = scenario_df['mean_sin_diff'].mean()\n",
    "        global_mean_con = scenario_df['mean_con_diff'].mean()\n",
    "        global_change_pct = ((global_mean_sin - global_mean_con) / global_mean_sin * 100) if global_mean_sin != 0 else 0\n",
    "        \n",
    "        # Almacenar resultado del método\n",
    "        final_results.append({\n",
    "            'Método': model,\n",
    "            'ECRPS_Sin_Diff': global_mean_sin,\n",
    "            'ECRPS_Con_Diff': global_mean_con,\n",
    "            'Cambio_%': global_change_pct,\n",
    "            '%_Escenarios_Significativos': pct_significant,\n",
    "            'N_Escenarios_Significativos': int(n_significant),\n",
    "            'N_Escenarios_Total': n_total_scenarios\n",
    "        })\n",
    "        \n",
    "        print(f\"  ✓ Escenarios evaluados: {n_total_scenarios}\")\n",
    "        print(f\"  ✓ Escenarios significativos (Bonferroni): {n_significant} ({pct_significant:.1f}%)\")\n",
    "        print(f\"  ✓ ECRPS promedio Sin Diff: {global_mean_sin:.4f}\")\n",
    "        print(f\"  ✓ ECRPS promedio Con Diff: {global_mean_con:.4f}\")\n",
    "        print(f\"  ✓ Cambio porcentual: {global_change_pct:+.2f}%\")\n",
    "    \n",
    "    # Crear DataFrame final con resumen por método\n",
    "    summary_df = pd.DataFrame(final_results)\n",
    "    \n",
    "    # Ordenar por cambio porcentual (mejores primero)\n",
    "    summary_df = summary_df.sort_values('Cambio_%', ascending=False)\n",
    "    \n",
    "    # Guardar Excel con formato profesional\n",
    "    excel_path = output_dir / 'RESUMEN_ConDiff_vs_SinDiff_por_Metodo_Bonferroni.xlsx'\n",
    "    \n",
    "    with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "        # Hoja principal: Resumen\n",
    "        summary_df.to_excel(writer, sheet_name='Resumen_Por_Metodo', index=False)\n",
    "        \n",
    "        # Obtener objetos de formato\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Resumen_Por_Metodo']\n",
    "        \n",
    "        # Formatos\n",
    "        fmt_header = workbook.add_format({\n",
    "            'bold': True,\n",
    "            'bg_color': '#4472C4',\n",
    "            'font_color': 'white',\n",
    "            'align': 'center',\n",
    "            'valign': 'vcenter',\n",
    "            'border': 1,\n",
    "            'text_wrap': True\n",
    "        })\n",
    "        \n",
    "        fmt_green = workbook.add_format({\n",
    "            'bg_color': '#C6EFCE',\n",
    "            'font_color': '#006100',\n",
    "            'num_format': '0.00'\n",
    "        })\n",
    "        \n",
    "        fmt_red = workbook.add_format({\n",
    "            'bg_color': '#FFC7CE',\n",
    "            'font_color': '#9C0006',\n",
    "            'num_format': '0.00'\n",
    "        })\n",
    "        \n",
    "        fmt_number = workbook.add_format({'num_format': '0.0000'})\n",
    "        fmt_percent = workbook.add_format({'num_format': '0.00\"%\"'})\n",
    "        \n",
    "        # Aplicar formato condicional a Cambio_%\n",
    "        cambio_col_idx = summary_df.columns.get_loc('Cambio_%')\n",
    "        worksheet.conditional_format(\n",
    "            1, cambio_col_idx, len(summary_df), cambio_col_idx,\n",
    "            {'type': 'cell', 'criteria': '>', 'value': 0, 'format': fmt_green}\n",
    "        )\n",
    "        worksheet.conditional_format(\n",
    "            1, cambio_col_idx, len(summary_df), cambio_col_idx,\n",
    "            {'type': 'cell', 'criteria': '<', 'value': 0, 'format': fmt_red}\n",
    "        )\n",
    "        \n",
    "        # Formato condicional a % Escenarios Significativos (escala de color)\n",
    "        sig_col_idx = summary_df.columns.get_loc('%_Escenarios_Significativos')\n",
    "        worksheet.conditional_format(\n",
    "            1, sig_col_idx, len(summary_df), sig_col_idx,\n",
    "            {\n",
    "                'type': '3_color_scale',\n",
    "                'min_color': '#F8696B',\n",
    "                'mid_color': '#FFEB84',\n",
    "                'max_color': '#63BE7B'\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Ajustar anchos de columna\n",
    "        worksheet.set_column('A:A', 22)  # Método\n",
    "        worksheet.set_column('B:D', 16)  # ECRPS y Cambio\n",
    "        worksheet.set_column('E:E', 28)  # % Escenarios Significativos\n",
    "        worksheet.set_column('F:G', 22)  # N Escenarios\n",
    "        \n",
    "        # Hoja 2: Información metodológica\n",
    "        method_info = pd.DataFrame({\n",
    "            'Parámetro': [\n",
    "                'Tipo de comparación',\n",
    "                'Alpha nominal',\n",
    "                'Alpha Bonferroni',\n",
    "                'Número de escenarios',\n",
    "                'Test estadístico',\n",
    "                'Corrección múltiple',\n",
    "                'Interpretación Cambio %',\n",
    "                'Interpretación % Sig'\n",
    "            ],\n",
    "            'Valor': [\n",
    "                'Mismo método: Con Diff vs Sin Diff en cada escenario',\n",
    "                alpha_nominal,\n",
    "                f'{alpha_bonferroni:.6f}',\n",
    "                n_scenarios,\n",
    "                'Diebold-Mariano modificado (Fixed-m asymptotics)',\n",
    "                'Bonferroni',\n",
    "                'Positivo = Con Diff mejora | Negativo = Sin Diff mejor',\n",
    "                'Porcentaje de escenarios donde diferencia es estadísticamente significativa'\n",
    "            ]\n",
    "        })\n",
    "        method_info.to_excel(writer, sheet_name='Metodologia', index=False)\n",
    "        \n",
    "        worksheet_info = writer.sheets['Metodologia']\n",
    "        worksheet_info.set_column('A:A', 25)\n",
    "        worksheet_info.set_column('B:B', 60)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"✓ RESUMEN GUARDADO EN: {excel_path}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# ====================================================================================\n",
    "# FUNCIÓN: TABLA DETALLADA POR MÉTODO Y ESCENARIO\n",
    "# ====================================================================================\n",
    "def generate_detailed_scenario_breakdown():\n",
    "    \"\"\"\n",
    "    Genera tabla detallada mostrando cada escenario individual por método\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERANDO TABLA DETALLADA POR ESCENARIO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Identificar escenarios\n",
    "    scenario_cols = ['d', 'ARMA_base', 'Distribución', 'Varianza']\n",
    "    df['Escenario_ID'] = df[scenario_cols].astype(str).agg('|'.join, axis=1)\n",
    "    \n",
    "    unique_scenarios = df['Escenario_ID'].unique()\n",
    "    n_scenarios = len(unique_scenarios)\n",
    "    alpha_bonferroni = 0.05 / n_scenarios\n",
    "    \n",
    "    excel_path = output_dir / 'DETALLE_Escenarios_ConDiff_vs_SinDiff_Bonferroni.xlsx'\n",
    "    \n",
    "    with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "        for model in model_cols:\n",
    "            print(f\"  Procesando detalle de: {model}\")\n",
    "            \n",
    "            detailed_rows = []\n",
    "            \n",
    "            for scenario_id in unique_scenarios:\n",
    "                scenario_data = df[df['Escenario_ID'] == scenario_id]\n",
    "                \n",
    "                # Obtener características del escenario\n",
    "                d_val = scenario_data['d'].iloc[0]\n",
    "                arma = scenario_data['ARMA_base'].iloc[0]\n",
    "                dist = scenario_data['Distribución'].iloc[0]\n",
    "                var_val = scenario_data['Varianza'].iloc[0]\n",
    "                \n",
    "                # Comparar MISMO método: Con vs Sin Diff\n",
    "                sin_diff = scenario_data[scenario_data['Modalidad'] == 'SIN_DIFF'][model].values\n",
    "                con_diff = scenario_data[scenario_data['Modalidad'] == 'CON_DIFF'][model].values\n",
    "                \n",
    "                if len(sin_diff) < 2 or len(con_diff) < 2:\n",
    "                    continue\n",
    "                \n",
    "                mean_sin = sin_diff.mean()\n",
    "                mean_con = con_diff.mean()\n",
    "                cambio_pct = ((mean_sin - mean_con) / mean_sin * 100) if mean_sin != 0 else 0\n",
    "                \n",
    "                dm_stat, p_value, _ = modified_diebold_mariano_test(sin_diff, con_diff, h=1)\n",
    "                is_sig = p_value < alpha_bonferroni\n",
    "                \n",
    "                detailed_rows.append({\n",
    "                    'd': d_val,\n",
    "                    'ARMA_base': arma,\n",
    "                    'Distribución': dist,\n",
    "                    'Varianza': var_val,\n",
    "                    'ECRPS_Sin_Diff': mean_sin,\n",
    "                    'ECRPS_Con_Diff': mean_con,\n",
    "                    'Cambio_%': cambio_pct,\n",
    "                    'DM_Stat': dm_stat,\n",
    "                    'p_value': p_value,\n",
    "                    'Sig_Bonferroni': 'Sí' if is_sig else 'No'\n",
    "                })\n",
    "            \n",
    "            detail_df = pd.DataFrame(detailed_rows)\n",
    "            detail_df = detail_df.sort_values(['d', 'Cambio_%'], ascending=[True, False])\n",
    "            \n",
    "            sheet_name = model[:31]\n",
    "            detail_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            \n",
    "            # Formato condicional\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "            \n",
    "            fmt_green = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})\n",
    "            fmt_red = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})\n",
    "            \n",
    "            cambio_col = detail_df.columns.get_loc('Cambio_%')\n",
    "            worksheet.conditional_format(\n",
    "                1, cambio_col, len(detail_df), cambio_col,\n",
    "                {'type': 'cell', 'criteria': '>', 'value': 0, 'format': fmt_green}\n",
    "            )\n",
    "            worksheet.conditional_format(\n",
    "                1, cambio_col, len(detail_df), cambio_col,\n",
    "                {'type': 'cell', 'criteria': '<', 'value': 0, 'format': fmt_red}\n",
    "            )\n",
    "    \n",
    "    print(f\"\\n✓ DETALLE GUARDADO EN: {excel_path}\\n\")\n",
    "\n",
    "# ====================================================================================\n",
    "# FUNCIÓN: GRÁFICO DE RESUMEN\n",
    "# ====================================================================================\n",
    "def plot_comparison_summary(summary_df):\n",
    "    \"\"\"\n",
    "    Genera gráfico dual mostrando:\n",
    "    1. Cambio porcentual por método\n",
    "    2. % de escenarios significativos por método\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Generando gráfico de resumen ===\")\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Panel 1: Cambio Porcentual\n",
    "    colors_cambio = ['#2ecc71' if x > 0 else '#e74c3c' for x in summary_df['Cambio_%']]\n",
    "    bars1 = ax1.barh(summary_df['Método'], summary_df['Cambio_%'],\n",
    "                     color=colors_cambio, edgecolor='black', linewidth=1.2, alpha=0.85)\n",
    "    \n",
    "    ax1.bar_label(bars1, padding=5, fmt='%.2f%%', fontweight='bold', fontsize=9)\n",
    "    ax1.axvline(0, color='black', linewidth=2, linestyle='--', alpha=0.7)\n",
    "    ax1.set_xlabel('Cambio Porcentual (%)', fontweight='bold', fontsize=12)\n",
    "    ax1.set_title('Mejora con Diferenciación\\n(Con Diff vs Sin Diff)', \n",
    "                  fontweight='bold', fontsize=13)\n",
    "    ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    ax1.set_axisbelow(True)\n",
    "    \n",
    "    # Panel 2: % Escenarios Significativos\n",
    "    colors_sig = plt.cm.RdYlGn(summary_df['%_Escenarios_Significativos'] / 100)\n",
    "    bars2 = ax2.barh(summary_df['Método'], summary_df['%_Escenarios_Significativos'],\n",
    "                     color=colors_sig, edgecolor='black', linewidth=1.2, alpha=0.85)\n",
    "    \n",
    "    ax2.bar_label(bars2, padding=5, fmt='%.1f%%', fontweight='bold', fontsize=9)\n",
    "    ax2.set_xlabel('% Escenarios Significativos (Bonferroni)', fontweight='bold', fontsize=12)\n",
    "    ax2.set_title('Robustez Estadística\\n(p < α Bonferroni)', \n",
    "                  fontweight='bold', fontsize=13)\n",
    "    ax2.set_xlim(0, 100)\n",
    "    ax2.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    ax2.set_axisbelow(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'RESUMEN_ConDiff_vs_SinDiff_Comparacion.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"✓ Gráfico de resumen guardado\\n\")\n",
    "\n",
    "# ====================================================================================\n",
    "# FUNCIONES ORIGINALES MANTENIDAS (OPCIONAL)\n",
    "# ====================================================================================\n",
    "def plot_individual_comparisons():\n",
    "    print(\"\\n=== Generando gráficos de barras con valores por d ===\")\n",
    "    \n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        stats_list = []\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        \n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "            mejora = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "            stats_list.append({'Modelo': model, 'Sin': sin, 'Con': con, 'Mejora': mejora})\n",
    "        \n",
    "        df_stats = pd.DataFrame(stats_list).sort_values(by='Mejora', ascending=False)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(14, 6))\n",
    "        x = np.arange(len(df_stats))\n",
    "        width = 0.35\n",
    "        \n",
    "        b1 = ax.bar(x - width/2, df_stats['Sin'], width, label='Sin Dif.', \n",
    "                    color='#e74c3c', edgecolor='black', alpha=0.8)\n",
    "        b2 = ax.bar(x + width/2, df_stats['Con'], width, label='Con Dif.', \n",
    "                    color='#2ecc71', edgecolor='black', alpha=0.8)\n",
    "        \n",
    "        ax.bar_label(b1, padding=3, fmt='%.3f', fontsize=7, rotation=45)\n",
    "        ax.bar_label(b2, padding=3, fmt='%.3f', fontsize=7, rotation=45)\n",
    "        \n",
    "        ax.set_title(f'ECRPS Promedio por Modelo (d={d_val})', fontweight='bold', fontsize=12)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(df_stats['Modelo'], rotation=45, ha='right')\n",
    "        ax.set_ylabel('ECRPS')\n",
    "        ax.legend()\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / f'1.1_barras_ecrps_d{d_val}.png')\n",
    "        plt.close()\n",
    "\n",
    "def plot_heatmap_d_vs_modelo():\n",
    "    print(\"\\n=== Generando Heatmap d vs Modelo ===\")\n",
    "    \n",
    "    results = []\n",
    "    d_values = sorted(df['d'].unique())\n",
    "    \n",
    "    for d_val in d_values:\n",
    "        subset_d = df[df['d'] == d_val]\n",
    "        for model in model_cols:\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "            mejora = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "            results.append({'d': d_val, 'Modelo': model, 'Mejora_%': mejora})\n",
    "    \n",
    "    df_mejora = pd.DataFrame(results)\n",
    "    pivot = df_mejora.pivot(index='Modelo', columns='d', values='Mejora_%')\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(pivot, annot=True, fmt=\".1f\", cmap=\"RdYlGn\", center=0, \n",
    "                cbar_kws={'label': 'Mejora (%)'}, linewidths=0.5)\n",
    "    plt.title(\"Mejora Porcentual (%): Modelo vs Valor de d\", fontweight='bold', fontsize=14)\n",
    "    plt.xlabel(\"Valor de d (Grado de diferenciación)\", fontweight='bold')\n",
    "    plt.ylabel(\"Modelo\", fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / '2_heatmap_d_vs_modelo.png')\n",
    "    plt.close()\n",
    "    \n",
    "    pivot.to_excel(output_dir / '2_tabla_d_vs_modelo.xlsx')\n",
    "\n",
    "# ====================================================================================\n",
    "# EJECUCIÓN PRINCIPAL\n",
    "# ====================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISIS: MISMO MÉTODO CON DIFF VS SIN DIFF\")\n",
    "    print(\"CORRECCIÓN DE BONFERRONI POR ESCENARIOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # FUNCIÓN PRINCIPAL: Análisis mismo método Con vs Sin Diff\n",
    "    summary_df = run_within_method_comparison_by_scenario()\n",
    "    \n",
    "    # Gráfico de resumen\n",
    "    plot_comparison_summary(summary_df)\n",
    "    \n",
    "    # Tabla detallada por escenario\n",
    "    generate_detailed_scenario_breakdown()\n",
    "    \n",
    "    # Análisis complementarios (opcional)\n",
    "    plot_individual_comparisons()\n",
    "    plot_heatmap_d_vs_modelo()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✓ ANÁLISIS COMPLETADO EXITOSAMENTE\")\n",
    "    print(f\"✓ Resultados en: {output_dir}\")\n",
    "    print(f\"✓ Gráficos en: {plots_dir}\")\n",
    "    print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e6b598",
   "metadata": {},
   "source": [
    "## Aumento d ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b73a5d",
   "metadata": {},
   "source": [
    "### Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d843823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "TEST DIEBOLD-MARIANO MODIFICADO (HLN): Comparación SIN_DIFF vs CON_DIFF por valor de d\n",
      "====================================================================================================\n",
      "\n",
      "H0: No hay diferencia significativa entre las modalidades\n",
      "H1: Hay diferencia significativa entre las modalidades\n",
      "\n",
      "Significancia: *** p<0.01, ** p<0.05, * p<0.10, No = no significativo\n",
      "\n",
      "\n",
      " d  N_obs  ECRPS_SIN_DIFF  ECRPS_CON_DIFF    Diferencia  DM_stat  HLN-DM_stat  p_valor Significativo\n",
      " 1   1680    5.495070e-01    5.485800e-01  9.280000e-04   0.5334       0.5334   0.6067            No\n",
      " 2   1680    2.884661e+01    2.883279e+01  1.382000e-02   0.8679       0.8679   0.4022            No\n",
      " 3   1680    2.725984e+01    2.726032e+01 -4.790000e-04  -0.0186      -0.0186   0.9856            No\n",
      " 4   1680    2.704997e+01    2.704544e+01  4.532000e-03   0.1216       0.1216   0.9066            No\n",
      " 5   1680    3.451632e+01    2.821125e+01  6.305071e+00   1.8941       1.8941   0.0676             *\n",
      " 6   1680    1.400979e+03    2.663349e+01  1.374346e+03   4.4940       4.4940   0.0000           ***\n",
      " 7   1680    9.737277e+04    1.570675e+03  9.580209e+04   5.2118       5.2118   0.0000           ***\n",
      "10   1680    1.502699e+09    6.795862e+07  1.434741e+09   6.5190       6.5190   0.0000           ***\n",
      "\n",
      "====================================================================================================\n",
      "RESUMEN\n",
      "====================================================================================================\n",
      "\n",
      "Total de comparaciones: 8\n",
      "Diferencias significativas: 4 (50.0%)\n",
      "No significativas: 4 (50.0%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.fft import fft\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de gráficos\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# ====================================================================================\n",
    "# CREAR DIRECTORIOS\n",
    "# ====================================================================================\n",
    "output_dir = Path(\"./Resultados_analisis/Sensibilidad_d\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "plots_dir = output_dir / \"Graficos\"\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ====================================================================================\n",
    "# TEST DIEBOLD-MARIANO CON FIXED-M ASYMPTOTICS\n",
    "# ====================================================================================\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano con fixed-smoothing asymptotics\n",
    "    \"\"\"\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    if T < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    u = d - d_bar\n",
    "    m = max(1, int(np.floor(T**(1/3))))\n",
    "    \n",
    "    fft_u = fft(u)\n",
    "    periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "    \n",
    "    if m >= len(periodogram) - 1:\n",
    "        m = len(periodogram) - 2\n",
    "    \n",
    "    sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "    \n",
    "    if sigma_hat_sq <= 0:\n",
    "        sigma_hat_sq = np.var(d, ddof=1) / T\n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0, 0\n",
    "    \n",
    "    dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "    df = 2 * m\n",
    "    hln_dm_stat = dm_stat\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "# ====================================================================================\n",
    "# CARGAR DATOS\n",
    "# ====================================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS DE SENSIBILIDAD AL INCREMENTO DE d\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "base_path = \"./datos/Simulacion/Multi_D/resultados_ARIMA_d1_a_d10_DOBLE_MODALIDAD_COMPLETO.xlsx\"\n",
    "base = pd.read_excel(base_path)\n",
    "\n",
    "# Modelos a analizar\n",
    "modelos_analizar = ['Sieve Bootstrap', 'LSPM', 'LSPMW', 'AV-MCPS', 'MCPS']\n",
    "\n",
    "print(f\"\\n✓ Datos cargados: {base.shape}\")\n",
    "print(f\"✓ Modelos a analizar: {modelos_analizar}\")\n",
    "\n",
    "# Identificar columnas de características\n",
    "caracteristicas = ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', \n",
    "                   'Distribución', 'Varianza', 'Modalidad']\n",
    "\n",
    "# ====================================================================================\n",
    "# FUNCIÓN: ANÁLISIS POR ESCENARIOS CON DM TEST\n",
    "# ====================================================================================\n",
    "def analizar_modelo_por_escenarios(datos, modelo_nombre):\n",
    "    \"\"\"\n",
    "    Analiza un modelo específico comparando Con Diff vs Sin Diff por escenario\n",
    "    Retorna matriz de p-valores: escenarios x valores de d\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Analizando: {modelo_nombre}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Columnas necesarias\n",
    "    cols_necesarias = caracteristicas + [modelo_nombre]\n",
    "    datos_modelo = datos[cols_necesarias].copy()\n",
    "    \n",
    "    # Crear identificador de escenario (sin incluir d)\n",
    "    escenario_cols = ['ARMA_base', 'Distribución', 'Varianza']\n",
    "    datos_modelo['Escenario'] = datos_modelo[escenario_cols].astype(str).agg('-', axis=1)\n",
    "    \n",
    "    # Obtener valores únicos\n",
    "    valores_d = sorted(datos_modelo['d'].unique())\n",
    "    escenarios = sorted(datos_modelo['Escenario'].unique())\n",
    "    \n",
    "    n_escenarios = len(escenarios)\n",
    "    n_valores_d = len(valores_d)\n",
    "    \n",
    "    print(f\"  ✓ Valores de d: {valores_d}\")\n",
    "    print(f\"  ✓ Número de escenarios: {n_escenarios}\")\n",
    "    \n",
    "    # Matriz de p-valores\n",
    "    matriz_pvalores = np.full((n_escenarios, n_valores_d), np.nan)\n",
    "    \n",
    "    # Matriz de diferencias medias (para contexto)\n",
    "    matriz_diferencias = np.full((n_escenarios, n_valores_d), np.nan)\n",
    "    \n",
    "    # Iterar por cada combinación de escenario y d\n",
    "    for i, escenario in enumerate(escenarios):\n",
    "        for j, d_val in enumerate(valores_d):\n",
    "            # Filtrar datos\n",
    "            mask = (datos_modelo['Escenario'] == escenario) & (datos_modelo['d'] == d_val)\n",
    "            subset = datos_modelo[mask]\n",
    "            \n",
    "            if len(subset) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Separar por modalidad\n",
    "            sin_diff = subset[subset['Modalidad'] == 'SIN_DIFF'][modelo_nombre].values\n",
    "            con_diff = subset[subset['Modalidad'] == 'CON_DIFF'][modelo_nombre].values\n",
    "            \n",
    "            if len(sin_diff) < 2 or len(con_diff) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Test DM\n",
    "            _, p_value, _ = modified_diebold_mariano_test(sin_diff, con_diff, h=1)\n",
    "            \n",
    "            # Almacenar\n",
    "            matriz_pvalores[i, j] = p_value\n",
    "            matriz_diferencias[i, j] = sin_diff.mean() - con_diff.mean()\n",
    "    \n",
    "    # Crear DataFrames\n",
    "    df_pvalores = pd.DataFrame(\n",
    "        matriz_pvalores,\n",
    "        index=escenarios,\n",
    "        columns=[f'd={d}' for d in valores_d]\n",
    "    )\n",
    "    \n",
    "    df_diferencias = pd.DataFrame(\n",
    "        matriz_diferencias,\n",
    "        index=escenarios,\n",
    "        columns=[f'd={d}' for d in valores_d]\n",
    "    )\n",
    "    \n",
    "    return df_pvalores, df_diferencias, valores_d, escenarios\n",
    "\n",
    "# ====================================================================================\n",
    "# FUNCIÓN: GENERAR HEATMAP DE P-VALORES\n",
    "# ====================================================================================\n",
    "def plot_pvalor_heatmap(df_pvalores, modelo_nombre, valores_d, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Genera heatmap de p-valores con corrección Bonferroni\n",
    "    \"\"\"\n",
    "    n_comparisons = df_pvalores.notna().sum().sum()\n",
    "    alpha_bonferroni = alpha / n_comparisons if n_comparisons > 0 else alpha\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, max(10, len(df_pvalores) * 0.3)))\n",
    "    \n",
    "    # Crear máscara para valores faltantes\n",
    "    mask = df_pvalores.isna()\n",
    "    \n",
    "    # Heatmap con escala logarítmica invertida\n",
    "    # Valores pequeños (significativos) en verde, grandes en rojo\n",
    "    sns.heatmap(\n",
    "        -np.log10(df_pvalores + 1e-300),  # Transformación logarítmica\n",
    "        mask=mask,\n",
    "        cmap='RdYlGn',\n",
    "        center=-np.log10(alpha_bonferroni),\n",
    "        cbar_kws={'label': '-log₁₀(p-valor)'},\n",
    "        linewidths=0.5,\n",
    "        linecolor='gray',\n",
    "        ax=ax,\n",
    "        vmin=-np.log10(0.5),\n",
    "        vmax=-np.log10(1e-10),\n",
    "        annot=False  # Sin anotaciones para evitar saturación\n",
    "    )\n",
    "    \n",
    "    # Línea de referencia para α Bonferroni\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.axhline(-np.log10(alpha_bonferroni), color='blue', linewidth=2, linestyle='--')\n",
    "    cbar.ax.text(\n",
    "        0.5, -np.log10(alpha_bonferroni), \n",
    "        f'  α_Bonf={alpha_bonferroni:.2e}',\n",
    "        va='center', ha='left', color='blue', fontweight='bold', fontsize=8\n",
    "    )\n",
    "    \n",
    "    # Títulos y etiquetas\n",
    "    ax.set_title(\n",
    "        f'Matriz de P-valores: {modelo_nombre}\\n'\n",
    "        f'Con Diff vs Sin Diff por Escenario y Valor de d\\n'\n",
    "        f'(Verde = Significativo | Rojo = No Significativo)',\n",
    "        fontsize=13, fontweight='bold', pad=15\n",
    "    )\n",
    "    ax.set_xlabel('Valor de d', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Escenario (Config-Dist-Var)', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Rotar etiquetas\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0, ha='center')\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Guardar\n",
    "    filename = f'HEATMAP_pvalores_{modelo_nombre.replace(\" \", \"_\")}.png'\n",
    "    plt.savefig(plots_dir / filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  ✓ Heatmap guardado: {filename}\")\n",
    "\n",
    "# ====================================================================================\n",
    "# FUNCIÓN: GRÁFICO RESUMEN DE SIGNIFICANCIA\n",
    "# ====================================================================================\n",
    "def plot_resumen_significancia(resultados_resumen, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Gráfico de barras mostrando % de escenarios significativos por modelo y d\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    \n",
    "    modelos = list(resultados_resumen.keys())\n",
    "    valores_d = list(resultados_resumen[modelos[0]].keys())\n",
    "    \n",
    "    x = np.arange(len(valores_d))\n",
    "    width = 0.15\n",
    "    \n",
    "    for i, modelo in enumerate(modelos):\n",
    "        porcentajes = [resultados_resumen[modelo][d] for d in valores_d]\n",
    "        offset = width * (i - len(modelos)/2 + 0.5)\n",
    "        \n",
    "        bars = ax.bar(x + offset, porcentajes, width, label=modelo, alpha=0.85, edgecolor='black')\n",
    "        \n",
    "        # Etiquetas en barras (solo si > 5%)\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if height > 5:\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.0f}%',\n",
    "                    ha='center', va='bottom', fontsize=7, fontweight='bold'\n",
    "                )\n",
    "    \n",
    "    ax.set_xlabel('Valor de d', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('% Escenarios Significativos', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(\n",
    "        'Porcentaje de Escenarios con Diferencias Significativas\\n'\n",
    "        f'(Con Diff vs Sin Diff, α Bonferroni por modelo)',\n",
    "        fontsize=13, fontweight='bold'\n",
    "    )\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'd={d}' for d in valores_d])\n",
    "    ax.legend(loc='upper right', fontsize=9)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'RESUMEN_Significancia_por_d.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\n✓ Gráfico de resumen guardado\")\n",
    "\n",
    "# ====================================================================================\n",
    "# FUNCIÓN: GRÁFICO DE DIFERENCIAS PROMEDIO POR d (MEJORADO)\n",
    "# ====================================================================================\n",
    "def plot_diferencias_promedio_mejorado(base, modelos_analizar):\n",
    "    \"\"\"\n",
    "    Gráfico de líneas mejorado mostrando diferencia promedio por d\n",
    "    Evita superposición de etiquetas\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    valores_d = sorted(base['d'].unique())\n",
    "    \n",
    "    for modelo in modelos_analizar:\n",
    "        diferencias_por_d = []\n",
    "        \n",
    "        for d_val in valores_d:\n",
    "            subset = base[base['d'] == d_val]\n",
    "            sin_diff = subset[subset['Modalidad'] == 'SIN_DIFF'][modelo].mean()\n",
    "            con_diff = subset[subset['Modalidad'] == 'CON_DIFF'][modelo].mean()\n",
    "            dif = sin_diff - con_diff\n",
    "            diferencias_por_d.append(dif)\n",
    "        \n",
    "        # Línea con marcadores\n",
    "        ax.plot(valores_d, diferencias_por_d, marker='o', linewidth=2.5, \n",
    "                markersize=8, label=modelo, alpha=0.85)\n",
    "    \n",
    "    ax.axhline(0, color='black', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    ax.set_xlabel('Valor de d', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Diferencia ECRPS (Sin Diff - Con Diff)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(\n",
    "        'Evolución de la Mejora con Diferenciación según Valor de d\\n'\n",
    "        '(Valores positivos indican mejora con diferenciación)',\n",
    "        fontsize=13, fontweight='bold'\n",
    "    )\n",
    "    ax.legend(loc='best', fontsize=10, framealpha=0.95)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax.set_xticks(valores_d)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / 'DIFERENCIAS_promedio_por_d_MEJORADO.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"✓ Gráfico de diferencias mejorado guardado\")\n",
    "\n",
    "# ====================================================================================\n",
    "# FUNCIÓN: TABLA RESUMEN EN EXCEL\n",
    "# ====================================================================================\n",
    "def guardar_resumen_excel(todos_resultados, output_dir):\n",
    "    \"\"\"\n",
    "    Guarda resumen consolidado en Excel\n",
    "    \"\"\"\n",
    "    excel_path = output_dir / 'RESUMEN_Analisis_Sensibilidad_d.xlsx'\n",
    "    \n",
    "    with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "        for modelo, (df_pvalores, df_diferencias) in todos_resultados.items():\n",
    "            # Hoja de p-valores\n",
    "            sheet_name_p = f'{modelo[:25]}_pvalores'\n",
    "            df_pvalores.to_excel(writer, sheet_name=sheet_name_p)\n",
    "            \n",
    "            # Hoja de diferencias\n",
    "            sheet_name_d = f'{modelo[:25]}_diferencias'\n",
    "            df_diferencias.to_excel(writer, sheet_name=sheet_name_d)\n",
    "            \n",
    "            # Formato condicional en p-valores\n",
    "            workbook = writer.book\n",
    "            worksheet_p = writer.sheets[sheet_name_p]\n",
    "            \n",
    "            # Formato para p < 0.05\n",
    "            fmt_sig = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})\n",
    "            \n",
    "            # Aplicar formato (aproximado, necesitaría cálculo exacto de Bonferroni)\n",
    "            for row in range(1, len(df_pvalores) + 1):\n",
    "                for col in range(1, len(df_pvalores.columns) + 1):\n",
    "                    worksheet_p.conditional_format(\n",
    "                        row, col, row, col,\n",
    "                        {'type': 'cell', 'criteria': '<', 'value': 0.05, 'format': fmt_sig}\n",
    "                    )\n",
    "    \n",
    "    print(f\"\\n✓ Excel guardado: {excel_path}\")\n",
    "\n",
    "# ====================================================================================\n",
    "# EJECUCIÓN PRINCIPAL\n",
    "# ====================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Almacenar resultados\n",
    "    todos_resultados = {}\n",
    "    resultados_resumen = {}\n",
    "    \n",
    "    # Analizar cada modelo\n",
    "    for modelo in modelos_analizar:\n",
    "        df_pvalores, df_diferencias, valores_d, escenarios = analizar_modelo_por_escenarios(\n",
    "            base, modelo\n",
    "        )\n",
    "        \n",
    "        # Guardar resultados\n",
    "        todos_resultados[modelo] = (df_pvalores, df_diferencias)\n",
    "        \n",
    "        # Generar heatmap\n",
    "        plot_pvalor_heatmap(df_pvalores, modelo, valores_d)\n",
    "        \n",
    "        # Calcular % significativos por d\n",
    "        alpha = 0.05\n",
    "        n_comparisons = df_pvalores.notna().sum().sum()\n",
    "        alpha_bonferroni = alpha / n_comparisons if n_comparisons > 0 else alpha\n",
    "        \n",
    "        resultados_resumen[modelo] = {}\n",
    "        for col in df_pvalores.columns:\n",
    "            n_sig = (df_pvalores[col] < alpha_bonferroni).sum()\n",
    "            n_total = df_pvalores[col].notna().sum()\n",
    "            pct = (n_sig / n_total * 100) if n_total > 0 else 0\n",
    "            d_val = int(col.split('=')[1])\n",
    "            resultados_resumen[modelo][d_val] = pct\n",
    "    \n",
    "    # Gráficos complementarios\n",
    "    plot_resumen_significancia(resultados_resumen)\n",
    "    plot_diferencias_promedio_mejorado(base, modelos_analizar)\n",
    "    \n",
    "    # Guardar Excel\n",
    "    guardar_resumen_excel(todos_resultados, output_dir)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✓ ANÁLISIS COMPLETADO\")\n",
    "    print(f\"✓ Resultados en: {output_dir}\")\n",
    "    print(f\"✓ Gráficos en: {plots_dir}\")\n",
    "    print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6425b70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "TEST DIEBOLD-MARIANO MODIFICADO (HLN): Comparación Sin Diferenciación (No) vs Con Diferenciación (Si)\n",
      "========================================================================================================================\n",
      "\n",
      "H0: No hay diferencia significativa entre aplicar o no diferenciación\n",
      "H1: Hay diferencia significativa entre aplicar o no diferenciación\n",
      "\n",
      "Significancia: *** p<0.01, ** p<0.05, * p<0.10, No = no significativo\n",
      "========================================================================================================================\n",
      "\n",
      "\n",
      "             Método  N_obs  ECRPS_Sin_Diff  ECRPS_Con_Diff  Diferencia  DM_stat  HLN-DM_stat  p_valor Significativo\n",
      "Block Bootstrapping   1680       11.251601        0.666133   10.585468   5.9736       5.9736   0.0000           ***\n",
      "    Sieve Bootstrap   1680        0.547481        0.546020    0.001461   1.1882       1.1882   0.2515            No\n",
      "               LSPM   1680        1.064804        0.648039    0.416766  14.2307      14.2307   0.0000           ***\n",
      "              LSPMW   1680        3.079645        0.767172    2.312473  10.3870      10.3870   0.0000           ***\n",
      "              AREPD   1680       10.031183        0.704149    9.327035   5.7364       5.7364   0.0000           ***\n",
      "               MCPS   1680        3.218168        0.677471    2.540697   5.1990       5.1990   0.0000           ***\n",
      "            AV-MCPS   1680        3.324007        0.654257    2.669750   5.8485       5.8485   0.0000           ***\n",
      "             DeepAR   1680        4.329124        0.561822    3.767302   3.4823       3.4823   0.0008           ***\n",
      "         EnCQR-LSTM   1680        6.112344        0.880288    5.232056   6.5596       6.5596   0.0000           ***\n",
      "\n",
      "========================================================================================================================\n",
      "RESUMEN\n",
      "========================================================================================================================\n",
      "\n",
      "Total de métodos comparados: 9\n",
      "Diferencias significativas: 8 (88.9%)\n",
      "No significativas: 1 (11.1%)\n",
      "\n",
      "Métodos con diferencias significativas:\n",
      "             Método Significativo  p_valor\n",
      "Block Bootstrapping           ***   0.0000\n",
      "               LSPM           ***   0.0000\n",
      "              LSPMW           ***   0.0000\n",
      "              AREPD           ***   0.0000\n",
      "               MCPS           ***   0.0000\n",
      "            AV-MCPS           ***   0.0000\n",
      "             DeepAR           ***   0.0008\n",
      "         EnCQR-LSTM           ***   0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Cargar datos\n",
    "base = pd.read_excel(\"./datos/Simulacion/Diferenciado/resultados_UNION_ARIMA.xlsx\")\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano con fixed-smoothing asymptotics (Coroneo & Iacone, 2020)\n",
    "    \n",
    "    Implementa dos enfoques:\n",
    "    1. Fixed-b asymptotics con kernel de Bartlett\n",
    "    2. Fixed-m asymptotics con kernel de Daniell\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    errors1, errors2 : array-like\n",
    "        Errores de pronóstico (ECRPS) de los dos modelos\n",
    "    h : int\n",
    "        Horizonte de pronóstico (forecast horizon)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    hln_dm_stat : float\n",
    "        Estadístico con fixed-smoothing asymptotics\n",
    "    p_value : float\n",
    "        P-valor usando distribución apropiada\n",
    "    dm_stat : float\n",
    "        Estadístico DM original (para referencia)\n",
    "    \"\"\"\n",
    "    # Calcular diferencial de pérdida\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    if T < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    # Desviaciones de la media\n",
    "    u = d - d_bar\n",
    "    \n",
    "    # Elegir método según tamaño de muestra\n",
    "    if T >= 80:\n",
    "        # Fixed-b con kernel de Bartlett para muestras medianas/grandes\n",
    "        M = int(np.floor(T**(1/2)))  # Bandwidth recomendado\n",
    "        b = M / T\n",
    "        \n",
    "        # Calcular WCE con kernel de Bartlett\n",
    "        gamma_0 = np.mean(u**2)\n",
    "        gamma_sum = gamma_0\n",
    "        \n",
    "        for j in range(1, min(M, T)):\n",
    "            gamma_j = np.mean(u[j:] * u[:-j])\n",
    "            weight = 1 - j/M  # Kernel de Bartlett\n",
    "            gamma_sum += 2 * weight * gamma_j\n",
    "        \n",
    "        sigma_hat_sq = gamma_sum\n",
    "        \n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0, 0\n",
    "        \n",
    "        # Estadístico DM\n",
    "        dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "        \n",
    "        # Valor crítico fixed-b para Bartlett kernel (fórmula del paper)\n",
    "        # Para test de dos colas al 5%\n",
    "        alpha_0, alpha_1, alpha_2, alpha_3 = 1.9600, 2.9694, 0.4160, -0.5324\n",
    "        critical_value = alpha_0 + alpha_1*b + alpha_2*b**2 + alpha_3*b**3\n",
    "        \n",
    "        # P-valor aproximado usando la distribución límite\n",
    "        # Nota: esto es una aproximación, idealmente se simularía\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat) / (critical_value/1.96)))\n",
    "        \n",
    "        hln_dm_stat = dm_stat\n",
    "        \n",
    "    else:\n",
    "        # Fixed-m con kernel de Daniell para muestras pequeñas\n",
    "        m = int(np.floor(T**(1/3)))  # Bandwidth recomendado\n",
    "        \n",
    "        # Calcular periodograma\n",
    "        from scipy.fft import fft\n",
    "        \n",
    "        # FFT de las desviaciones\n",
    "        fft_u = fft(u)\n",
    "        periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "        \n",
    "        # WPE con kernel de Daniell (promedio de primeros m periodogramas)\n",
    "        sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "        \n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0, 0\n",
    "        \n",
    "        # Estadístico DM\n",
    "        dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "        \n",
    "        # Fixed-m asymptotics: límite es t-Student con 2m grados de libertad\n",
    "        df = 2 * m\n",
    "        hln_dm_stat = dm_stat\n",
    "        \n",
    "        # P-valor usando t-Student\n",
    "        p_value = 2 * (1 - stats.t.cdf(abs(hln_dm_stat), df))\n",
    "    \n",
    "    return hln_dm_stat, p_value, dm_stat\n",
    "\n",
    "\n",
    "# Separar por diferenciación\n",
    "sin_diff = base[base['Diferenciacion'] == 'No'].copy()\n",
    "con_diff = base[base['Diferenciacion'] == 'Si'].copy()\n",
    "\n",
    "# Métodos a comparar (todos excepto las columnas de configuración)\n",
    "metodos = ['Block Bootstrapping', 'Sieve Bootstrap', 'LSPM', 'LSPMW', \n",
    "           'AREPD', 'MCPS', 'AV-MCPS', 'DeepAR', 'EnCQR-LSTM']\n",
    "\n",
    "# Lista para almacenar resultados\n",
    "resultados = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"TEST DIEBOLD-MARIANO MODIFICADO (HLN): Comparación Sin Diferenciación (No) vs Con Diferenciación (Si)\")\n",
    "print(\"=\"*120)\n",
    "print(\"\\nH0: No hay diferencia significativa entre aplicar o no diferenciación\")\n",
    "print(\"H1: Hay diferencia significativa entre aplicar o no diferenciación\")\n",
    "print(\"\\nSignificancia: *** p<0.01, ** p<0.05, * p<0.10, No = no significativo\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "# Iterar sobre cada método\n",
    "for metodo in metodos:\n",
    "    # Obtener valores de ECRPS para cada modalidad\n",
    "    ecrps_sin = sin_diff[metodo].values\n",
    "    ecrps_con = con_diff[metodo].values\n",
    "    \n",
    "    # Verificar que ambas modalidades tengan datos\n",
    "    if len(ecrps_sin) == 0 or len(ecrps_con) == 0:\n",
    "        print(f\"\\nAdvertencia: {metodo} no tiene datos para ambas modalidades\")\n",
    "        continue\n",
    "    \n",
    "    # Verificar que tengan la misma longitud\n",
    "    if len(ecrps_sin) != len(ecrps_con):\n",
    "        print(f\"\\nAdvertencia: {metodo} tiene diferente número de observaciones\")\n",
    "        min_len = min(len(ecrps_sin), len(ecrps_con))\n",
    "        ecrps_sin = ecrps_sin[:min_len]\n",
    "        ecrps_con = ecrps_con[:min_len]\n",
    "    \n",
    "    # Calcular estadísticas descriptivas\n",
    "    ecrps_sin_mean = np.mean(ecrps_sin)\n",
    "    ecrps_con_mean = np.mean(ecrps_con)\n",
    "    diferencia = ecrps_sin_mean - ecrps_con_mean\n",
    "    \n",
    "    # Realizar test Diebold-Mariano modificado\n",
    "    hln_dm_stat, p_value, dm_stat = modified_diebold_mariano_test(ecrps_sin, ecrps_con, h=1)\n",
    "    \n",
    "    # Determinar significancia\n",
    "    if p_value < 0.01:\n",
    "        significativo = \"***\"\n",
    "    elif p_value < 0.05:\n",
    "        significativo = \"**\"\n",
    "    elif p_value < 0.10:\n",
    "        significativo = \"*\"\n",
    "    else:\n",
    "        significativo = \"No\"\n",
    "    \n",
    "    # Agregar a resultados\n",
    "    resultados.append({\n",
    "        'Método': metodo,\n",
    "        'N_obs': len(ecrps_sin),\n",
    "        'ECRPS_Sin_Diff': ecrps_sin_mean,\n",
    "        'ECRPS_Con_Diff': ecrps_con_mean,\n",
    "        'Diferencia': diferencia,\n",
    "        'DM_stat': dm_stat,\n",
    "        'HLN-DM_stat': hln_dm_stat,\n",
    "        'p_valor': p_value,\n",
    "        'Significativo': significativo\n",
    "    })\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "resultados_df = pd.DataFrame(resultados)\n",
    "\n",
    "# Formatear para mejor visualización\n",
    "resultados_df['ECRPS_Sin_Diff'] = resultados_df['ECRPS_Sin_Diff'].round(6)\n",
    "resultados_df['ECRPS_Con_Diff'] = resultados_df['ECRPS_Con_Diff'].round(6)\n",
    "resultados_df['Diferencia'] = resultados_df['Diferencia'].round(6)\n",
    "resultados_df['DM_stat'] = resultados_df['DM_stat'].round(4)\n",
    "resultados_df['HLN-DM_stat'] = resultados_df['HLN-DM_stat'].round(4)\n",
    "resultados_df['p_valor'] = resultados_df['p_valor'].round(4)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n\")\n",
    "print(resultados_df.to_string(index=False))\n",
    "\n",
    "# Resumen de resultados\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"RESUMEN\")\n",
    "print(\"=\"*120)\n",
    "n_significativos = len(resultados_df[resultados_df['Significativo'] != 'No'])\n",
    "n_total = len(resultados_df)\n",
    "print(f\"\\nTotal de métodos comparados: {n_total}\")\n",
    "print(f\"Diferencias significativas: {n_significativos} ({100*n_significativos/n_total:.1f}%)\")\n",
    "print(f\"No significativas: {n_total - n_significativos} ({100*(n_total-n_significativos)/n_total:.1f}%)\")\n",
    "\n",
    "# Mostrar cuáles métodos tienen diferencias significativas\n",
    "if n_significativos > 0:\n",
    "    print(\"\\nMétodos con diferencias significativas:\")\n",
    "    metodos_sig = resultados_df[resultados_df['Significativo'] != 'No'][['Método', 'Significativo', 'p_valor']]\n",
    "    print(metodos_sig.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbb8245",
   "metadata": {},
   "source": [
    "### Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b604c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Datos cargados: (26880, 19)\n",
      "✓ Columnas: ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', 'Distribución', 'Varianza', 'Modalidad', 'Valor_Observado', 'AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
      "✓ Modelos identificados: ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
      "✓ Valores únicos de d: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(10)]\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS MULTI-D — VERSIÓN CORREGIDA\n",
      "================================================================================\n",
      "\n",
      "=== ANÁLISIS 1: Mejora Porcentual por d ===\n",
      "✓ Gráfico guardado: 1_MEJORA_PORCENTUAL_POR_D.png\n",
      "✓ Tabla guardada: 1_tabla_mejora_por_d.xlsx\n",
      "\n",
      "=== ANÁLISIS 2: Sensibilidad de Modelos por d ===\n",
      "✓ Gráfico guardado: 2_SENSIBILIDAD_MODELOS_POR_D.png\n",
      "✓ Tabla guardada: 2_tabla_sensibilidad_por_d.xlsx\n",
      "\n",
      "=== ANÁLISIS 3: Test Diebold-Mariano con Bonferroni por Modelo ===\n",
      "✓ Escenarios únicos: 1120\n",
      "\n",
      "  Procesando modelo: AV-MCPS\n",
      "  α Bonferroni = 0.05 / 1120 = 0.000045\n",
      "  ✓ Excel guardado: 3_DM_COMPLETO_AV_MCPS.xlsx\n",
      "  ✓ Heatmap % significancia guardado\n",
      "  ✓ Heatmap p-valores guardado\n",
      "  ✓ Comparaciones significativas: 963/1120 (86.0%)\n",
      "\n",
      "  Procesando modelo: Block Bootstrapping\n",
      "  α Bonferroni = 0.05 / 1120 = 0.000045\n",
      "  ✓ Excel guardado: 3_DM_COMPLETO_Block_Bootstrapping.xlsx\n",
      "  ✓ Heatmap % significancia guardado\n",
      "  ✓ Heatmap p-valores guardado\n",
      "  ✓ Comparaciones significativas: 1109/1120 (99.0%)\n",
      "\n",
      "  Procesando modelo: DeepAR\n",
      "  α Bonferroni = 0.05 / 1120 = 0.000045\n",
      "  ✓ Excel guardado: 3_DM_COMPLETO_DeepAR.xlsx\n",
      "  ✓ Heatmap % significancia guardado\n",
      "  ✓ Heatmap p-valores guardado\n",
      "  ✓ Comparaciones significativas: 1010/1120 (90.2%)\n",
      "\n",
      "  Procesando modelo: EnCQR-LSTM\n",
      "  α Bonferroni = 0.05 / 1120 = 0.000045\n",
      "  ✓ Excel guardado: 3_DM_COMPLETO_EnCQR_LSTM.xlsx\n",
      "  ✓ Heatmap % significancia guardado\n",
      "  ✓ Heatmap p-valores guardado\n",
      "  ✓ Comparaciones significativas: 1081/1120 (96.5%)\n",
      "\n",
      "  Procesando modelo: LSPM\n",
      "  α Bonferroni = 0.05 / 1120 = 0.000045\n",
      "  ✓ Excel guardado: 3_DM_COMPLETO_LSPM.xlsx\n",
      "  ✓ Heatmap % significancia guardado\n",
      "  ✓ Heatmap p-valores guardado\n",
      "  ✓ Comparaciones significativas: 945/1120 (84.4%)\n",
      "\n",
      "  Procesando modelo: LSPMW\n",
      "  α Bonferroni = 0.05 / 1120 = 0.000045\n",
      "  ✓ Excel guardado: 3_DM_COMPLETO_LSPMW.xlsx\n",
      "  ✓ Heatmap % significancia guardado\n",
      "  ✓ Heatmap p-valores guardado\n",
      "  ✓ Comparaciones significativas: 949/1120 (84.7%)\n",
      "\n",
      "  Procesando modelo: MCPS\n",
      "  α Bonferroni = 0.05 / 1120 = 0.000045\n",
      "  ✓ Excel guardado: 3_DM_COMPLETO_MCPS.xlsx\n",
      "  ✓ Heatmap % significancia guardado\n",
      "  ✓ Heatmap p-valores guardado\n",
      "  ✓ Comparaciones significativas: 987/1120 (88.1%)\n",
      "\n",
      "  Procesando modelo: Sieve Bootstrap\n",
      "  α Bonferroni = 0.05 / 1120 = 0.000045\n",
      "  ✓ Excel guardado: 3_DM_COMPLETO_Sieve_Bootstrap.xlsx\n",
      "  ✓ Heatmap % significancia guardado\n",
      "  ✓ Heatmap p-valores guardado\n",
      "  ✓ Comparaciones significativas: 677/1120 (60.4%)\n",
      "\n",
      "✓ Análisis 3 completado\n",
      "\n",
      "================================================================================\n",
      "✓ ANÁLISIS COMPLETADO\n",
      "✓ Resultados: Resultados_analisis\\Multi_d\n",
      "✓ Gráficos:   Resultados_analisis\\Multi_d\\Graficos_Analisis\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Configuración inicial\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# ====================================================================================\n",
    "# 1. PREPARACIÓN DE DIRECTORIOS\n",
    "# ====================================================================================\n",
    "output_dir = Path(\"./Resultados_analisis/Multi_d\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "plots_dir = output_dir / \"Graficos_Analisis\"\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "path_excel = \"./datos/Simulacion/Multi_D/resultados_ARIMA_d1_a_d10_DOBLE_MODALIDAD_COMPLETO.xlsx\"\n",
    "try:\n",
    "    df = pd.read_excel(path_excel)\n",
    "    print(f\"✓ Datos cargados: {df.shape}\")\n",
    "    print(f\"✓ Columnas: {df.columns.tolist()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error crítico: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Identificar columnas\n",
    "var_cols = ['Paso', 'Proceso', 'p', 'd', 'q', 'ARMA_base', 'Distribución',\n",
    "            'Varianza', 'Modalidad', 'Valor_Observado']\n",
    "model_cols = [col for col in df.columns if col not in var_cols]\n",
    "print(f\"✓ Modelos identificados: {model_cols}\")\n",
    "print(f\"✓ Valores únicos de d: {sorted(df['d'].unique())}\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# TEST DE DIEBOLD-MARIANO CORREGIDO\n",
    "# ====================================================================================\n",
    "def diebold_mariano_test(loss1, loss2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano correcto.\n",
    "\n",
    "    Recibe dos arrays de PÉRDIDAS por observación (ej. ECRPS por paso/réplica)\n",
    "    del mismo largo. Calcula el diferencial d_t = loss1_t - loss2_t y testea\n",
    "    H0: E[d_t] = 0  vs  H1: E[d_t] != 0.\n",
    "\n",
    "    Usa HAC (Newey-West) con bandwidth = h-1 para series de h pasos adelante,\n",
    "    que es la corrección estándar para correlación serial inducida por el horizonte.\n",
    "\n",
    "    DIFERENCIAS respecto al código original (que tenía 3 bugs):\n",
    "    -------------------------------------------------------\n",
    "    Bug 1 (original): Se calculaba sigma_hat_sq sobre las DESVIACIONES u = d - d_bar\n",
    "                      en lugar de sobre la serie diferencial d_t completa.\n",
    "                      → Cuando d_bar >> 0 (caso de interés), las desviaciones son\n",
    "                        pequeñas y sigma se subestima, inflando el estadístico\n",
    "                        artificialmente O deflacionándolo según el paso del FFT.\n",
    "\n",
    "    Bug 2 (original): La varianza espectral usaba solo los primeros m periodogramas\n",
    "                      del FFT de u, no de d. Esto es una estimación no estándar\n",
    "                      que mezcla la media con la varianza de manera incorrecta.\n",
    "\n",
    "    Bug 3 (original): El estadístico resultante a veces era enorme (rechaza cuando\n",
    "                      no debería) y a veces cercano a cero (no rechaza cuando sí\n",
    "                      debería), porque u ≈ 0 cuando loss1 >> loss2 implica que\n",
    "                      todas las desviaciones de la media son similares entre sí,\n",
    "                      haciendo que sigma → 0 y el test colapsa numéricamente.\n",
    "\n",
    "    Solución: HAC estándar (Newey-West) directamente sobre d_t = loss1_t - loss2_t.\n",
    "    \"\"\"\n",
    "    loss1 = np.asarray(loss1, dtype=float)\n",
    "    loss2 = np.asarray(loss2, dtype=float)\n",
    "\n",
    "    if len(loss1) != len(loss2):\n",
    "        raise ValueError(\"Las series deben tener el mismo largo\")\n",
    "\n",
    "    T = len(loss1)\n",
    "    if T < 4:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    # Diferencial de pérdidas (positivo = loss1 peor que loss2)\n",
    "    d = loss1 - loss2\n",
    "    d_bar = np.mean(d)\n",
    "\n",
    "    # --- Varianza HAC Newey-West ---\n",
    "    # La varianza de d_bar bajo correlación serial es:\n",
    "    # V = (1/T) * [ gamma_0 + 2 * sum_{k=1}^{K} w_k * gamma_k ]\n",
    "    # donde gamma_k es la autocovarianza muestral de d en lag k\n",
    "    # y w_k = 1 - k/(K+1) son los pesos de Bartlett.\n",
    "    # K = max(h-1, 1) es el bandwidth: para h=1 se usa solo gamma_0 (sin\n",
    "    # corrección de autocorrelación), que es el estimador DM original.\n",
    "    # Para h>1 se corrige por la autocorrelación inducida por el solapamiento.\n",
    "\n",
    "    K = max(h - 1, 0)  # bandwidth (lags a incluir)\n",
    "    d_centered = d - d_bar  # desviaciones para autocovarianzas\n",
    "\n",
    "    # gamma_0: varianza muestral\n",
    "    gamma_0 = np.dot(d_centered, d_centered) / T\n",
    "\n",
    "    hac_var = gamma_0\n",
    "    for k in range(1, K + 1):\n",
    "        gamma_k = np.dot(d_centered[k:], d_centered[:-k]) / T\n",
    "        w_k = 1.0 - k / (K + 1.0)  # peso de Bartlett\n",
    "        hac_var += 2.0 * w_k * gamma_k\n",
    "\n",
    "    # Protección numérica: si la varianza es no positiva, usar gamma_0\n",
    "    if hac_var <= 0:\n",
    "        hac_var = gamma_0\n",
    "    if hac_var <= 0:\n",
    "        # Caso degenerado: todas las diferencias son idénticas\n",
    "        return 0.0, 1.0\n",
    "\n",
    "    # Estadístico DM\n",
    "    dm_stat = d_bar / np.sqrt(hac_var / T)\n",
    "\n",
    "    # Corrección de muestra pequeña Harvey, Leybourne & Newbold (1997):\n",
    "    # multiplica el estadístico por sqrt((T + 1 - 2h + h(h-1)/T) / T)\n",
    "    # para mejorar la aproximación en muestras finitas.\n",
    "    hln_factor = np.sqrt((T + 1 - 2 * h + h * (h - 1) / T) / T)\n",
    "    dm_stat_hln = dm_stat * hln_factor\n",
    "\n",
    "    # P-valor: t-Student con T-1 grados de libertad (HLN) o normal estándar\n",
    "    p_value = 2.0 * (1.0 - stats.t.cdf(abs(dm_stat_hln), df=T - 1))\n",
    "\n",
    "    return dm_stat_hln, p_value\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# ANÁLISIS 1: MEJORA PORCENTUAL POR DIFERENCIACIÓN (HEATMAP POR d)\n",
    "# ====================================================================================\n",
    "def plot_mejora_porcentual_por_d():\n",
    "    \"\"\"\n",
    "    Heatmap de mejora porcentual (CON_DIFF vs SIN_DIFF) para cada modelo por d\n",
    "    \"\"\"\n",
    "    print(\"\\n=== ANÁLISIS 1: Mejora Porcentual por d ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "\n",
    "    # Calcular mejoras para cada modelo y d\n",
    "    mejoras = []\n",
    "    for model in model_cols:\n",
    "        mejoras_model = []\n",
    "        for d_val in d_values:\n",
    "            subset_d = df[df['d'] == d_val]\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "            mejora_pct = ((sin - con) / sin) * 100 if sin != 0 else 0\n",
    "            mejoras_model.append(mejora_pct)\n",
    "        mejoras.append(mejoras_model)\n",
    "\n",
    "    df_mejora = pd.DataFrame(mejoras, index=model_cols, columns=[f'd={d}' for d in d_values])\n",
    "\n",
    "    # Crear heatmap\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    sns.heatmap(df_mejora, annot=True, fmt='.1f', cmap='RdYlGn', center=0,\n",
    "                cbar_kws={'label': 'Mejora (%)'}, linewidths=0.8,\n",
    "                vmin=-20, vmax=20)\n",
    "    plt.title('Mejora Porcentual: CON_DIFF vs SIN_DIFF por Orden de Diferenciación',\n",
    "              fontweight='bold', fontsize=16, pad=20)\n",
    "    plt.xlabel('Orden de Diferenciación (d)', fontweight='bold', fontsize=13)\n",
    "    plt.ylabel('Modelo', fontweight='bold', fontsize=13)\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / '1_MEJORA_PORCENTUAL_POR_D.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    df_mejora.to_excel(output_dir / '1_tabla_mejora_por_d.xlsx')\n",
    "    print(f\"✓ Gráfico guardado: 1_MEJORA_PORCENTUAL_POR_D.png\")\n",
    "    print(f\"✓ Tabla guardada: 1_tabla_mejora_por_d.xlsx\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# ANÁLISIS 2: SENSIBILIDAD DE MODELOS POR d\n",
    "# ====================================================================================\n",
    "def plot_sensibilidad_modelos_por_d():\n",
    "    \"\"\"\n",
    "    Heatmap de sensibilidad normalizada (CV) por modelo y d\n",
    "    \"\"\"\n",
    "    print(\"\\n=== ANÁLISIS 2: Sensibilidad de Modelos por d ===\")\n",
    "    d_values = sorted(df['d'].unique())\n",
    "\n",
    "    sensibilidades = []\n",
    "    for model in model_cols:\n",
    "        sens_model = []\n",
    "        for d_val in d_values:\n",
    "            subset_d = df[df['d'] == d_val]\n",
    "            sin = subset_d[subset_d['Modalidad'] == 'SIN_DIFF'][model].mean()\n",
    "            con = subset_d[subset_d['Modalidad'] == 'CON_DIFF'][model].mean()\n",
    "            valores = [sin, con]\n",
    "            std = np.std(valores)\n",
    "            mean = np.mean(valores)\n",
    "            cv = (std / mean * 100) if mean != 0 else 0\n",
    "            sens_model.append(cv)\n",
    "        sensibilidades.append(sens_model)\n",
    "\n",
    "    df_sens = pd.DataFrame(sensibilidades, index=model_cols,\n",
    "                           columns=[f'd={d}' for d in d_values])\n",
    "\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    sns.heatmap(df_sens, annot=True, fmt='.2f', cmap='YlOrRd',\n",
    "                cbar_kws={'label': 'Coeficiente de Variación (%)'},\n",
    "                linewidths=0.8, vmin=0)\n",
    "    plt.title('Sensibilidad de Modelos por Orden de Diferenciación\\n(Coeficiente de Variación entre Modalidades)',\n",
    "              fontweight='bold', fontsize=16, pad=20)\n",
    "    plt.xlabel('Orden de Diferenciación (d)', fontweight='bold', fontsize=13)\n",
    "    plt.ylabel('Modelo', fontweight='bold', fontsize=13)\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_dir / '2_SENSIBILIDAD_MODELOS_POR_D.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    df_sens.to_excel(output_dir / '2_tabla_sensibilidad_por_d.xlsx')\n",
    "    print(f\"✓ Gráfico guardado: 2_SENSIBILIDAD_MODELOS_POR_D.png\")\n",
    "    print(f\"✓ Tabla guardada: 2_tabla_sensibilidad_por_d.xlsx\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# ANÁLISIS 3: TEST DIEBOLD-MARIANO CON BONFERRONI POR MODELO\n",
    "# ====================================================================================\n",
    "def plot_dm_bonferroni_por_modelo():\n",
    "    \"\"\"\n",
    "    Para cada modelo, compara SIN_DIFF vs CON_DIFF usando el test DM corregido.\n",
    "\n",
    "    La clave del test DM es que necesita PARES de pérdidas por observación:\n",
    "      - loss1_t = ECRPS del modelo SIN_DIFF en el paso t (réplica t)\n",
    "      - loss2_t = ECRPS del modelo CON_DIFF en el paso t (réplica t)\n",
    "    El test evalúa si E[loss1_t - loss2_t] = 0.\n",
    "\n",
    "    Para que los pares sean válidos, se emparejan por 'Paso' dentro de cada\n",
    "    (Escenario, d): cada Paso corresponde a una réplica de simulación, y la\n",
    "    diferencia de pérdidas entre modalidades en ese Paso es la observación\n",
    "    del diferencial d_t que alimenta el test.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== ANÁLISIS 3: Test Diebold-Mariano con Bonferroni por Modelo ===\")\n",
    "\n",
    "    modelos_analizar = ['AV-MCPS', 'Block Bootstrapping', 'DeepAR', 'EnCQR-LSTM',\n",
    "                        'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "    modelos_disponibles = [m for m in modelos_analizar if m in model_cols]\n",
    "    if len(modelos_disponibles) < len(modelos_analizar):\n",
    "        faltantes = set(modelos_analizar) - set(modelos_disponibles)\n",
    "        print(f\"⚠ Modelos no encontrados: {faltantes}\")\n",
    "        print(f\"  Modelos en el dataset: {model_cols}\")\n",
    "\n",
    "    d_values = sorted(df['d'].unique())\n",
    "\n",
    "    # --- Crear columnas auxiliares de escenario ---\n",
    "    def extract_pq(arma_str):\n",
    "        try:\n",
    "            parts = arma_str.replace('ARMA_I(', '').replace(')', '').split(',')\n",
    "            if len(parts) == 3:\n",
    "                p, d_val, q = parts\n",
    "                return f\"ARMA({p},{q})\"\n",
    "            return arma_str\n",
    "        except Exception:\n",
    "            return arma_str\n",
    "\n",
    "    def grupo_proceso_arima(arma_str):\n",
    "        try:\n",
    "            parts = arma_str.replace('ARMA_I(', '').replace(')', '').split(',')\n",
    "            if len(parts) == 3:\n",
    "                p, d_val, q = parts\n",
    "                return f\"ARIMA({p},d,{q})\"\n",
    "            return arma_str\n",
    "        except Exception:\n",
    "            return arma_str\n",
    "\n",
    "    df['ARMA_pq'] = df['ARMA_base'].apply(extract_pq)\n",
    "    df['Proceso_Agrupado'] = df['ARMA_base'].apply(grupo_proceso_arima)\n",
    "\n",
    "    # Escenario excluye d (varía en columnas del heatmap)\n",
    "    df['Escenario'] = (df['Proceso'].astype(str) + '_' +\n",
    "                       df['ARMA_pq'].astype(str) + '_' +\n",
    "                       df['Distribución'].astype(str) + '_' +\n",
    "                       df['Varianza'].astype(str))\n",
    "\n",
    "    escenarios_unicos = sorted(df['Escenario'].unique())\n",
    "    print(f\"✓ Escenarios únicos: {len(escenarios_unicos)}\")\n",
    "\n",
    "    for model in modelos_disponibles:\n",
    "        print(f\"\\n  Procesando modelo: {model}\")\n",
    "\n",
    "        resultados_detalle = []\n",
    "        pvalor_matrix = []\n",
    "        escenarios_lista = []\n",
    "\n",
    "        for escenario in escenarios_unicos:\n",
    "            pvalores_d = [np.nan] * len(d_values)\n",
    "            tiene_datos = False\n",
    "\n",
    "            for idx_d, d_val in enumerate(d_values):\n",
    "                subset = df[(df['Escenario'] == escenario) & (df['d'] == d_val)]\n",
    "                if len(subset) == 0:\n",
    "                    continue\n",
    "\n",
    "                proceso = subset['Proceso'].iloc[0]\n",
    "                distribucion = subset['Distribución'].iloc[0]\n",
    "                varianza = subset['Varianza'].iloc[0]\n",
    "                proceso_agrupado = subset['Proceso_Agrupado'].iloc[0]\n",
    "\n",
    "                # ----------------------------------------------------------------\n",
    "                # CORRECCIÓN CLAVE: emparejar por 'Paso' para obtener pares\n",
    "                # (loss_SIN_t, loss_CON_t) con el mismo índice temporal/réplica.\n",
    "                # Antes se usaban arrays sin alinear, lo que rompía el test DM.\n",
    "                # ----------------------------------------------------------------\n",
    "                sin_df = subset[subset['Modalidad'] == 'SIN_DIFF'][['Paso', model]].rename(\n",
    "                    columns={model: 'loss_sin'})\n",
    "                con_df = subset[subset['Modalidad'] == 'CON_DIFF'][['Paso', model]].rename(\n",
    "                    columns={model: 'loss_con'})\n",
    "\n",
    "                # Inner join: solo pasos presentes en ambas modalidades\n",
    "                paired = pd.merge(sin_df, con_df, on='Paso', how='inner')\n",
    "                paired = paired.dropna(subset=['loss_sin', 'loss_con'])\n",
    "\n",
    "                n_pairs = len(paired)\n",
    "\n",
    "                # Umbral mínimo de pares para que el test sea informativo\n",
    "                if n_pairs < 5:\n",
    "                    continue\n",
    "\n",
    "                loss_sin = paired['loss_sin'].values\n",
    "                loss_con = paired['loss_con'].values\n",
    "\n",
    "                dm_stat, p_value = diebold_mariano_test(loss_sin, loss_con, h=1)\n",
    "\n",
    "                if np.isnan(p_value):\n",
    "                    continue\n",
    "\n",
    "                pvalores_d[idx_d] = p_value\n",
    "                tiene_datos = True\n",
    "\n",
    "                resultados_detalle.append({\n",
    "                    'Proceso': proceso,\n",
    "                    'Distribución': distribucion,\n",
    "                    'Varianza': varianza,\n",
    "                    'd': d_val,\n",
    "                    'p_valor': p_value,\n",
    "                    'n_pares': n_pairs,\n",
    "                    'Proceso_Agrupado': proceso_agrupado\n",
    "                })\n",
    "\n",
    "            if tiene_datos:\n",
    "                pvalor_matrix.append(pvalores_d)\n",
    "                escenarios_lista.append(escenario)\n",
    "\n",
    "        if len(pvalor_matrix) == 0:\n",
    "            print(f\"  ⚠ Sin datos válidos para {model}\")\n",
    "            continue\n",
    "\n",
    "        df_pvalor = pd.DataFrame(pvalor_matrix,\n",
    "                                 index=escenarios_lista,\n",
    "                                 columns=[f'd={d}' for d in d_values])\n",
    "\n",
    "        # Corrección Bonferroni sobre el número de tests válidos\n",
    "        n_tests_validos = int(df_pvalor.notna().sum().sum())\n",
    "        alpha_bonferroni = 0.05 / n_tests_validos if n_tests_validos > 0 else 0.05\n",
    "        print(f\"  α Bonferroni = 0.05 / {n_tests_validos} = {alpha_bonferroni:.6f}\")\n",
    "\n",
    "        df_significancia = df_pvalor < alpha_bonferroni\n",
    "\n",
    "        # ==================== EXCEL CON 3 HOJAS ====================\n",
    "        safe_name = model.replace(' ', '_').replace('/', '_').replace('-', '_')\n",
    "        excel_path = output_dir / f'3_DM_COMPLETO_{safe_name}.xlsx'\n",
    "\n",
    "        df_detalle = pd.DataFrame(resultados_detalle)\n",
    "        df_agrupado = df_detalle[['Proceso_Agrupado', 'Distribución', 'Varianza', 'd', 'p_valor']].rename(\n",
    "            columns={'Proceso_Agrupado': 'Proceso_ARIMA'})\n",
    "\n",
    "        procesos_agrupados = sorted(df_agrupado['Proceso_ARIMA'].unique())\n",
    "        matriz_pct_sig = []\n",
    "        for proceso_ag in procesos_agrupados:\n",
    "            fila_pct = []\n",
    "            for d_val in d_values:\n",
    "                subset_proc_d = df_agrupado[\n",
    "                    (df_agrupado['Proceso_ARIMA'] == proceso_ag) &\n",
    "                    (df_agrupado['d'] == d_val)\n",
    "                ]\n",
    "                if len(subset_proc_d) > 0:\n",
    "                    n_total = len(subset_proc_d)\n",
    "                    n_sig = (subset_proc_d['p_valor'] < alpha_bonferroni).sum()\n",
    "                    fila_pct.append((n_sig / n_total) * 100)\n",
    "                else:\n",
    "                    fila_pct.append(np.nan)\n",
    "            matriz_pct_sig.append(fila_pct)\n",
    "\n",
    "        df_pct_sig = pd.DataFrame(matriz_pct_sig,\n",
    "                                  index=procesos_agrupados,\n",
    "                                  columns=[f'd={d}' for d in d_values])\n",
    "\n",
    "        with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "            df_detalle[['Proceso', 'Distribución', 'Varianza', 'd', 'p_valor', 'n_pares']].to_excel(\n",
    "                writer, sheet_name='1_Detalle', index=False)\n",
    "            df_agrupado.to_excel(writer, sheet_name='2_Agrupado', index=False)\n",
    "            df_pct_sig.to_excel(writer, sheet_name='3_Porcentaje_Significancia')\n",
    "\n",
    "            workbook = writer.book\n",
    "            for sheet_name, df_temp in [('1_Detalle', df_detalle), ('2_Agrupado', df_agrupado)]:\n",
    "                worksheet = writer.sheets[sheet_name]\n",
    "                fmt_green = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})\n",
    "                fmt_red = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})\n",
    "                col_idx = df_temp.columns.get_loc('p_valor')\n",
    "                worksheet.conditional_format(1, col_idx, len(df_temp), col_idx,\n",
    "                    {'type': 'cell', 'criteria': '<', 'value': alpha_bonferroni, 'format': fmt_green})\n",
    "                worksheet.conditional_format(1, col_idx, len(df_temp), col_idx,\n",
    "                    {'type': 'cell', 'criteria': '>=', 'value': alpha_bonferroni, 'format': fmt_red})\n",
    "\n",
    "        print(f\"  ✓ Excel guardado: {excel_path.name}\")\n",
    "\n",
    "        # ==================== HEATMAP % SIGNIFICANCIA ====================\n",
    "        fig, ax = plt.subplots(figsize=(14, max(8, len(procesos_agrupados) * 0.4)))\n",
    "        sns.heatmap(df_pct_sig, annot=True, fmt='.1f', cmap='RdYlGn',\n",
    "                    cbar_kws={'label': '% Significativo (Bonferroni)'},\n",
    "                    linewidths=0.8, vmin=0, vmax=100, ax=ax)\n",
    "        ax.set_title(f'Porcentaje de p-valores Significativos: {model}\\n'\n",
    "                     f'Por Proceso ARIMA y d (α Bonferroni = {alpha_bonferroni:.6f})',\n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.set_xlabel('Orden de Diferenciación (d)', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Proceso ARIMA(p,d,q)', fontweight='bold', fontsize=12)\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / f'3_HEATMAP_PCT_SIGNIFICANCIA_{safe_name}.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  ✓ Heatmap % significancia guardado\")\n",
    "\n",
    "        # ==================== HEATMAP P-VALORES ====================\n",
    "        fig, ax = plt.subplots(figsize=(16, max(12, len(escenarios_lista) * 0.3)))\n",
    "        sns.heatmap(df_pvalor, annot=True, fmt='.4f', cmap='RdYlGn',\n",
    "                    cbar_kws={'label': 'p-valor'}, linewidths=0.5,\n",
    "                    vmin=0, vmax=0.1, center=alpha_bonferroni, ax=ax)\n",
    "\n",
    "        for i in range(len(escenarios_lista)):\n",
    "            for j in range(len(d_values)):\n",
    "                if df_significancia.iloc[i, j]:\n",
    "                    ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False,\n",
    "                                               edgecolor='black', lw=3))\n",
    "\n",
    "        ax.set_title(f'Test Diebold-Mariano: {model}\\n'\n",
    "                     f'SIN_DIFF vs CON_DIFF por Escenario y d\\n'\n",
    "                     f'(α Bonferroni = {alpha_bonferroni:.6f}, bordes negros = significativo)',\n",
    "                     fontweight='bold', fontsize=14, pad=20)\n",
    "        ax.set_xlabel('Orden de Diferenciación (d)', fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel('Escenario (Proceso_ARMA(p,q)_Dist_Var)', fontweight='bold', fontsize=12)\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=7)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_dir / f'3_DM_PVALORES_{safe_name}.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  ✓ Heatmap p-valores guardado\")\n",
    "\n",
    "        n_significativos = int(df_significancia.sum().sum())\n",
    "        pct_sig = (n_significativos / n_tests_validos) * 100 if n_tests_validos > 0 else 0\n",
    "        print(f\"  ✓ Comparaciones significativas: {n_significativos}/{n_tests_validos} ({pct_sig:.1f}%)\")\n",
    "\n",
    "    print(f\"\\n✓ Análisis 3 completado\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# EJECUCIÓN PRINCIPAL\n",
    "# ====================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ANÁLISIS MULTI-D — VERSIÓN CORREGIDA\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    plot_mejora_porcentual_por_d()\n",
    "    plot_sensibilidad_modelos_por_d()\n",
    "    plot_dm_bonferroni_por_modelo()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"✓ ANÁLISIS COMPLETADO\")\n",
    "    print(f\"✓ Resultados: {output_dir}\")\n",
    "    print(f\"✓ Gráficos:   {plots_dir}\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8a52b",
   "metadata": {},
   "source": [
    "## Analisis Tamaño"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169f259",
   "metadata": {},
   "source": [
    "### Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd6fb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TABLA COMPARATIVA DE MODELOS POR ESCENARIO\n",
      "(Promedio de amplitud de intervalos de predicción)\n",
      "================================================================================\n",
      "             Modelo   ARMA   ARIMA  SETAR Mejor_Escenario\n",
      "              AREPD 0.9264 12.3986 0.8148           SETAR\n",
      "            AV-MCPS 0.6780  3.0524 0.6585           SETAR\n",
      "Block Bootstrapping 0.9036 14.2503 0.7915           SETAR\n",
      "             DeepAR 0.5745  2.8056 0.5736           SETAR\n",
      "         EnCQR-LSTM 0.7947  6.1857 0.7544           SETAR\n",
      "               LSPM 0.7721  1.0854 0.6490           SETAR\n",
      "              LSPMW 0.7839  1.0846 0.6610           SETAR\n",
      "               MCPS 0.6613  2.8912 0.6488           SETAR\n",
      "    Sieve Bootstrap 0.5444  0.5473 0.5544            ARMA\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Archivo 'Base_Tamaño_3_escenarios.xlsx' creado exitosamente!\n",
      "Columna 'Block Bootstrapping' verificada en el archivo final.\n",
      "Total de filas: 25200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Leer los tres archivos\n",
    "arma_df = pd.read_excel(\"./datos/Simulacion/Tamaño/resultados_TAMANOS_CRECIENTES_ARMA.xlsx\")\n",
    "arima_df = pd.read_excel(\"./datos/Simulacion/Tamaño/resultados_TAMANOS_CRECIENTES_ARIMA.xlsx\")\n",
    "setar_df = pd.read_excel(\"./datos/Simulacion/Tamaño/resultados_TAMANOS_CRECIENTES_SETAR.xlsx\")\n",
    "\n",
    "# 2. ESTANDARIZAR NOMBRES DE COLUMNAS\n",
    "# Renombramos 'Block Bootstrap' a 'Block Bootstrapping' en ARIMA y SETAR para que coincidan con ARMA\n",
    "arima_df = arima_df.rename(columns={'Block Bootstrap': 'Block Bootstrapping'})\n",
    "setar_df = setar_df.rename(columns={'Block Bootstrap': 'Block Bootstrapping'})\n",
    "\n",
    "# 3. Asignar escenarios\n",
    "arma_df['ESCENARIO'] = \"Lineal Estacionario\"\n",
    "arima_df['ESCENARIO'] = \"Lineal No estacionario\"\n",
    "setar_df['ESCENARIO'] = \"No lineal Estacionario\"\n",
    "\n",
    "# 4. Filtrar los que no tienen \"Promedio\" en la columna \"Paso\"\n",
    "arma_df = arma_df[arma_df['Paso'] != 'Promedio']\n",
    "arima_df = arima_df[arima_df['Paso'] != 'Promedio']\n",
    "setar_df = setar_df[setar_df['Paso'] != 'Promedio']\n",
    "\n",
    "# 5. Lista de modelos (ahora el nombre es uniforme)\n",
    "modelos = ['AREPD', 'AV-MCPS', 'Block Bootstrapping', 'DeepAR',\n",
    "           'EnCQR-LSTM', 'LSPM', 'LSPMW', 'MCPS', 'Sieve Bootstrap']\n",
    "\n",
    "# 6. Crear tabla comparativa\n",
    "comparacion = []\n",
    "\n",
    "for modelo in modelos:\n",
    "    fila = {'Modelo': modelo}\n",
    "    \n",
    "    # Calcular promedio para cada escenario\n",
    "    arma_promedio = arma_df[modelo].mean() if modelo in arma_df.columns else np.nan\n",
    "    arima_promedio = arima_df[modelo].mean() if modelo in arima_df.columns else np.nan\n",
    "    setar_promedio = setar_df[modelo].mean() if modelo in setar_df.columns else np.nan\n",
    "    \n",
    "    fila['ARMA'] = arma_promedio\n",
    "    fila['ARIMA'] = arima_promedio\n",
    "    fila['SETAR'] = setar_promedio\n",
    "    \n",
    "    # Determinar mejor escenario (menor promedio)\n",
    "    promedios = {\n",
    "        'ARMA': arma_promedio,\n",
    "        'ARIMA': arima_promedio,\n",
    "        'SETAR': setar_promedio\n",
    "    }\n",
    "    \n",
    "    promedios_validos = {k: v for k, v in promedios.items() if not pd.isna(v)}\n",
    "    \n",
    "    if promedios_validos:\n",
    "        mejor_escenario = min(promedios_validos, key=promedios_validos.get)\n",
    "        fila['Mejor_Escenario'] = mejor_escenario\n",
    "    else:\n",
    "        fila['Mejor_Escenario'] = 'N/A'\n",
    "    \n",
    "    comparacion.append(fila)\n",
    "\n",
    "# Crear DataFrame con la tabla comparativa\n",
    "tabla_comparativa = pd.DataFrame(comparacion)\n",
    "columnas_numericas = ['ARMA', 'ARIMA', 'SETAR']\n",
    "tabla_comparativa[columnas_numericas] = tabla_comparativa[columnas_numericas].round(4)\n",
    "\n",
    "# Mostrar tabla comparativa\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA COMPARATIVA DE MODELOS POR ESCENARIO\")\n",
    "print(\"(Promedio de amplitud de intervalos de predicción)\")\n",
    "print(\"=\"*80)\n",
    "print(tabla_comparativa.to_string(index=False))\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# 7. Procesamiento final y exportación\n",
    "if 'Descripción' in setar_df.columns:\n",
    "    setar_df = setar_df.drop('Descripción', axis=1)\n",
    "\n",
    "# Concatenar los tres dataframes (ahora las columnas se alinearán perfectamente)\n",
    "base_consolidada = pd.concat([arma_df, arima_df, setar_df], ignore_index=True)\n",
    "\n",
    "# Guardar en un archivo Excel\n",
    "base_consolidada.to_excel(\"./datos/Simulacion/Tamaño/Base_Tamaño_3_escenarios.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nArchivo 'Base_Tamaño_3_escenarios.xlsx' creado exitosamente!\")\n",
    "print(f\"Columna 'Block Bootstrapping' verificada en el archivo final.\")\n",
    "print(f\"Total de filas: {len(base_consolidada)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a6937",
   "metadata": {},
   "source": [
    "### Analisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "518faae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "✓ Datos cargados:        (25200, 20)\n",
      "✓ Modelos:               9\n",
      "✓ Tamaños N_Total:       [np.int64(120), np.int64(240), np.int64(360), np.int64(600), np.int64(1200)]\n",
      "✓ Tipos de escenario:    ['Lineal Estacionario (ARMA)', 'Lineal No Estacionario (ARIMA)', 'No lineal Estacionario (SETAR)']\n",
      "✓ Escenarios únicos      (Proceso × Dist × Var): 420\n",
      "   Lineal Estacionario (ARMA): 140 escenarios\n",
      "   Lineal No Estacionario (ARIMA): 140 escenarios\n",
      "   No lineal Estacionario (SETAR): 140 escenarios\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DM CORREGIDO — EFECTOS DEL TAMAÑO MUESTRAL\n",
      "Escenario = combinación única (Proceso × Distribución × Varianza)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS GENERAL (TODOS LOS ESCENARIOS)\n",
      "================================================================================\n",
      "\n",
      "[Calculando tablas de p-valores - GENERAL]\n",
      "✓ Tests válidos totales: 37800\n",
      "✓ α Bonferroni = 0.05 / 37800 = 0.00000132\n",
      "\n",
      "[Generando visualizaciones - GENERAL]\n",
      "✓ Heatmap combinado guardado: General\n",
      "✓ Heatmap Z-scores generado: General\n",
      "✓ Mejora relativa generada: General\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS: Lineal Estacionario (ARMA)\n",
      "================================================================================\n",
      "\n",
      "[Calculando tablas de p-valores - Lineal Estacionario (ARMA)]\n",
      "✓ Tests válidos totales: 12600\n",
      "✓ α Bonferroni = 0.05 / 12600 = 0.00000397\n",
      "\n",
      "[Generando visualizaciones - Lineal Estacionario (ARMA)]\n",
      "✓ Heatmap combinado guardado: Lineal_Estacionario_ARMA\n",
      "✓ Heatmap Z-scores generado: Lineal_Estacionario_ARMA\n",
      "✓ Mejora relativa generada: Lineal_Estacionario_ARMA\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS: Lineal No Estacionario (ARIMA)\n",
      "================================================================================\n",
      "\n",
      "[Calculando tablas de p-valores - Lineal No Estacionario (ARIMA)]\n",
      "✓ Tests válidos totales: 12600\n",
      "✓ α Bonferroni = 0.05 / 12600 = 0.00000397\n",
      "\n",
      "[Generando visualizaciones - Lineal No Estacionario (ARIMA)]\n",
      "✓ Heatmap combinado guardado: Lineal_No_Estacionario_ARIMA\n",
      "✓ Heatmap Z-scores generado: Lineal_No_Estacionario_ARIMA\n",
      "✓ Mejora relativa generada: Lineal_No_Estacionario_ARIMA\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS: No lineal Estacionario (SETAR)\n",
      "================================================================================\n",
      "\n",
      "[Calculando tablas de p-valores - No lineal Estacionario (SETAR)]\n",
      "✓ Tests válidos totales: 12600\n",
      "✓ α Bonferroni = 0.05 / 12600 = 0.00000397\n",
      "\n",
      "[Generando visualizaciones - No lineal Estacionario (SETAR)]\n",
      "✓ Heatmap combinado guardado: No_lineal_Estacionario_SETAR\n",
      "✓ Heatmap Z-scores generado: No_lineal_Estacionario_SETAR\n",
      "✓ Mejora relativa generada: No_lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "EXPORTANDO EXCEL CONSOLIDADO\n",
      "================================================================================\n",
      "\n",
      "✓ Excel consolidado guardado: Resultados_analisis\\Tamaño\\DM_tamaño_muestral_consolidado.xlsx\n",
      "\n",
      "================================================================================\n",
      "✓ ANÁLISIS COMPLETADO\n",
      "✓ Resultados en: Resultados_analisis\\Tamaño\n",
      "\n",
      "Archivos generados:\n",
      "  1. HEATMAPS COMBINADOS (ECRPS + % Significancia):\n",
      "     - 4 archivos .png (General + ARMA + ARIMA + SETAR)\n",
      "  2. HEATMAPS Z-SCORES:\n",
      "     - 4 archivos .png + 8 .xlsx (General + ARMA + ARIMA + SETAR)\n",
      "  3. CURVAS DE MEJORA RELATIVA:\n",
      "     - 4 archivos .png + 4 .xlsx (General + ARMA + ARIMA + SETAR)\n",
      "  4. EXCEL CONSOLIDADO:\n",
      "     - 1 archivo con 9 hojas (2 por análisis + metodología)\n",
      "\n",
      "METODOLOGÍA:\n",
      "  - Test DM: HAC Newey-West + corrección HLN (1997)\n",
      "  - Emparejamiento: por Paso dentro de cada escenario único\n",
      "  - Corrección: Bonferroni por tipo de análisis\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "# ====================================================================================\n",
    "# 1. CONFIGURACIÓN Y PREPARACIÓN DE DATOS\n",
    "# ====================================================================================\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "output_dir = Path(\"./Resultados_analisis/Tamaño\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(\"./datos/Simulacion/Tamaño/Base_Tamaño_3_escenarios.xlsx\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: No se encontró el archivo Excel. Verifica la ruta.\")\n",
    "    exit()\n",
    "\n",
    "# Renombrar escenarios de tipo\n",
    "df['ESCENARIO'] = df['ESCENARIO'].replace({\n",
    "    \"Lineal Estacionario\":      \"Lineal Estacionario (ARMA)\",\n",
    "    \"Lineal No estacionario\":   \"Lineal No Estacionario (ARIMA)\",\n",
    "    \"No lineal Estacionario\":   \"No lineal Estacionario (SETAR)\"\n",
    "})\n",
    "\n",
    "var_cols = ['Paso', 'Proceso', 'Tipo_Proceso', 'Distribución', 'Varianza',\n",
    "            'N_Train', 'N_Calib', 'N_Total', 'Valor_Observado', 'ESCENARIO', 'Size']\n",
    "\n",
    "model_cols = [col for col in df.columns\n",
    "              if col not in var_cols and pd.api.types.is_numeric_dtype(df[col])]\n",
    "\n",
    "n_total_values = sorted(df['N_Total'].unique())\n",
    "tipos_escenario = sorted(df['ESCENARIO'].unique())   # los 3 tipos (ARMA, ARIMA, SETAR)\n",
    "\n",
    "# ====================================================================================\n",
    "# ESCENARIO = combinación única de (Proceso, Distribución, Varianza)\n",
    "# Esta es la unidad analítica del test DM:\n",
    "# comparamos modelo A con N=n1 vs modelo A con N=n2 DENTRO del mismo escenario.\n",
    "# ====================================================================================\n",
    "df['escenario_id'] = (df['Proceso'].astype(str) + ' | ' +\n",
    "                      df['Distribución'].astype(str) + ' | ' +\n",
    "                      df['Varianza'].astype(str))\n",
    "\n",
    "escenarios_unicos = sorted(df['escenario_id'].unique())\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ Datos cargados:        {df.shape}\")\n",
    "print(f\"✓ Modelos:               {len(model_cols)}\")\n",
    "print(f\"✓ Tamaños N_Total:       {n_total_values}\")\n",
    "print(f\"✓ Tipos de escenario:    {tipos_escenario}\")\n",
    "print(f\"✓ Escenarios únicos      \"\n",
    "      f\"(Proceso × Dist × Var): {len(escenarios_unicos)}\")\n",
    "\n",
    "# Mostrar cuántos escenarios hay por tipo\n",
    "for t in tipos_escenario:\n",
    "    ids_tipo = df[df['ESCENARIO'] == t]['escenario_id'].unique()\n",
    "    print(f\"   {t}: {len(ids_tipo)} escenarios\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# ====================================================================================\n",
    "# PALETA DE COLORES PARA GRÁFICAS\n",
    "# ====================================================================================\n",
    "def generate_maximally_distinct_colors(n):\n",
    "    \"\"\"Genera n colores maximamente distintivos\"\"\"\n",
    "    if n <= 10:\n",
    "        return plt.cm.tab10(np.linspace(0, 1, 10))[:n]\n",
    "    elif n <= 20:\n",
    "        return plt.cm.tab20(np.linspace(0, 1, 20))[:n]\n",
    "    else:\n",
    "        colors = []\n",
    "        tab20 = plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "        colors.extend(tab20)\n",
    "        if n > 20:\n",
    "            set3 = plt.cm.Set3(np.linspace(0, 1, 12))\n",
    "            colors.extend(set3)\n",
    "        if n > 32:\n",
    "            paired = plt.cm.Paired(np.linspace(0, 1, 12))\n",
    "            colors.extend(paired)\n",
    "        if n > 44:\n",
    "            remaining = n - len(colors)\n",
    "            for i in range(remaining):\n",
    "                hue = (i * 0.618033988749895) % 1.0\n",
    "                rgb = plt.cm.hsv(hue)\n",
    "                colors.append(rgb)\n",
    "        return np.array(colors[:n])\n",
    "\n",
    "MODEL_COLORS = dict(zip(model_cols, generate_maximally_distinct_colors(len(model_cols))))\n",
    "\n",
    "# ====================================================================================\n",
    "# 2. TEST DIEBOLD-MARIANO CORREGIDO\n",
    "#    HAC Newey-West + corrección Harvey-Leybourne-Newbold (1997)\n",
    "# ====================================================================================\n",
    "\n",
    "def diebold_mariano_test(loss1, loss2, h=1):\n",
    "    \"\"\"\n",
    "    Test DM bilateral para H0: E[loss1_t - loss2_t] = 0.\n",
    "\n",
    "    loss1_t, loss2_t deben ser pérdidas del MISMO paso/réplica t\n",
    "    (emparejar por 'Paso' antes de llamar esta función).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    loss1, loss2 : array-like, mismo largo\n",
    "    h            : horizonte de pronóstico (default=1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dm_stat : float   estadístico con corrección HLN\n",
    "    p_value : float   p-valor bilateral t_{T-1}\n",
    "    \"\"\"\n",
    "    loss1 = np.asarray(loss1, dtype=float)\n",
    "    loss2 = np.asarray(loss2, dtype=float)\n",
    "\n",
    "    T = len(loss1)\n",
    "    if T < 4:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    d     = loss1 - loss2\n",
    "    d_bar = np.mean(d)\n",
    "\n",
    "    # Varianza HAC Newey-West con bandwidth K = h-1\n",
    "    K         = max(h - 1, 0)\n",
    "    d_c       = d - d_bar       # desviaciones centradas\n",
    "    gamma_0   = np.dot(d_c, d_c) / T\n",
    "    hac_var   = gamma_0\n",
    "\n",
    "    for k in range(1, K + 1):\n",
    "        gamma_k = np.dot(d_c[k:], d_c[:-k]) / T\n",
    "        w_k     = 1.0 - k / (K + 1.0)\n",
    "        hac_var += 2.0 * w_k * gamma_k\n",
    "\n",
    "    if hac_var <= 0:\n",
    "        hac_var = gamma_0\n",
    "    if hac_var <= 0:\n",
    "        return 0.0, 1.0\n",
    "\n",
    "    dm_stat    = d_bar / np.sqrt(hac_var / T)\n",
    "\n",
    "    # Corrección HLN (Harvey, Leybourne & Newbold 1997)\n",
    "    hln_factor = np.sqrt((T + 1 - 2 * h + h * (h - 1) / T) / T)\n",
    "    dm_stat   *= hln_factor\n",
    "\n",
    "    p_value    = 2.0 * (1.0 - stats.t.cdf(abs(dm_stat), df=T - 1))\n",
    "    return dm_stat, p_value\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 3. FUNCIÓN CENTRAL: tabla de p-valores por modelo (POR TIPO DE ESCENARIO)\n",
    "# ====================================================================================\n",
    "\n",
    "def compute_pvalue_table(model, tipo_escenario=None):\n",
    "    \"\"\"\n",
    "    Genera la tabla detallada de p-valores para un modelo.\n",
    "    \n",
    "    Si tipo_escenario es None: usa todos los escenarios\n",
    "    Si tipo_escenario es especificado: filtra solo ese tipo\n",
    "    \n",
    "    Filas    = escenario único (Proceso | Dist | Var)\n",
    "    Columnas = par de tamaños  (N=n1 vs N=n2)\n",
    "\n",
    "    Emparejamiento: inner-join por 'Paso' entre N=n1 y N=n2\n",
    "    dentro del mismo escenario → misma réplica de simulación.\n",
    "    \"\"\"\n",
    "    # Filtrar datos si se especifica tipo de escenario\n",
    "    if tipo_escenario:\n",
    "        df_filtrado = df[df['ESCENARIO'] == tipo_escenario]\n",
    "        escenarios_usar = sorted(df_filtrado['escenario_id'].unique())\n",
    "    else:\n",
    "        df_filtrado = df\n",
    "        escenarios_usar = escenarios_unicos\n",
    "    \n",
    "    size_pairs = list(combinations(n_total_values, 2))\n",
    "    col_names  = [f\"N={n1} vs N={n2}\" for n1, n2 in size_pairs]\n",
    "\n",
    "    rows_pval, rows_dm = [], []\n",
    "\n",
    "    for esc_id in escenarios_usar:\n",
    "        subset_esc = df_filtrado[df_filtrado['escenario_id'] == esc_id]\n",
    "\n",
    "        row_pval, row_dm = [], []\n",
    "\n",
    "        for (n1, n2) in size_pairs:\n",
    "            s1 = (subset_esc[subset_esc['N_Total'] == n1][['Paso', model]]\n",
    "                  .rename(columns={model: 'l1'}))\n",
    "            s2 = (subset_esc[subset_esc['N_Total'] == n2][['Paso', model]]\n",
    "                  .rename(columns={model: 'l2'}))\n",
    "\n",
    "            paired = pd.merge(s1, s2, on='Paso', how='inner').dropna()\n",
    "            n_pairs = len(paired)\n",
    "\n",
    "            if n_pairs < 5:\n",
    "                row_pval.append(np.nan)\n",
    "                row_dm.append(np.nan)\n",
    "                continue\n",
    "\n",
    "            dm_stat, p_val = diebold_mariano_test(\n",
    "                paired['l1'].values, paired['l2'].values, h=1)\n",
    "\n",
    "            row_pval.append(p_val)\n",
    "            row_dm.append(dm_stat)\n",
    "\n",
    "        rows_pval.append(row_pval)\n",
    "        rows_dm.append(row_dm)\n",
    "\n",
    "    df_pval = pd.DataFrame(rows_pval, index=escenarios_usar, columns=col_names)\n",
    "    df_dm   = pd.DataFrame(rows_dm,   index=escenarios_usar, columns=col_names)\n",
    "\n",
    "    return df_pval, df_dm\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 4. CALCULAR TODAS LAS TABLAS Y BONFERRONI GLOBAL (POR TIPO)\n",
    "# ====================================================================================\n",
    "\n",
    "def compute_all_tables(tipo_escenario=None):\n",
    "    \"\"\"\n",
    "    Recorre todos los modelos, calcula las tablas de p-valores y determina\n",
    "    el α de Bonferroni global.\n",
    "    \n",
    "    Si tipo_escenario es None: análisis general\n",
    "    Si tipo_escenario especificado: solo ese tipo\n",
    "    \"\"\"\n",
    "    tipo_str = tipo_escenario if tipo_escenario else \"GENERAL\"\n",
    "    print(f\"\\n[Calculando tablas de p-valores - {tipo_str}]\")\n",
    "\n",
    "    all_pval_tables = {}\n",
    "    all_dm_tables   = {}\n",
    "    n_tests_total   = 0\n",
    "\n",
    "    for model in model_cols:\n",
    "        df_pval, df_dm = compute_pvalue_table(model, tipo_escenario)\n",
    "        all_pval_tables[model] = df_pval\n",
    "        all_dm_tables[model]   = df_dm\n",
    "        n_valid = int(df_pval.notna().sum().sum())\n",
    "        n_tests_total += n_valid\n",
    "\n",
    "    alpha_bonf = 0.05 / n_tests_total if n_tests_total > 0 else 0.05\n",
    "    print(f\"✓ Tests válidos totales: {n_tests_total}\")\n",
    "    print(f\"✓ α Bonferroni = 0.05 / {n_tests_total} = {alpha_bonf:.8f}\")\n",
    "\n",
    "    # ECRPS medio por (N_Total, modelo)\n",
    "    df_usar = df if tipo_escenario is None else df[df['ESCENARIO'] == tipo_escenario]\n",
    "    ecrps_data = {model: [df_usar[df_usar['N_Total'] == nt][model].mean()\n",
    "                           for nt in n_total_values]\n",
    "                  for model in model_cols}\n",
    "    df_ecrps = pd.DataFrame(ecrps_data, index=n_total_values)\n",
    "    df_ecrps.index.name = 'N_Total'\n",
    "\n",
    "    return all_pval_tables, all_dm_tables, alpha_bonf, df_ecrps\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 5. TABLA RESUMEN: % escenarios significativos por (N_Total, modelo)\n",
    "# ====================================================================================\n",
    "\n",
    "def compute_summary_pct(all_pval_tables, alpha_bonf):\n",
    "    \"\"\"\n",
    "    Tabla resumen % escenarios con diferencia significativa.\n",
    "    Filas = Tamaños N_Total, Columnas = Modelos\n",
    "    \"\"\"\n",
    "    pct_data = {}\n",
    "    for model in model_cols:\n",
    "        df_pval = all_pval_tables[model]\n",
    "        col_pct = []\n",
    "        for nt in n_total_values:\n",
    "            cols_nt = [c for c in df_pval.columns if f\"N={nt}\" in c]\n",
    "            vals = df_pval[cols_nt].values.flatten()\n",
    "            vals = vals[~np.isnan(vals)]\n",
    "            if len(vals) == 0:\n",
    "                col_pct.append(np.nan)\n",
    "            else:\n",
    "                col_pct.append(100.0 * np.sum(vals < alpha_bonf) / len(vals))\n",
    "        pct_data[model] = col_pct\n",
    "\n",
    "    df_pct = pd.DataFrame(pct_data, index=n_total_values)\n",
    "    df_pct.index.name = 'N_Total'\n",
    "    return df_pct\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 6. VISUALIZACIÓN: HEATMAP COMBINADO (ECRPS + % SIGNIFICANCIA)\n",
    "# ====================================================================================\n",
    "\n",
    "def plot_combined_heatmap(df_ecrps, df_pct, alpha_bonf, tipo_escenario=None):\n",
    "    \"\"\"\n",
    "    Heatmap resumen:\n",
    "      Fondo = % comparaciones significativas (verde alto, rojo bajo)\n",
    "      Anotación = \"ECRPS\\n(% sig)\"\n",
    "    \"\"\"\n",
    "    suffix = tipo_escenario.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\") if tipo_escenario else \"General\"\n",
    "    \n",
    "    n_rows = len(n_total_values)\n",
    "    n_cols = len(model_cols)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(max(14, n_cols * 1.4),\n",
    "                                    max(5,  n_rows * 0.9)))\n",
    "\n",
    "    annot = np.empty((n_rows, n_cols), dtype=object)\n",
    "    for i, nt in enumerate(n_total_values):\n",
    "        for j, model in enumerate(model_cols):\n",
    "            ecrps_val = df_ecrps.iloc[i, j]\n",
    "            pct_val   = df_pct.iloc[i, j]\n",
    "            if np.isnan(pct_val):\n",
    "                annot[i, j] = f\"{ecrps_val:.3f}\\n(—)\"\n",
    "            else:\n",
    "                annot[i, j] = f\"{ecrps_val:.3f}\\n({pct_val:.0f}%)\"\n",
    "\n",
    "    sns.heatmap(\n",
    "        df_pct,\n",
    "        annot=annot,\n",
    "        fmt='',\n",
    "        cmap='RdYlGn',\n",
    "        vmin=0, vmax=100, center=50,\n",
    "        linewidths=0.6, linecolor='white',\n",
    "        cbar_kws={'label': '% Escenarios con diferencia significativa (Bonferroni)',\n",
    "                  'shrink': 0.7},\n",
    "        ax=ax,\n",
    "        annot_kws={'fontsize': 8, 'va': 'center'}\n",
    "    )\n",
    "\n",
    "    title = f'ECRPS Medio y % Escenarios con Diferencia Significativa por Tamaño Muestral'\n",
    "    if tipo_escenario:\n",
    "        title += f'\\n{tipo_escenario}'\n",
    "    title += f'\\nCelda: ECRPS medio  |  (%) escenarios sign. Bonferroni  α = {alpha_bonf:.6f}'\n",
    "    \n",
    "    ax.set_title(title, fontweight='bold', fontsize=12, pad=15)\n",
    "    ax.set_xlabel('Modelo', fontweight='bold', fontsize=11)\n",
    "    ax.set_ylabel('Tamaño Muestral (N_Total)', fontweight='bold', fontsize=11)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha='right', fontsize=9)\n",
    "    ax.set_yticklabels([f'N={nt}' for nt in n_total_values], rotation=0, fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'heatmap_ecrps_significancia_{suffix}.png',\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Heatmap combinado guardado: {suffix}\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 7. HEATMAP: Z-SCORES POR MODELO\n",
    "# ====================================================================================\n",
    "\n",
    "def plot_heatmap_zscores(data, tipo_escenario=None):\n",
    "    \"\"\"\n",
    "    Heatmap de Modelos (filas) vs N_Total (columnas) con Z-scores\n",
    "    Z-score calculado POR MODELO (estandarización por fila)\n",
    "    \"\"\"\n",
    "    suffix = tipo_escenario.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\") if tipo_escenario else \"General\"\n",
    "    \n",
    "    if tipo_escenario:\n",
    "        data = data[data['ESCENARIO'] == tipo_escenario]\n",
    "    \n",
    "    # Crear matriz de ECRPS promedio\n",
    "    ecrps_data = []\n",
    "    for model in model_cols:\n",
    "        row = []\n",
    "        for nt in n_total_values:\n",
    "            ecrps_mean = data[data['N_Total'] == nt][model].mean()\n",
    "            row.append(ecrps_mean)\n",
    "        ecrps_data.append(row)\n",
    "    \n",
    "    ecrps_df = pd.DataFrame(ecrps_data, \n",
    "                             index=model_cols, \n",
    "                             columns=[f'N={nt}' for nt in n_total_values])\n",
    "    \n",
    "    # Calcular Z-scores POR MODELO (por fila)\n",
    "    zscore_df = ecrps_df.apply(lambda row: (row - row.mean()) / row.std() if row.std() > 0 else 0, axis=1)\n",
    "    \n",
    "    # Guardar datos\n",
    "    ecrps_df.to_excel(output_dir / f'heatmap_ecrps_{suffix}.xlsx')\n",
    "    zscore_df.to_excel(output_dir / f'heatmap_zscores_{suffix}.xlsx')\n",
    "    \n",
    "    # Graficar\n",
    "    plt.figure(figsize=(10, max(8, len(model_cols) * 0.4)))\n",
    "    sns.heatmap(zscore_df, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, vmin=-2, vmax=2,\n",
    "                cbar_kws={'label': 'Z-score'},\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    title = 'Z-scores de ECRPS: Modelos vs N_Total'\n",
    "    if tipo_escenario:\n",
    "        title += f'\\n{tipo_escenario}'\n",
    "    \n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Tamaño Muestral Total', fontsize=12)\n",
    "    plt.ylabel('Modelo', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'heatmap_zscore_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Heatmap Z-scores generado: {suffix}\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 8. GRÁFICA DE MEJORA RELATIVA\n",
    "# ====================================================================================\n",
    "\n",
    "def plot_relative_improvement(data, tipo_escenario=None):\n",
    "    \"\"\"Mejora relativa (%) respecto al tamaño base (primer N_Total)\"\"\"\n",
    "    suffix = tipo_escenario.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\") if tipo_escenario else \"General\"\n",
    "    \n",
    "    if tipo_escenario:\n",
    "        data = data[data['ESCENARIO'] == tipo_escenario]\n",
    "    \n",
    "    baseline = n_total_values[0]\n",
    "    improvements = {}\n",
    "    \n",
    "    for model in model_cols:\n",
    "        base_perf = data[data['N_Total'] == baseline][model].mean()\n",
    "        model_impr = []\n",
    "        for nt in n_total_values:\n",
    "            current = data[data['N_Total'] == nt][model].mean()\n",
    "            improvement = ((base_perf - current) / base_perf) * 100 if base_perf != 0 else 0\n",
    "            model_impr.append(improvement)\n",
    "        improvements[model] = model_impr\n",
    "    \n",
    "    # Guardar datos\n",
    "    improvements_df = pd.DataFrame(improvements, index=n_total_values)\n",
    "    improvements_df.index.name = 'N_Total'\n",
    "    improvements_df.to_excel(output_dir / f'mejora_relativa_{suffix}.xlsx')\n",
    "    \n",
    "    # Graficar\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    for model, values in improvements.items():\n",
    "        plt.plot(n_total_values, values, marker='o', label=model, \n",
    "                color=MODEL_COLORS[model], linewidth=2.5, markersize=8)\n",
    "    \n",
    "    plt.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    title = f'Mejora Relativa vs N={n_total_values[0]}'\n",
    "    if tipo_escenario:\n",
    "        title += f' - {tipo_escenario}'\n",
    "    \n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('N_Total', fontsize=12)\n",
    "    plt.ylabel('Mejora Relativa (%)', fontsize=12)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "    plt.grid(True, alpha=0.3, linestyle=':', linewidth=0.8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'mejora_relativa_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Mejora relativa generada: {suffix}\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 9. EXPORTAR EXCEL CONSOLIDADO\n",
    "# ====================================================================================\n",
    "\n",
    "def export_consolidated_excel(results_dict):\n",
    "    \"\"\"\n",
    "    Excel consolidado con todas las tablas de p-valores y resúmenes\n",
    "    \n",
    "    results_dict = {\n",
    "        'General': (all_pval_tables, all_dm_tables, alpha_bonf, df_ecrps, df_pct),\n",
    "        'ARMA': (...),\n",
    "        'ARIMA': (...),\n",
    "        'SETAR': (...)\n",
    "    }\n",
    "    \"\"\"\n",
    "    excel_path = output_dir / 'DM_tamaño_muestral_consolidado.xlsx'\n",
    "\n",
    "    with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "        wb = writer.book\n",
    "\n",
    "        # Formatos\n",
    "        fmt_hdr  = wb.add_format({'bold': True, 'bg_color': '#2E4057',\n",
    "                                   'font_color': 'white', 'align': 'center',\n",
    "                                   'valign': 'vcenter', 'border': 1})\n",
    "        fmt_sig  = wb.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100',\n",
    "                                   'align': 'center', 'border': 1})\n",
    "        fmt_no   = wb.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006',\n",
    "                                   'align': 'center', 'border': 1})\n",
    "\n",
    "        sheet_counter = 1\n",
    "        \n",
    "        for tipo, (all_pval_tables, all_dm_tables, alpha_bonf, df_ecrps, df_pct) in results_dict.items():\n",
    "            tipo_short = tipo.replace(\"Lineal Estacionario (ARMA)\", \"ARMA\") \\\n",
    "                             .replace(\"Lineal No Estacionario (ARIMA)\", \"ARIMA\") \\\n",
    "                             .replace(\"No lineal Estacionario (SETAR)\", \"SETAR\") \\\n",
    "                             .replace(\"General\", \"General\")\n",
    "            \n",
    "            # Hoja 1: ECRPS medios\n",
    "            sheet_name = f'{sheet_counter}_ECRPS_{tipo_short}'\n",
    "            df_ecrps.to_excel(writer, sheet_name=sheet_name)\n",
    "            ws = writer.sheets[sheet_name]\n",
    "            ws.set_column('A:A', 12)\n",
    "            ws.set_column('B:Z', 18)\n",
    "            for c, col in enumerate(df_ecrps.columns, 1):\n",
    "                ws.write(0, c, col, fmt_hdr)\n",
    "            sheet_counter += 1\n",
    "            \n",
    "            # Hoja 2: % Significancia\n",
    "            sheet_name = f'{sheet_counter}_PctSig_{tipo_short}'\n",
    "            df_pct.to_excel(writer, sheet_name=sheet_name)\n",
    "            ws2 = writer.sheets[sheet_name]\n",
    "            ws2.set_column('A:A', 12)\n",
    "            ws2.set_column('B:Z', 18)\n",
    "            for c, col in enumerate(df_pct.columns, 1):\n",
    "                ws2.write(0, c, col, fmt_hdr)\n",
    "            for c in range(1, len(model_cols) + 1):\n",
    "                ws2.conditional_format(1, c, len(n_total_values), c,\n",
    "                    {'type': 'cell', 'criteria': '>=', 'value': 50, 'format': fmt_sig})\n",
    "                ws2.conditional_format(1, c, len(n_total_values), c,\n",
    "                    {'type': 'cell', 'criteria': '<',  'value': 50, 'format': fmt_no})\n",
    "            sheet_counter += 1\n",
    "\n",
    "        # Hoja final: Metodología\n",
    "        meta = pd.DataFrame({\n",
    "            'Parámetro': [\n",
    "                'Unidad de escenario',\n",
    "                'Emparejamiento dentro del test DM',\n",
    "                'Test estadístico',\n",
    "                'Corrección de muestra pequeña',\n",
    "                'Corrección de multiplicidad',\n",
    "                'α nominal',\n",
    "                'Métrica de pérdida',\n",
    "                'Modelos evaluados',\n",
    "                'Tamaños N_Total',\n",
    "                'Tipos de escenario',\n",
    "                'Escenarios únicos totales'\n",
    "            ],\n",
    "            'Valor': [\n",
    "                'Combinación única (Proceso, Distribución, Varianza)',\n",
    "                'Inner-join por columna Paso (réplica de simulación)',\n",
    "                'Diebold-Mariano bilateral',\n",
    "                'Harvey, Leybourne & Newbold (1997)',\n",
    "                'Bonferroni sobre todos los tests válidos (por tipo)',\n",
    "                0.05,\n",
    "                'ECRPS',\n",
    "                ', '.join(model_cols),\n",
    "                ', '.join(map(str, n_total_values)),\n",
    "                ', '.join(tipos_escenario),\n",
    "                len(escenarios_unicos)\n",
    "            ]\n",
    "        })\n",
    "        meta.to_excel(writer, sheet_name='ZZ_Metodologia', index=False)\n",
    "        ws_m = writer.sheets['ZZ_Metodologia']\n",
    "        ws_m.set_column('A:A', 45)\n",
    "        ws_m.set_column('B:B', 80)\n",
    "\n",
    "    print(f\"\\n✓ Excel consolidado guardado: {excel_path}\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 10. EJECUCIÓN PRINCIPAL\n",
    "# ====================================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ANÁLISIS DM CORREGIDO — EFECTOS DEL TAMAÑO MUESTRAL\")\n",
    "    print(\"Escenario = combinación única (Proceso × Distribución × Varianza)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Diccionario para guardar todos los resultados\n",
    "    all_results = {}\n",
    "    \n",
    "    # ============================================================\n",
    "    # ANÁLISIS GENERAL\n",
    "    # ============================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISIS GENERAL (TODOS LOS ESCENARIOS)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    all_pval_tables, all_dm_tables, alpha_bonf, df_ecrps = compute_all_tables(tipo_escenario=None)\n",
    "    df_pct = compute_summary_pct(all_pval_tables, alpha_bonf)\n",
    "    \n",
    "    all_results['General'] = (all_pval_tables, all_dm_tables, alpha_bonf, df_ecrps, df_pct)\n",
    "    \n",
    "    print(\"\\n[Generando visualizaciones - GENERAL]\")\n",
    "    plot_combined_heatmap(df_ecrps, df_pct, alpha_bonf, tipo_escenario=None)\n",
    "    plot_heatmap_zscores(df, tipo_escenario=None)\n",
    "    plot_relative_improvement(df, tipo_escenario=None)\n",
    "    \n",
    "    # ============================================================\n",
    "    # ANÁLISIS POR TIPO DE ESCENARIO\n",
    "    # ============================================================\n",
    "    for tipo in tipos_escenario:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"ANÁLISIS: {tipo}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        all_pval_tables, all_dm_tables, alpha_bonf, df_ecrps = compute_all_tables(tipo_escenario=tipo)\n",
    "        df_pct = compute_summary_pct(all_pval_tables, alpha_bonf)\n",
    "        \n",
    "        all_results[tipo] = (all_pval_tables, all_dm_tables, alpha_bonf, df_ecrps, df_pct)\n",
    "        \n",
    "        print(f\"\\n[Generando visualizaciones - {tipo}]\")\n",
    "        plot_combined_heatmap(df_ecrps, df_pct, alpha_bonf, tipo_escenario=tipo)\n",
    "        plot_heatmap_zscores(df, tipo_escenario=tipo)\n",
    "        plot_relative_improvement(df, tipo_escenario=tipo)\n",
    "    \n",
    "    # ============================================================\n",
    "    # EXPORTAR EXCEL CONSOLIDADO\n",
    "    # ============================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPORTANDO EXCEL CONSOLIDADO\")\n",
    "    print(\"=\"*80)\n",
    "    export_consolidated_excel(all_results)\n",
    "    \n",
    "    # ============================================================\n",
    "    # RESUMEN FINAL\n",
    "    # ============================================================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"✓ ANÁLISIS COMPLETADO\")\n",
    "    print(f\"✓ Resultados en: {output_dir}\")\n",
    "    print(\"\\nArchivos generados:\")\n",
    "    print(\"  1. HEATMAPS COMBINADOS (ECRPS + % Significancia):\")\n",
    "    print(\"     - 4 archivos .png (General + ARMA + ARIMA + SETAR)\")\n",
    "    print(\"  2. HEATMAPS Z-SCORES:\")\n",
    "    print(\"     - 4 archivos .png + 8 .xlsx (General + ARMA + ARIMA + SETAR)\")\n",
    "    print(\"  3. CURVAS DE MEJORA RELATIVA:\")\n",
    "    print(\"     - 4 archivos .png + 4 .xlsx (General + ARMA + ARIMA + SETAR)\")\n",
    "    print(\"  4. EXCEL CONSOLIDADO:\")\n",
    "    print(\"     - 1 archivo con 9 hojas (2 por análisis + metodología)\")\n",
    "    print(\"\\nMETODOLOGÍA:\")\n",
    "    print(\"  - Test DM: HAC Newey-West + corrección HLN (1997)\")\n",
    "    print(\"  - Emparejamiento: por Paso dentro de cada escenario único\")\n",
    "    print(\"  - Corrección: Bonferroni por tipo de análisis\")\n",
    "    print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0a2b92",
   "metadata": {},
   "source": [
    "## Analisis proporciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52209586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SIMULACIÓN 4: PROPORCIONES DE CALIBRACIÓN (N=240 FIJO)\n",
      "CON TEST DIEBOLD-MARIANO MODIFICADO Y CORRECCIÓN DE BONFERRONI\n",
      "================================================================================\n",
      "\n",
      "Modelos evaluados: 9\n",
      "Proporciones: [np.int64(10), np.int64(20), np.int64(30), np.int64(40), np.int64(50)]\n",
      "Escenarios: ['Lineal Estacionario (ARMA)', 'Lineal No Estacionario (ARIMA)', 'No Lineal Estacionario (SETAR)']\n",
      "Escenarios únicos (Proceso × Dist × Var): 420\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DM CON FIXED-SMOOTHING ASYMPTOTICS — EFECTOS DE LA PROPORCIÓN\n",
      "Escenario = combinación única (Proceso × Distribución × Varianza)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS GENERAL (TODOS LOS ESCENARIOS)\n",
      "================================================================================\n",
      "\n",
      "[Calculando tablas de p-valores - GENERAL]\n",
      "✓ Tests válidos totales: 37800\n",
      "✓ α Bonferroni = 0.05 / 37800 = 0.00000132\n",
      "\n",
      "[Generando visualizaciones - GENERAL]\n",
      "✓ Heatmap combinado guardado: General\n",
      "✓ Heatmap Z-scores generado: General\n",
      "✓ Mejora relativa generada: General\n",
      "✓ Evolución por proporción generada: General\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS: Lineal Estacionario (ARMA)\n",
      "================================================================================\n",
      "\n",
      "[Calculando tablas de p-valores - Lineal Estacionario (ARMA)]\n",
      "✓ Tests válidos totales: 12600\n",
      "✓ α Bonferroni = 0.05 / 12600 = 0.00000397\n",
      "\n",
      "[Generando visualizaciones - Lineal Estacionario (ARMA)]\n",
      "✓ Heatmap combinado guardado: Lineal_Estacionario_ARMA\n",
      "✓ Heatmap Z-scores generado: Lineal_Estacionario_ARMA\n",
      "✓ Mejora relativa generada: Lineal_Estacionario_ARMA\n",
      "✓ Evolución por proporción generada: Lineal_Estacionario_ARMA\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS: Lineal No Estacionario (ARIMA)\n",
      "================================================================================\n",
      "\n",
      "[Calculando tablas de p-valores - Lineal No Estacionario (ARIMA)]\n",
      "✓ Tests válidos totales: 12600\n",
      "✓ α Bonferroni = 0.05 / 12600 = 0.00000397\n",
      "\n",
      "[Generando visualizaciones - Lineal No Estacionario (ARIMA)]\n",
      "✓ Heatmap combinado guardado: Lineal_No_Estacionario_ARIMA\n",
      "✓ Heatmap Z-scores generado: Lineal_No_Estacionario_ARIMA\n",
      "✓ Mejora relativa generada: Lineal_No_Estacionario_ARIMA\n",
      "✓ Evolución por proporción generada: Lineal_No_Estacionario_ARIMA\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS: No Lineal Estacionario (SETAR)\n",
      "================================================================================\n",
      "\n",
      "[Calculando tablas de p-valores - No Lineal Estacionario (SETAR)]\n",
      "✓ Tests válidos totales: 12600\n",
      "✓ α Bonferroni = 0.05 / 12600 = 0.00000397\n",
      "\n",
      "[Generando visualizaciones - No Lineal Estacionario (SETAR)]\n",
      "✓ Heatmap combinado guardado: No_Lineal_Estacionario_SETAR\n",
      "✓ Heatmap Z-scores generado: No_Lineal_Estacionario_SETAR\n",
      "✓ Mejora relativa generada: No_Lineal_Estacionario_SETAR\n",
      "✓ Evolución por proporción generada: No_Lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE PROPORCIÓN ÓPTIMA Y SENSIBILIDAD\n",
      "================================================================================\n",
      "✓ Análisis proporción óptima generado: General\n",
      "✓ Análisis proporción óptima generado: Lineal_Estacionario_ARMA\n",
      "✓ Análisis proporción óptima generado: Lineal_No_Estacionario_ARIMA\n",
      "✓ Análisis proporción óptima generado: No_Lineal_Estacionario_SETAR\n",
      "✓ Análisis de sensibilidad generado: General\n",
      "✓ Análisis de sensibilidad generado: Lineal_Estacionario_ARMA\n",
      "✓ Análisis de sensibilidad generado: Lineal_No_Estacionario_ARIMA\n",
      "✓ Análisis de sensibilidad generado: No_Lineal_Estacionario_SETAR\n",
      "\n",
      "================================================================================\n",
      "EXPORTANDO EXCEL CONSOLIDADO\n",
      "================================================================================\n",
      "\n",
      "✓ Excel consolidado guardado: Resultados_analisis\\Proporciones\\DM_proporciones_consolidado.xlsx\n",
      "\n",
      "================================================================================\n",
      "✓ ANÁLISIS COMPLETADO\n",
      "✓ Resultados en: Resultados_analisis\\Proporciones\n",
      "\n",
      "Archivos generados:\n",
      "  1. HEATMAPS COMBINADOS (ECRPS + % Significancia):\n",
      "     - 4 archivos .png (General + ARMA + ARIMA + SETAR)\n",
      "  2. HEATMAPS Z-SCORES:\n",
      "     - 4 archivos .png + 8 .xlsx (General + ARMA + ARIMA + SETAR)\n",
      "  3. CURVAS DE MEJORA RELATIVA:\n",
      "     - 4 archivos .png + 4 .xlsx (General + ARMA + ARIMA + SETAR)\n",
      "  4. CURVAS DE EVOLUCIÓN:\n",
      "     - 4 archivos .png (General + ARMA + ARIMA + SETAR)\n",
      "  5. ANÁLISIS PROPORCIÓN ÓPTIMA:\n",
      "     - 4 archivos .png + 4 .xlsx (General + ARMA + ARIMA + SETAR)\n",
      "  6. ANÁLISIS DE SENSIBILIDAD:\n",
      "     - 4 archivos .png + 4 .xlsx (General + ARMA + ARIMA + SETAR)\n",
      "  7. EXCEL CONSOLIDADO:\n",
      "     - 1 archivo con 9 hojas (2 por análisis + metodología)\n",
      "\n",
      "METODOLOGÍA:\n",
      "  - Test DM: Fixed-smoothing asymptotics con estimación espectral\n",
      "  - Bandwidth: T^(1/3) para estimación de varianza de largo plazo\n",
      "  - Emparejamiento: por Paso dentro de cada escenario único\n",
      "  - Corrección: Bonferroni por tipo de análisis\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "# ====================================================================================\n",
    "# 1. CONFIGURACIÓN Y PREPARACIÓN DE DATOS\n",
    "# ====================================================================================\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de gráficas\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# Rutas\n",
    "output_dir = Path(\"./Resultados_analisis/Proporciones\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "try:\n",
    "    df = pd.read_excel(\"./datos/Simulacion/proporciones/resultados_PROPORCIONES_240_TODOS.xlsx\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: No se encontró el archivo Excel. Verifica la ruta.\")\n",
    "    exit()\n",
    "\n",
    "# Renombrar escenarios\n",
    "df['Tipo_Proceso'] = df['Tipo_Proceso'].replace({\n",
    "    \"ARMA\": \"Lineal Estacionario (ARMA)\",\n",
    "    \"ARIMA\": \"Lineal No Estacionario (ARIMA)\",\n",
    "    \"SETAR\": \"No Lineal Estacionario (SETAR)\"\n",
    "})\n",
    "\n",
    "# Limpiar Prop_Calib\n",
    "def clean_prop_calib(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value_str = str(value).strip()\n",
    "    if '%' in value_str:\n",
    "        value_str = value_str.split('%')[0]\n",
    "    try:\n",
    "        value_num = float(value_str)\n",
    "        if value_num < 1:\n",
    "            return int(value_num * 100)\n",
    "        else:\n",
    "            return int(value_num)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['Prop_Calib_Pct'] = df['Prop_Calib'].apply(clean_prop_calib)\n",
    "df['Prop_Calib'] = df['Prop_Calib_Pct'] / 100\n",
    "\n",
    "# Limpiar Paso\n",
    "def clean_paso(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value_str = str(value).strip()\n",
    "    import re\n",
    "    numbers = re.findall(r'\\d+', value_str)\n",
    "    if numbers:\n",
    "        return int(numbers[0])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df['Paso'] = df['Paso'].apply(clean_paso)\n",
    "\n",
    "# Identificación de variables y modelos\n",
    "var_cols = ['Paso', 'Proceso', 'Distribución', 'Varianza', \n",
    "            'N_Train', 'N_Calib', 'Prop_Calib', 'Prop_Calib_Pct', 'Tipo_Proceso']\n",
    "model_cols = [col for col in df.columns if col not in var_cols and pd.api.types.is_numeric_dtype(df[col])]\n",
    "\n",
    "# Limpiar datos numéricos\n",
    "for col in ['N_Train', 'N_Calib', 'Varianza', 'Paso']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "for model in model_cols:\n",
    "    df[model] = pd.to_numeric(df[model], errors='coerce')\n",
    "\n",
    "# Eliminar NaN\n",
    "critical_cols = ['Paso', 'Prop_Calib_Pct', 'N_Train', 'N_Calib'] + model_cols\n",
    "df = df.dropna(subset=critical_cols)\n",
    "\n",
    "prop_values = sorted(df['Prop_Calib_Pct'].unique())\n",
    "escenarios = sorted(df['Tipo_Proceso'].unique())\n",
    "\n",
    "# Crear escenario_id único (Proceso | Distribución | Varianza)\n",
    "df['escenario_id'] = (df['Proceso'].astype(str) + ' | ' +\n",
    "                      df['Distribución'].astype(str) + ' | ' +\n",
    "                      df['Varianza'].astype(str))\n",
    "\n",
    "escenarios_unicos = sorted(df['escenario_id'].unique())\n",
    "\n",
    "# ====================================================================================\n",
    "# PALETA DE COLORES ÚNICA PARA MODELOS\n",
    "# ====================================================================================\n",
    "def generate_maximally_distinct_colors(n):\n",
    "    if n <= 10:\n",
    "        base_colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "        return base_colors[:n]\n",
    "    elif n <= 20:\n",
    "        base_colors = plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "        return base_colors[:n]\n",
    "    else:\n",
    "        colors = []\n",
    "        tab20 = plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "        colors.extend(tab20)\n",
    "        \n",
    "        if n > 20:\n",
    "            set3 = plt.cm.Set3(np.linspace(0, 1, 12))\n",
    "            colors.extend(set3)\n",
    "        \n",
    "        if n > 32:\n",
    "            paired = plt.cm.Paired(np.linspace(0, 1, 12))\n",
    "            colors.extend(paired)\n",
    "        \n",
    "        if n > 44:\n",
    "            remaining = n - len(colors)\n",
    "            hsv_colors = []\n",
    "            for i in range(remaining):\n",
    "                hue = (i * 0.618033988749895) % 1.0\n",
    "                saturation = 0.6 + (i % 3) * 0.15\n",
    "                value = 0.7 + (i % 2) * 0.2\n",
    "                rgb = plt.cm.hsv(hue)\n",
    "                hsv_colors.append(rgb)\n",
    "            colors.extend(hsv_colors)\n",
    "        \n",
    "        return np.array(colors[:n])\n",
    "\n",
    "MODEL_COLORS = dict(zip(model_cols, generate_maximally_distinct_colors(len(model_cols))))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"SIMULACIÓN 4: PROPORCIONES DE CALIBRACIÓN (N=240 FIJO)\")\n",
    "print(f\"CON TEST DIEBOLD-MARIANO MODIFICADO Y CORRECCIÓN DE BONFERRONI\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nModelos evaluados: {len(model_cols)}\")\n",
    "print(f\"Proporciones: {prop_values}\")\n",
    "print(f\"Escenarios: {list(escenarios)}\")\n",
    "print(f\"Escenarios únicos (Proceso × Dist × Var): {len(escenarios_unicos)}\\n\")\n",
    "\n",
    "# ====================================================================================\n",
    "# 2. TEST DIEBOLD-MARIANO MODIFICADO (NUEVA IMPLEMENTACIÓN)\n",
    "#    Fixed-smoothing asymptotics con estimación espectral\n",
    "# ====================================================================================\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano con fixed-smoothing asymptotics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    errors1, errors2 : array-like\n",
    "        Pérdidas/errores de los dos métodos a comparar\n",
    "    h : int\n",
    "        Horizonte de pronóstico (default=1)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dm_stat : float\n",
    "        Estadístico DM\n",
    "    p_value : float\n",
    "        P-valor bilateral\n",
    "    mean_diff : float\n",
    "        Diferencia media de pérdidas\n",
    "    \"\"\"\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    if T < 2: \n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    # Desviaciones centradas\n",
    "    u = d - d_bar\n",
    "    \n",
    "    # Bandwidth para fixed-smoothing asymptotics\n",
    "    m = max(1, int(np.floor(T**(1/3))))\n",
    "    \n",
    "    # Estimación espectral usando periodograma\n",
    "    from scipy.fft import fft\n",
    "    fft_u = fft(u)\n",
    "    periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "    \n",
    "    # Asegurar que m no exceda el tamaño del periodograma\n",
    "    if m >= len(periodogram) - 1: \n",
    "        m = len(periodogram) - 2\n",
    "    \n",
    "    # Varianza de largo plazo (long-run variance)\n",
    "    sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "    \n",
    "    # Fallback si la estimación es no positiva\n",
    "    if sigma_hat_sq <= 0: \n",
    "        sigma_hat_sq = np.var(d, ddof=1) / T\n",
    "    \n",
    "    # Estadístico DM\n",
    "    dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "    \n",
    "    # Grados de libertad para distribución t\n",
    "    df_t = 2 * m\n",
    "    \n",
    "    # P-valor bilateral\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(dm_stat), df_t))\n",
    "    \n",
    "    return dm_stat, p_value, d_bar\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 3. FUNCIÓN CENTRAL: tabla de p-valores por modelo (POR TIPO DE ESCENARIO)\n",
    "# ====================================================================================\n",
    "\n",
    "def compute_pvalue_table_props(model, tipo_escenario=None):\n",
    "    \"\"\"\n",
    "    Genera la tabla detallada de p-valores para un modelo comparando proporciones.\n",
    "    \n",
    "    Si tipo_escenario es None: usa todos los escenarios\n",
    "    Si tipo_escenario es especificado: filtra solo ese tipo\n",
    "    \n",
    "    Filas    = escenario único (Proceso | Dist | Var)\n",
    "    Columnas = par de proporciones (Prop=p1 vs Prop=p2)\n",
    "\n",
    "    Emparejamiento: inner-join por 'Paso' entre Prop=p1 y Prop=p2\n",
    "    dentro del mismo escenario → misma réplica de simulación.\n",
    "    \"\"\"\n",
    "    # Filtrar datos si se especifica tipo de escenario\n",
    "    if tipo_escenario:\n",
    "        df_filtrado = df[df['Tipo_Proceso'] == tipo_escenario]\n",
    "        escenarios_usar = sorted(df_filtrado['escenario_id'].unique())\n",
    "    else:\n",
    "        df_filtrado = df\n",
    "        escenarios_usar = escenarios_unicos\n",
    "    \n",
    "    prop_pairs = list(combinations(prop_values, 2))\n",
    "    col_names = [f\"Prop={p1}% vs Prop={p2}%\" for p1, p2 in prop_pairs]\n",
    "\n",
    "    rows_pval, rows_dm, rows_diff = [], [], []\n",
    "\n",
    "    for esc_id in escenarios_usar:\n",
    "        subset_esc = df_filtrado[df_filtrado['escenario_id'] == esc_id]\n",
    "\n",
    "        row_pval, row_dm, row_diff = [], [], []\n",
    "\n",
    "        for (p1, p2) in prop_pairs:\n",
    "            s1 = (subset_esc[subset_esc['Prop_Calib_Pct'] == p1][['Paso', model]]\n",
    "                  .rename(columns={model: 'l1'}))\n",
    "            s2 = (subset_esc[subset_esc['Prop_Calib_Pct'] == p2][['Paso', model]]\n",
    "                  .rename(columns={model: 'l2'}))\n",
    "\n",
    "            paired = pd.merge(s1, s2, on='Paso', how='inner').dropna()\n",
    "            n_pairs = len(paired)\n",
    "\n",
    "            if n_pairs < 5:\n",
    "                row_pval.append(np.nan)\n",
    "                row_dm.append(np.nan)\n",
    "                row_diff.append(np.nan)\n",
    "                continue\n",
    "\n",
    "            dm_stat, p_val, mean_diff = modified_diebold_mariano_test(\n",
    "                paired['l1'].values, paired['l2'].values, h=1)\n",
    "\n",
    "            row_pval.append(p_val)\n",
    "            row_dm.append(dm_stat)\n",
    "            row_diff.append(mean_diff)\n",
    "\n",
    "        rows_pval.append(row_pval)\n",
    "        rows_dm.append(row_dm)\n",
    "        rows_diff.append(row_diff)\n",
    "\n",
    "    df_pval = pd.DataFrame(rows_pval, index=escenarios_usar, columns=col_names)\n",
    "    df_dm   = pd.DataFrame(rows_dm,   index=escenarios_usar, columns=col_names)\n",
    "    df_diff = pd.DataFrame(rows_diff, index=escenarios_usar, columns=col_names)\n",
    "\n",
    "    return df_pval, df_dm, df_diff\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 4. CALCULAR TODAS LAS TABLAS Y BONFERRONI GLOBAL (POR TIPO)\n",
    "# ====================================================================================\n",
    "\n",
    "def compute_all_tables(tipo_escenario=None):\n",
    "    \"\"\"\n",
    "    Recorre todos los modelos, calcula las tablas de p-valores y determina\n",
    "    el α de Bonferroni global.\n",
    "    \n",
    "    Si tipo_escenario es None: análisis general\n",
    "    Si tipo_escenario especificado: solo ese tipo\n",
    "    \"\"\"\n",
    "    tipo_str = tipo_escenario if tipo_escenario else \"GENERAL\"\n",
    "    print(f\"\\n[Calculando tablas de p-valores - {tipo_str}]\")\n",
    "\n",
    "    all_pval_tables = {}\n",
    "    all_dm_tables   = {}\n",
    "    all_diff_tables = {}\n",
    "    n_tests_total   = 0\n",
    "\n",
    "    for model in model_cols:\n",
    "        df_pval, df_dm, df_diff = compute_pvalue_table_props(model, tipo_escenario)\n",
    "        all_pval_tables[model] = df_pval\n",
    "        all_dm_tables[model]   = df_dm\n",
    "        all_diff_tables[model] = df_diff\n",
    "        n_valid = int(df_pval.notna().sum().sum())\n",
    "        n_tests_total += n_valid\n",
    "\n",
    "    alpha_bonf = 0.05 / n_tests_total if n_tests_total > 0 else 0.05\n",
    "    print(f\"✓ Tests válidos totales: {n_tests_total}\")\n",
    "    print(f\"✓ α Bonferroni = 0.05 / {n_tests_total} = {alpha_bonf:.8f}\")\n",
    "\n",
    "    # ECRPS medio por (Prop_Calib_Pct, modelo)\n",
    "    df_usar = df if tipo_escenario is None else df[df['Tipo_Proceso'] == tipo_escenario]\n",
    "    ecrps_data = {model: [df_usar[df_usar['Prop_Calib_Pct'] == prop][model].mean()\n",
    "                           for prop in prop_values]\n",
    "                  for model in model_cols}\n",
    "    df_ecrps = pd.DataFrame(ecrps_data, index=prop_values)\n",
    "    df_ecrps.index.name = 'Prop_Calib_%'\n",
    "\n",
    "    return all_pval_tables, all_dm_tables, all_diff_tables, alpha_bonf, df_ecrps\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 5. TABLA RESUMEN: % escenarios significativos por (Proporción, modelo)\n",
    "# ====================================================================================\n",
    "\n",
    "def compute_summary_pct(all_pval_tables, alpha_bonf):\n",
    "    \"\"\"\n",
    "    Tabla resumen % escenarios con diferencia significativa.\n",
    "    Filas = Proporciones, Columnas = Modelos\n",
    "    \"\"\"\n",
    "    pct_data = {}\n",
    "    for model in model_cols:\n",
    "        df_pval = all_pval_tables[model]\n",
    "        col_pct = []\n",
    "        for prop in prop_values:\n",
    "            cols_prop = [c for c in df_pval.columns if f\"Prop={prop}%\" in c]\n",
    "            vals = df_pval[cols_prop].values.flatten()\n",
    "            vals = vals[~np.isnan(vals)]\n",
    "            if len(vals) == 0:\n",
    "                col_pct.append(np.nan)\n",
    "            else:\n",
    "                col_pct.append(100.0 * np.sum(vals < alpha_bonf) / len(vals))\n",
    "        pct_data[model] = col_pct\n",
    "\n",
    "    df_pct = pd.DataFrame(pct_data, index=prop_values)\n",
    "    df_pct.index.name = 'Prop_Calib_%'\n",
    "    return df_pct\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 6. VISUALIZACIÓN: HEATMAP COMBINADO (ECRPS + % SIGNIFICANCIA)\n",
    "# ====================================================================================\n",
    "\n",
    "def plot_combined_heatmap(df_ecrps, df_pct, alpha_bonf, tipo_escenario=None):\n",
    "    \"\"\"\n",
    "    Heatmap resumen:\n",
    "      Fondo = % comparaciones significativas (verde alto, rojo bajo)\n",
    "      Anotación = \"ECRPS\\n(% sig)\"\n",
    "    \"\"\"\n",
    "    suffix = tipo_escenario.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\") if tipo_escenario else \"General\"\n",
    "    \n",
    "    n_rows = len(prop_values)\n",
    "    n_cols = len(model_cols)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(max(14, n_cols * 1.4),\n",
    "                                    max(5,  n_rows * 0.9)))\n",
    "\n",
    "    annot = np.empty((n_rows, n_cols), dtype=object)\n",
    "    for i, prop in enumerate(prop_values):\n",
    "        for j, model in enumerate(model_cols):\n",
    "            ecrps_val = df_ecrps.iloc[i, j]\n",
    "            pct_val   = df_pct.iloc[i, j]\n",
    "            if np.isnan(pct_val):\n",
    "                annot[i, j] = f\"{ecrps_val:.3f}\\n(—)\"\n",
    "            else:\n",
    "                annot[i, j] = f\"{ecrps_val:.3f}\\n({pct_val:.0f}%)\"\n",
    "\n",
    "    sns.heatmap(\n",
    "        df_pct,\n",
    "        annot=annot,\n",
    "        fmt='',\n",
    "        cmap='RdYlGn',\n",
    "        vmin=0, vmax=100, center=50,\n",
    "        linewidths=0.6, linecolor='white',\n",
    "        cbar_kws={'label': '% Escenarios con diferencia significativa (Bonferroni)',\n",
    "                  'shrink': 0.7},\n",
    "        ax=ax,\n",
    "        annot_kws={'fontsize': 8, 'va': 'center'}\n",
    "    )\n",
    "\n",
    "    title = f'ECRPS Medio y % Escenarios con Diferencia Significativa por Proporción de Calibración'\n",
    "    if tipo_escenario:\n",
    "        title += f'\\n{tipo_escenario}'\n",
    "    title += f'\\nCelda: ECRPS medio  |  (%) escenarios sign. Bonferroni  α = {alpha_bonf:.6f}'\n",
    "    \n",
    "    ax.set_title(title, fontweight='bold', fontsize=12, pad=15)\n",
    "    ax.set_xlabel('Modelo', fontweight='bold', fontsize=11)\n",
    "    ax.set_ylabel('Proporción de Calibración (%)', fontweight='bold', fontsize=11)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha='right', fontsize=9)\n",
    "    ax.set_yticklabels([f'{prop}%' for prop in prop_values], rotation=0, fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'heatmap_ecrps_significancia_{suffix}.png',\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Heatmap combinado guardado: {suffix}\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 7. HEATMAP: Z-SCORES POR MODELO\n",
    "# ====================================================================================\n",
    "\n",
    "def plot_heatmap_zscores(data, tipo_escenario=None):\n",
    "    \"\"\"\n",
    "    Heatmap de Modelos (filas) vs Proporciones (columnas) con Z-scores\n",
    "    Z-score calculado POR MODELO (estandarización por fila)\n",
    "    \"\"\"\n",
    "    suffix = tipo_escenario.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\") if tipo_escenario else \"General\"\n",
    "    \n",
    "    if tipo_escenario:\n",
    "        data = data[data['Tipo_Proceso'] == tipo_escenario]\n",
    "    \n",
    "    # Crear matriz de ECRPS promedio\n",
    "    ecrps_data = []\n",
    "    for model in model_cols:\n",
    "        row = []\n",
    "        for prop in prop_values:\n",
    "            ecrps_mean = data[data['Prop_Calib_Pct'] == prop][model].mean()\n",
    "            row.append(ecrps_mean)\n",
    "        ecrps_data.append(row)\n",
    "    \n",
    "    ecrps_df = pd.DataFrame(ecrps_data, \n",
    "                             index=model_cols, \n",
    "                             columns=[f'{p}%' for p in prop_values])\n",
    "    \n",
    "    # Calcular Z-scores POR MODELO (por fila)\n",
    "    zscore_df = ecrps_df.apply(lambda row: (row - row.mean()) / row.std() if row.std() > 0 else 0, axis=1)\n",
    "    \n",
    "    # Guardar datos\n",
    "    ecrps_df.to_excel(output_dir / f'heatmap_ecrps_{suffix}.xlsx')\n",
    "    zscore_df.to_excel(output_dir / f'heatmap_zscores_{suffix}.xlsx')\n",
    "    \n",
    "    # Graficar\n",
    "    plt.figure(figsize=(10, max(8, len(model_cols) * 0.4)))\n",
    "    sns.heatmap(zscore_df, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, vmin=-2, vmax=2,\n",
    "                cbar_kws={'label': 'Z-score'},\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    title = 'Z-scores de ECRPS: Modelos vs Proporción de Calibración'\n",
    "    if tipo_escenario:\n",
    "        title += f'\\n{tipo_escenario}'\n",
    "    \n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Proporción de Calibración', fontsize=12)\n",
    "    plt.ylabel('Modelo', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'heatmap_zscore_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Heatmap Z-scores generado: {suffix}\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 8. GRÁFICA DE MEJORA RELATIVA\n",
    "# ====================================================================================\n",
    "\n",
    "def plot_relative_improvement(data, tipo_escenario=None):\n",
    "    \"\"\"Mejora relativa (%) respecto a la proporción base (primera proporción)\"\"\"\n",
    "    suffix = tipo_escenario.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\") if tipo_escenario else \"General\"\n",
    "    \n",
    "    if tipo_escenario:\n",
    "        data = data[data['Tipo_Proceso'] == tipo_escenario]\n",
    "    \n",
    "    baseline = prop_values[0]\n",
    "    improvements = {}\n",
    "    \n",
    "    for model in model_cols:\n",
    "        base_perf = data[data['Prop_Calib_Pct'] == baseline][model].mean()\n",
    "        model_impr = []\n",
    "        for prop in prop_values:\n",
    "            current = data[data['Prop_Calib_Pct'] == prop][model].mean()\n",
    "            improvement = ((base_perf - current) / base_perf) * 100 if base_perf != 0 else 0\n",
    "            model_impr.append(improvement)\n",
    "        improvements[model] = model_impr\n",
    "    \n",
    "    # Guardar datos\n",
    "    improvements_df = pd.DataFrame(improvements, index=prop_values)\n",
    "    improvements_df.index.name = 'Prop_Calib_%'\n",
    "    improvements_df.to_excel(output_dir / f'mejora_relativa_{suffix}.xlsx')\n",
    "    \n",
    "    # Graficar\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    for model, values in improvements.items():\n",
    "        plt.plot(prop_values, values, marker='o', label=model, \n",
    "                color=MODEL_COLORS[model], linewidth=2.5, markersize=8)\n",
    "    \n",
    "    plt.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    title = f'Mejora Relativa vs Proporción Base ({baseline}%)'\n",
    "    if tipo_escenario:\n",
    "        title += f' - {tipo_escenario}'\n",
    "    \n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Proporción de Calibración (%)', fontsize=12)\n",
    "    plt.ylabel('Mejora Relativa (%)', fontsize=12)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "    plt.grid(True, alpha=0.3, linestyle=':', linewidth=0.8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'mejora_relativa_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Mejora relativa generada: {suffix}\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 9. GRÁFICA DE EVOLUCIÓN POR PROPORCIÓN\n",
    "# ====================================================================================\n",
    "\n",
    "def plot_evolution_by_proportion(data, scenario_name=None):\n",
    "    \"\"\"Evolución del ECRPS de cada modelo a través de proporciones\"\"\"\n",
    "    if scenario_name:\n",
    "        data = data[data['Tipo_Proceso'] == scenario_name]\n",
    "        suffix = scenario_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Evolución del ECRPS por Proporción\\n{scenario_name}'\n",
    "    else:\n",
    "        suffix = \"General\"\n",
    "        title = 'Evolución del ECRPS por Proporción\\nTodos los Escenarios'\n",
    "    \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    for model in model_cols:\n",
    "        means = [data[data['Prop_Calib_Pct'] == p][model].mean() for p in prop_values]\n",
    "        plt.plot(prop_values, means, marker='o', label=model, \n",
    "                color=MODEL_COLORS[model], linewidth=2.5, markersize=8)\n",
    "    \n",
    "    plt.xlabel('Proporción de Calibración (%)', fontsize=12)\n",
    "    plt.ylabel('ECRPS Promedio', fontsize=12)\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "    plt.grid(True, alpha=0.3, linestyle=':', linewidth=0.8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'evolucion_proporciones_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Evolución por proporción generada: {suffix}\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 10. PROPORCIÓN ÓPTIMA POR MODELO\n",
    "# ====================================================================================\n",
    "\n",
    "def analyze_optimal_proportion(data, scenario_name=None):\n",
    "    \"\"\"Identifica la proporción óptima para cada modelo\"\"\"\n",
    "    if scenario_name:\n",
    "        data = data[data['Tipo_Proceso'] == scenario_name]\n",
    "        suffix = scenario_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Proporción Óptima por Modelo\\n{scenario_name}'\n",
    "    else:\n",
    "        suffix = \"General\"\n",
    "        title = 'Proporción Óptima por Modelo\\nTodos los Escenarios'\n",
    "    \n",
    "    optimal_results = []\n",
    "    \n",
    "    for model in model_cols:\n",
    "        prop_means = {}\n",
    "        for prop in prop_values:\n",
    "            prop_means[prop] = data[data['Prop_Calib_Pct'] == prop][model].mean()\n",
    "        \n",
    "        optimal_prop = min(prop_means, key=prop_means.get)\n",
    "        worst_prop = max(prop_means, key=prop_means.get)\n",
    "        \n",
    "        optimal_results.append({\n",
    "            'Modelo': model,\n",
    "            'Proporcion_Optima_%': optimal_prop,\n",
    "            'ECRPS_Optimo': prop_means[optimal_prop],\n",
    "            'Proporcion_Peor_%': worst_prop,\n",
    "            'ECRPS_Peor': prop_means[worst_prop],\n",
    "            'Diferencia_%': ((prop_means[worst_prop] - prop_means[optimal_prop]) / prop_means[optimal_prop]) * 100\n",
    "        })\n",
    "    \n",
    "    optimal_df = pd.DataFrame(optimal_results).sort_values('ECRPS_Optimo')\n",
    "    \n",
    "    # Gráfica\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    y_pos = np.arange(len(optimal_df))\n",
    "    colors = [MODEL_COLORS[m] for m in optimal_df['Modelo']]\n",
    "    \n",
    "    bars = ax.barh(y_pos, optimal_df['ECRPS_Optimo'], \n",
    "                   color=colors, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(optimal_df['Modelo'])\n",
    "    ax.set_xlabel('ECRPS en Proporción Óptima', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Anotar proporción óptima\n",
    "    for i, (bar, (_, row)) in enumerate(zip(bars, optimal_df.iterrows())):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + width*0.01, bar.get_y() + bar.get_height()/2.,\n",
    "               f\"{row['Proporcion_Optima_%']}%\",\n",
    "               ha='left', va='center', fontsize=9, fontweight='bold',\n",
    "               bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'proporcion_optima_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Guardar tabla\n",
    "    optimal_df.to_excel(output_dir / f'proporcion_optima_{suffix}.xlsx', index=False)\n",
    "    \n",
    "    print(f\"✓ Análisis proporción óptima generado: {suffix}\")\n",
    "    \n",
    "    return optimal_df\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 11. ANÁLISIS DE SENSIBILIDAD A LA PROPORCIÓN\n",
    "# ====================================================================================\n",
    "\n",
    "def analyze_sensitivity_to_proportion(data, scenario_name=None):\n",
    "    \"\"\"Identifica qué modelos son más sensibles a cambios en la proporción\"\"\"\n",
    "    if scenario_name:\n",
    "        data = data[data['Tipo_Proceso'] == scenario_name]\n",
    "        suffix = scenario_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        title = f'Sensibilidad a Proporción de Calibración\\n{scenario_name}'\n",
    "    else:\n",
    "        suffix = \"General\"\n",
    "        title = 'Sensibilidad a Proporción de Calibración\\nTodos los Escenarios'\n",
    "    \n",
    "    sensitivity_results = []\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means_by_prop = []\n",
    "        for prop in prop_values:\n",
    "            means_by_prop.append(data[data['Prop_Calib_Pct'] == prop][model].mean())\n",
    "        \n",
    "        means_array = np.array(means_by_prop)\n",
    "        \n",
    "        # Métricas de sensibilidad\n",
    "        rango_absoluto = means_array.max() - means_array.min()\n",
    "        rango_relativo = (rango_absoluto / means_array[0]) * 100\n",
    "        volatilidad = np.std(means_array)\n",
    "        cv = volatilidad / np.mean(means_array)\n",
    "        \n",
    "        # Correlación con proporción\n",
    "        from scipy.stats import spearmanr\n",
    "        corr, p_val = spearmanr(prop_values, means_array)\n",
    "        \n",
    "        sensitivity_results.append({\n",
    "            'Modelo': model,\n",
    "            'Rango_Absoluto': rango_absoluto,\n",
    "            'Rango_Relativo_%': rango_relativo,\n",
    "            'Volatilidad': volatilidad,\n",
    "            'CV': cv,\n",
    "            'Correlacion_Spearman': corr,\n",
    "            'P_value': p_val,\n",
    "            'ECRPS_Medio': means_array.mean()\n",
    "        })\n",
    "    \n",
    "    sensitivity_df = pd.DataFrame(sensitivity_results).sort_values('Rango_Relativo_%', ascending=False)\n",
    "    \n",
    "    # Gráfica\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    colors = plt.cm.RdYlGn_r(sensitivity_df['Rango_Relativo_%'] / sensitivity_df['Rango_Relativo_%'].max())\n",
    "    bars = ax.barh(sensitivity_df['Modelo'], sensitivity_df['Rango_Relativo_%'],\n",
    "                  color=colors, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax.set_xlabel('Variación Relativa Máxima (%)', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    for bar, (_, row) in zip(bars, sensitivity_df.iterrows()):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.5, bar.get_y() + bar.get_height()/2.,\n",
    "               f\"{row['Rango_Relativo_%']:.2f}%\",\n",
    "               ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'sensibilidad_proporcion_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    sensitivity_df.to_excel(output_dir / f'sensibilidad_proporcion_{suffix}.xlsx', index=False)\n",
    "    \n",
    "    print(f\"✓ Análisis de sensibilidad generado: {suffix}\")\n",
    "    \n",
    "    return sensitivity_df\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 12. EXPORTAR EXCEL CONSOLIDADO\n",
    "# ====================================================================================\n",
    "\n",
    "def export_consolidated_excel(results_dict):\n",
    "    \"\"\"\n",
    "    Excel consolidado con todas las tablas de p-valores y resúmenes\n",
    "    \n",
    "    results_dict = {\n",
    "        'General': (all_pval_tables, all_dm_tables, all_diff_tables, alpha_bonf, df_ecrps, df_pct),\n",
    "        'ARMA': (...),\n",
    "        'ARIMA': (...),\n",
    "        'SETAR': (...)\n",
    "    }\n",
    "    \"\"\"\n",
    "    excel_path = output_dir / 'DM_proporciones_consolidado.xlsx'\n",
    "\n",
    "    with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "        wb = writer.book\n",
    "\n",
    "        # Formatos\n",
    "        fmt_hdr  = wb.add_format({'bold': True, 'bg_color': '#2E4057',\n",
    "                                   'font_color': 'white', 'align': 'center',\n",
    "                                   'valign': 'vcenter', 'border': 1})\n",
    "        fmt_sig  = wb.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100',\n",
    "                                   'align': 'center', 'border': 1})\n",
    "        fmt_no   = wb.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006',\n",
    "                                   'align': 'center', 'border': 1})\n",
    "\n",
    "        sheet_counter = 1\n",
    "        \n",
    "        for tipo, (all_pval_tables, all_dm_tables, all_diff_tables, alpha_bonf, df_ecrps, df_pct) in results_dict.items():\n",
    "            tipo_short = tipo.replace(\"Lineal Estacionario (ARMA)\", \"ARMA\") \\\n",
    "                             .replace(\"Lineal No Estacionario (ARIMA)\", \"ARIMA\") \\\n",
    "                             .replace(\"No Lineal Estacionario (SETAR)\", \"SETAR\") \\\n",
    "                             .replace(\"General\", \"General\")\n",
    "            \n",
    "            # Hoja 1: ECRPS medios\n",
    "            sheet_name = f'{sheet_counter}_ECRPS_{tipo_short}'\n",
    "            df_ecrps.to_excel(writer, sheet_name=sheet_name)\n",
    "            ws = writer.sheets[sheet_name]\n",
    "            ws.set_column('A:A', 12)\n",
    "            ws.set_column('B:Z', 18)\n",
    "            for c, col in enumerate(df_ecrps.columns, 1):\n",
    "                ws.write(0, c, col, fmt_hdr)\n",
    "            sheet_counter += 1\n",
    "            \n",
    "            # Hoja 2: % Significancia\n",
    "            sheet_name = f'{sheet_counter}_PctSig_{tipo_short}'\n",
    "            df_pct.to_excel(writer, sheet_name=sheet_name)\n",
    "            ws2 = writer.sheets[sheet_name]\n",
    "            ws2.set_column('A:A', 12)\n",
    "            ws2.set_column('B:Z', 18)\n",
    "            for c, col in enumerate(df_pct.columns, 1):\n",
    "                ws2.write(0, c, col, fmt_hdr)\n",
    "            for c in range(1, len(model_cols) + 1):\n",
    "                ws2.conditional_format(1, c, len(prop_values), c,\n",
    "                    {'type': 'cell', 'criteria': '>=', 'value': 50, 'format': fmt_sig})\n",
    "                ws2.conditional_format(1, c, len(prop_values), c,\n",
    "                    {'type': 'cell', 'criteria': '<',  'value': 50, 'format': fmt_no})\n",
    "            sheet_counter += 1\n",
    "\n",
    "        # Hoja final: Metodología\n",
    "        meta = pd.DataFrame({\n",
    "            'Parámetro': [\n",
    "                'Unidad de escenario',\n",
    "                'Emparejamiento dentro del test DM',\n",
    "                'Test estadístico',\n",
    "                'Método de estimación de varianza',\n",
    "                'Corrección de multiplicidad',\n",
    "                'α nominal',\n",
    "                'Métrica de pérdida',\n",
    "                'Modelos evaluados',\n",
    "                'Proporciones evaluadas',\n",
    "                'Tipos de escenario',\n",
    "                'Escenarios únicos totales'\n",
    "            ],\n",
    "            'Valor': [\n",
    "                'Combinación única (Proceso, Distribución, Varianza)',\n",
    "                'Inner-join por columna Paso (réplica de simulación)',\n",
    "                'Diebold-Mariano bilateral con fixed-smoothing asymptotics',\n",
    "                'Estimación espectral con periodograma y bandwidth T^(1/3)',\n",
    "                'Bonferroni sobre todos los tests válidos (por tipo)',\n",
    "                0.05,\n",
    "                'ECRPS',\n",
    "                ', '.join(model_cols),\n",
    "                ', '.join([f'{p}%' for p in prop_values]),\n",
    "                ', '.join(escenarios),\n",
    "                len(escenarios_unicos)\n",
    "            ]\n",
    "        })\n",
    "        meta.to_excel(writer, sheet_name='ZZ_Metodologia', index=False)\n",
    "        ws_m = writer.sheets['ZZ_Metodologia']\n",
    "        ws_m.set_column('A:A', 45)\n",
    "        ws_m.set_column('B:B', 80)\n",
    "\n",
    "    print(f\"\\n✓ Excel consolidado guardado: {excel_path}\")\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# 13. EJECUCIÓN PRINCIPAL\n",
    "# ====================================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ANÁLISIS DM CON FIXED-SMOOTHING ASYMPTOTICS — EFECTOS DE LA PROPORCIÓN\")\n",
    "    print(\"Escenario = combinación única (Proceso × Distribución × Varianza)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Diccionario para guardar todos los resultados\n",
    "    all_results = {}\n",
    "    \n",
    "    # ============================================================\n",
    "    # ANÁLISIS GENERAL\n",
    "    # ============================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISIS GENERAL (TODOS LOS ESCENARIOS)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    all_pval_tables, all_dm_tables, all_diff_tables, alpha_bonf, df_ecrps = compute_all_tables(tipo_escenario=None)\n",
    "    df_pct = compute_summary_pct(all_pval_tables, alpha_bonf)\n",
    "    \n",
    "    all_results['General'] = (all_pval_tables, all_dm_tables, all_diff_tables, alpha_bonf, df_ecrps, df_pct)\n",
    "    \n",
    "    print(\"\\n[Generando visualizaciones - GENERAL]\")\n",
    "    plot_combined_heatmap(df_ecrps, df_pct, alpha_bonf, tipo_escenario=None)\n",
    "    plot_heatmap_zscores(df, tipo_escenario=None)\n",
    "    plot_relative_improvement(df, tipo_escenario=None)\n",
    "    plot_evolution_by_proportion(df, scenario_name=None)\n",
    "    \n",
    "    # ============================================================\n",
    "    # ANÁLISIS POR TIPO DE ESCENARIO\n",
    "    # ============================================================\n",
    "    for tipo in escenarios:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"ANÁLISIS: {tipo}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        all_pval_tables, all_dm_tables, all_diff_tables, alpha_bonf, df_ecrps = compute_all_tables(tipo_escenario=tipo)\n",
    "        df_pct = compute_summary_pct(all_pval_tables, alpha_bonf)\n",
    "        \n",
    "        all_results[tipo] = (all_pval_tables, all_dm_tables, all_diff_tables, alpha_bonf, df_ecrps, df_pct)\n",
    "        \n",
    "        print(f\"\\n[Generando visualizaciones - {tipo}]\")\n",
    "        plot_combined_heatmap(df_ecrps, df_pct, alpha_bonf, tipo_escenario=tipo)\n",
    "        plot_heatmap_zscores(df, tipo_escenario=tipo)\n",
    "        plot_relative_improvement(df, tipo_escenario=tipo)\n",
    "        plot_evolution_by_proportion(df, scenario_name=tipo)\n",
    "    \n",
    "    # ============================================================\n",
    "    # ANÁLISIS ADICIONALES (PROPORCIÓN ÓPTIMA Y SENSIBILIDAD)\n",
    "    # ============================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISIS DE PROPORCIÓN ÓPTIMA Y SENSIBILIDAD\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    optimal_general = analyze_optimal_proportion(df)\n",
    "    for scen in escenarios:\n",
    "        analyze_optimal_proportion(df, scen)\n",
    "    \n",
    "    sensitivity_general = analyze_sensitivity_to_proportion(df)\n",
    "    for scen in escenarios:\n",
    "        analyze_sensitivity_to_proportion(df, scen)\n",
    "    \n",
    "    # ============================================================\n",
    "    # EXPORTAR EXCEL CONSOLIDADO\n",
    "    # ============================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPORTANDO EXCEL CONSOLIDADO\")\n",
    "    print(\"=\"*80)\n",
    "    export_consolidated_excel(all_results)\n",
    "    \n",
    "    # ============================================================\n",
    "    # RESUMEN FINAL\n",
    "    # ============================================================\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"✓ ANÁLISIS COMPLETADO\")\n",
    "    print(f\"✓ Resultados en: {output_dir}\")\n",
    "    print(\"\\nArchivos generados:\")\n",
    "    print(\"  1. HEATMAPS COMBINADOS (ECRPS + % Significancia):\")\n",
    "    print(\"     - 4 archivos .png (General + ARMA + ARIMA + SETAR)\")\n",
    "    print(\"  2. HEATMAPS Z-SCORES:\")\n",
    "    print(\"     - 4 archivos .png + 8 .xlsx (General + ARMA + ARIMA + SETAR)\")\n",
    "    print(\"  3. CURVAS DE MEJORA RELATIVA:\")\n",
    "    print(\"     - 4 archivos .png + 4 .xlsx (General + ARMA + ARIMA + SETAR)\")\n",
    "    print(\"  4. CURVAS DE EVOLUCIÓN:\")\n",
    "    print(\"     - 4 archivos .png (General + ARMA + ARIMA + SETAR)\")\n",
    "    print(\"  5. ANÁLISIS PROPORCIÓN ÓPTIMA:\")\n",
    "    print(\"     - 4 archivos .png + 4 .xlsx (General + ARMA + ARIMA + SETAR)\")\n",
    "    print(\"  6. ANÁLISIS DE SENSIBILIDAD:\")\n",
    "    print(\"     - 4 archivos .png + 4 .xlsx (General + ARMA + ARIMA + SETAR)\")\n",
    "    print(\"  7. EXCEL CONSOLIDADO:\")\n",
    "    print(\"     - 1 archivo con 9 hojas (2 por análisis + metodología)\")\n",
    "    print(\"\\nMETODOLOGÍA:\")\n",
    "    print(\"  - Test DM: Fixed-smoothing asymptotics con estimación espectral\")\n",
    "    print(\"  - Bandwidth: T^(1/3) para estimación de varianza de largo plazo\")\n",
    "    print(\"  - Emparejamiento: por Paso dentro de cada escenario único\")\n",
    "    print(\"  - Corrección: Bonferroni por tipo de análisis\")\n",
    "    print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e77a51",
   "metadata": {},
   "source": [
    "# Analisis Simulacion h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fb751e",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b7c750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tabla Comparativa de Modelos (Basada en MEDIA) ---\n",
      "         Modelo  General     ARMA    ARIMA    SETAR Mejor_Escenario\n",
      "Sieve Bootstrap 1.261013 0.793567 2.405825 0.583647           SETAR\n",
      "           LSPM 1.423114 0.863196 2.811590 0.594555           SETAR\n",
      "           MCPS 2.122821 0.885279 4.871372 0.611811           SETAR\n",
      "         DeepAR 3.126949 0.833898 7.970984 0.575966           SETAR\n",
      "\n",
      "--- Tabla Comparativa de Modelos (Basada en MEDIANA) ---\n",
      "         Modelo  General     ARMA    ARIMA    SETAR Mejor_Escenario\n",
      "Sieve Bootstrap 0.722924 0.622694 1.688908 0.497262           SETAR\n",
      "           LSPM 0.786162 0.661725 1.946193 0.502726           SETAR\n",
      "           MCPS 0.850184 0.660088 2.845228 0.528392           SETAR\n",
      "         DeepAR 0.821647 0.635593 3.456565 0.473015           SETAR\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Leer los archivos\n",
    "arma_df = pd.read_excel(\"./datos/Simulacion_h/resultados_140_trayectorias_ARMA_FINAL.xlsx\")\n",
    "arima_df = pd.read_excel(\"./datos/Simulacion_h/resultados_140_trayectorias_ARIMA_FINAL.xlsx\")\n",
    "setar_df = pd.read_excel(\"./datos/Simulacion_h/resultados_140_trayectorias_SETAR_FINAL.xlsx\")\n",
    "LSPMW_df = pd.read_excel(\"./datos/Simulacion_h/resultados_LSPMW_todos_procesos.xlsx\")\n",
    "\n",
    "\n",
    "# 2. Asignar la columna ESCENARIO a cada dataframe\n",
    "arma_df['ESCENARIO'] = \"Lineal Estacionario\"\n",
    "arima_df['ESCENARIO'] = \"Lineal No estacionario\"\n",
    "setar_df['ESCENARIO'] = \"No lineal Estacionario\"\n",
    "\n",
    "# 3. Juntarlos uno bajo el otro (Concatenar)\n",
    "df_total = pd.concat([arma_df, arima_df, setar_df], ignore_index=True)\n",
    "\n",
    "# Seleccionar solo las columnas requeridas\n",
    "columnas_deseadas = [\n",
    "    \"Paso\", \"Config\", \"Dist\", \"Var\",  \n",
    "    \"Sieve Bootstrap\", \"LSPM\",  \"MCPS\", \n",
    "    \"DeepAR\", \"ESCENARIO\"\n",
    "]\n",
    "df_total = df_total[columnas_deseadas]\n",
    "\n",
    "# Definimos cuáles son las columnas que representan a los modelos predictivos\n",
    "modelos = [\n",
    "    \"Sieve Bootstrap\", \"LSPM\",  \"MCPS\", \n",
    "    \"DeepAR\"\n",
    "]\n",
    "\n",
    "# 4. Guardar el dataframe consolidado\n",
    "df_total.to_excel(\"./datos/Simulacion_h/dataframe_consolidado.xlsx\", index=False)\n",
    "\n",
    "# 5. Generar y mostrar las tablas (Media y Mediana)\n",
    "metricas = {'MEDIA': 'mean', 'MEDIANA': 'median'}\n",
    "\n",
    "for nombre_metrica, funcion in metricas.items():\n",
    "    # Calculamos el valor general según la métrica (mean o median)\n",
    "    if funcion == 'mean':\n",
    "        resumen_general = df_total[modelos].mean()\n",
    "        resumen_escenarios = df_total.groupby('ESCENARIO')[modelos].mean().T\n",
    "    else:\n",
    "        resumen_general = df_total[modelos].median()\n",
    "        resumen_escenarios = df_total.groupby('ESCENARIO')[modelos].median().T\n",
    "\n",
    "    # Construimos la tabla final para esta métrica\n",
    "    tabla_resumen = pd.DataFrame(index=modelos)\n",
    "    tabla_resumen['General'] = resumen_general\n",
    "    tabla_resumen['ARMA'] = resumen_escenarios['Lineal Estacionario']\n",
    "    tabla_resumen['ARIMA'] = resumen_escenarios['Lineal No estacionario']\n",
    "    tabla_resumen['SETAR'] = resumen_escenarios['No lineal Estacionario']\n",
    "\n",
    "    # Determinar el Mejor_Escenario (valor mínimo entre los tres escenarios)\n",
    "    escenarios_cols = ['ARMA', 'ARIMA', 'SETAR']\n",
    "    tabla_resumen['Mejor_Escenario'] = tabla_resumen[escenarios_cols].idxmin(axis=1)\n",
    "\n",
    "    # Imprimir resultado\n",
    "    print(f\"\\n--- Tabla Comparativa de Modelos (Basada en {nombre_metrica}) ---\")\n",
    "    print(tabla_resumen.reset_index().rename(columns={'index': 'Modelo'}).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f053082f",
   "metadata": {},
   "source": [
    "### Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cbb14cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo orden de modelos (basado en Lineal No Estacionario (ARIMA)):\n",
      "1. Sieve Bootstrap: 2.4058\n",
      "2. LSPM: 2.8116\n",
      "3. MCPS: 4.8714\n",
      "4. DeepAR: 7.9710\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\n",
      "================================================================================\n",
      "✓ Gráfica 1.1 guardada\n",
      "✓ Gráfica 1.2 guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 2: ANÁLISIS POR CONFIG\n",
      "================================================================================\n",
      "✓ Gráfica 2.1 guardada\n",
      "✓ Gráfica 2.1.a guardada\n",
      "✓ Gráfica 2.1.b guardada\n",
      "✓ Gráfica 2.1.c guardada\n",
      "✓ Gráfica 2.2 guardada\n",
      "✓ Gráfica 2.2.a guardada\n",
      "✓ Gráfica 2.2.b guardada\n",
      "✓ Gráfica 2.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 3: ANÁLISIS POR DIST\n",
      "================================================================================\n",
      "✓ Gráfica 3.1 guardada\n",
      "✓ Gráfica 3.1.a guardada\n",
      "✓ Gráfica 3.1.b guardada\n",
      "✓ Gráfica 3.1.c guardada\n",
      "✓ Gráfica 3.2 guardada\n",
      "✓ Gráfica 3.2.a guardada\n",
      "✓ Gráfica 3.2.b guardada\n",
      "✓ Gráfica 3.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 4: ANÁLISIS POR VAR\n",
      "================================================================================\n",
      "✓ Gráfica 4.1 guardada\n",
      "✓ Gráfica 4.1.a guardada\n",
      "✓ Gráfica 4.1.b guardada\n",
      "✓ Gráfica 4.1.c guardada\n",
      "✓ Gráfica 4.2 guardada\n",
      "✓ Gráfica 4.2.a guardada\n",
      "✓ Gráfica 4.2.b guardada\n",
      "✓ Gráfica 4.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\n",
      "================================================================================\n",
      "✓ Gráfica 5.1 guardada\n",
      "✓ Gráfica 5.1.a guardada\n",
      "✓ Gráfica 5.1.b guardada\n",
      "✓ Gráfica 5.1.c guardada\n",
      "✓ Gráfica 5.2 guardada\n",
      "✓ Gráfica 5.2.a guardada\n",
      "✓ Gráfica 5.2.b guardada\n",
      "✓ Gráfica 5.2.c guardada\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES (FORMATO 2x2)\n",
      "================================================================================\n",
      "✓ Gráfica 5.3 guardada (Config × Var 2x2)\n",
      "✓ Gráfica 5.4 guardada (Config × Dist 2x2)\n",
      "✓ Gráfica 5.5 guardada (Dist × Paso 2x2)\n",
      "✓ Gráfica 5.6 guardada (Dist × Var 2x2)\n",
      "✓ Gráfica 5.7 guardada (Config × Paso 2x2)\n",
      "✓ Gráfica 5.8 guardada (Var × Horizonte 2x2)\n",
      "✓ Gráfica 5.3.a guardada (Config × Var 2x2)\n",
      "✓ Gráfica 5.4.a guardada (Config × Dist 2x2)\n",
      "✓ Gráfica 5.5.a guardada (Dist × Paso 2x2)\n",
      "✓ Gráfica 5.6.a guardada (Dist × Var 2x2)\n",
      "✓ Gráfica 5.7.a guardada (Config × Paso 2x2)\n",
      "✓ Gráfica 5.8.a guardada (Var × Horizonte 2x2)\n",
      "✓ Gráfica 5.3.b guardada (Config × Var 2x2)\n",
      "✓ Gráfica 5.4.b guardada (Config × Dist 2x2)\n",
      "✓ Gráfica 5.5.b guardada (Dist × Paso 2x2)\n",
      "✓ Gráfica 5.6.b guardada (Dist × Var 2x2)\n",
      "✓ Gráfica 5.7.b guardada (Config × Paso 2x2)\n",
      "✓ Gráfica 5.8.b guardada (Var × Horizonte 2x2)\n",
      "✓ Gráfica 5.3.c guardada (Config × Var 2x2)\n",
      "✓ Gráfica 5.4.c guardada (Config × Dist 2x2)\n",
      "✓ Gráfica 5.5.c guardada (Dist × Paso 2x2)\n",
      "✓ Gráfica 5.6.c guardada (Dist × Var 2x2)\n",
      "✓ Gráfica 5.7.c guardada (Config × Paso 2x2)\n",
      "✓ Gráfica 5.8.c guardada (Var × Horizonte 2x2)\n",
      "\n",
      "================================================================================\n",
      "SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\n",
      "================================================================================\n",
      "✓ Gráfica 6.1 guardada\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CÁLCULO TEST DIEBOLD-MARIANO - PROCESO PASO A PASO\n",
      "--------------------------------------------------------------------------------\n",
      "Tipo de análisis: GENERAL\n",
      "PASO 1: Escenarios únicos identificados: 5040\n",
      "Número de comparaciones por escenario: 6\n",
      "α nominal: 0.05\n",
      "α Bonferroni: 0.008333\n",
      "\n",
      "PASO 2: Calculando p-valores para cada escenario y par de modelos...\n",
      "✓ Tabla de 5040 escenarios × 6 comparaciones completada\n",
      "\n",
      "PASO 3: Clasificando significancia estadística...\n",
      "✓ Tabla de significancia creada\n",
      "\n",
      "PASO 4: Creando tablas resumen...\n",
      "✓ Tabla resumen por comparación creada (6 filas)\n",
      "✓ Matrices modelo vs modelo creadas\n",
      "\n",
      "✓ Excel guardado: 6.2_dm_proceso_completo.xlsx\n",
      "  - Hoja 1: 5040 escenarios únicos\n",
      "  - Hoja 2: 5040 × 6 p-valores\n",
      "  - Hoja 3: 5040 × 6 clasificaciones\n",
      "  - Hoja 4: 6 resúmenes por comparación\n",
      "  - Hojas 5-6: Matrices 4×4\n",
      "✓ Gráfica guardada: 6.2_dm_matriz_comparativa.png\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CÁLCULO TEST DIEBOLD-MARIANO - PROCESO PASO A PASO\n",
      "--------------------------------------------------------------------------------\n",
      "Tipo de análisis: ARMA\n",
      "PASO 1: Escenarios únicos identificados: 1680\n",
      "Número de comparaciones por escenario: 6\n",
      "α nominal: 0.05\n",
      "α Bonferroni: 0.008333\n",
      "\n",
      "PASO 2: Calculando p-valores para cada escenario y par de modelos...\n",
      "✓ Tabla de 1680 escenarios × 6 comparaciones completada\n",
      "\n",
      "PASO 3: Clasificando significancia estadística...\n",
      "✓ Tabla de significancia creada\n",
      "\n",
      "PASO 4: Creando tablas resumen...\n",
      "✓ Tabla resumen por comparación creada (6 filas)\n",
      "✓ Matrices modelo vs modelo creadas\n",
      "\n",
      "✓ Excel guardado: 6.2.a_dm_proceso_completo.xlsx\n",
      "  - Hoja 1: 1680 escenarios únicos\n",
      "  - Hoja 2: 1680 × 6 p-valores\n",
      "  - Hoja 3: 1680 × 6 clasificaciones\n",
      "  - Hoja 4: 6 resúmenes por comparación\n",
      "  - Hojas 5-6: Matrices 4×4\n",
      "✓ Gráfica guardada: 6.2.a_dm_matriz_comparativa.png\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CÁLCULO TEST DIEBOLD-MARIANO - PROCESO PASO A PASO\n",
      "--------------------------------------------------------------------------------\n",
      "Tipo de análisis: ARIMA\n",
      "PASO 1: Escenarios únicos identificados: 1680\n",
      "Número de comparaciones por escenario: 6\n",
      "α nominal: 0.05\n",
      "α Bonferroni: 0.008333\n",
      "\n",
      "PASO 2: Calculando p-valores para cada escenario y par de modelos...\n",
      "✓ Tabla de 1680 escenarios × 6 comparaciones completada\n",
      "\n",
      "PASO 3: Clasificando significancia estadística...\n",
      "✓ Tabla de significancia creada\n",
      "\n",
      "PASO 4: Creando tablas resumen...\n",
      "✓ Tabla resumen por comparación creada (6 filas)\n",
      "✓ Matrices modelo vs modelo creadas\n",
      "\n",
      "✓ Excel guardado: 6.2.b_dm_proceso_completo.xlsx\n",
      "  - Hoja 1: 1680 escenarios únicos\n",
      "  - Hoja 2: 1680 × 6 p-valores\n",
      "  - Hoja 3: 1680 × 6 clasificaciones\n",
      "  - Hoja 4: 6 resúmenes por comparación\n",
      "  - Hojas 5-6: Matrices 4×4\n",
      "✓ Gráfica guardada: 6.2.b_dm_matriz_comparativa.png\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CÁLCULO TEST DIEBOLD-MARIANO - PROCESO PASO A PASO\n",
      "--------------------------------------------------------------------------------\n",
      "Tipo de análisis: SETAR\n",
      "PASO 1: Escenarios únicos identificados: 1680\n",
      "Número de comparaciones por escenario: 6\n",
      "α nominal: 0.05\n",
      "α Bonferroni: 0.008333\n",
      "\n",
      "PASO 2: Calculando p-valores para cada escenario y par de modelos...\n",
      "✓ Tabla de 1680 escenarios × 6 comparaciones completada\n",
      "\n",
      "PASO 3: Clasificando significancia estadística...\n",
      "✓ Tabla de significancia creada\n",
      "\n",
      "PASO 4: Creando tablas resumen...\n",
      "✓ Tabla resumen por comparación creada (6 filas)\n",
      "✓ Matrices modelo vs modelo creadas\n",
      "\n",
      "✓ Excel guardado: 6.2.c_dm_proceso_completo.xlsx\n",
      "  - Hoja 1: 1680 escenarios únicos\n",
      "  - Hoja 2: 1680 × 6 p-valores\n",
      "  - Hoja 3: 1680 × 6 clasificaciones\n",
      "  - Hoja 4: 6 resúmenes por comparación\n",
      "  - Hojas 5-6: Matrices 4×4\n",
      "✓ Gráfica guardada: 6.2.c_dm_matriz_comparativa.png\n",
      "\n",
      "================================================================================\n",
      "PROCESO COMPLETADO CON ÉXITO\n",
      "================================================================================\n",
      "\n",
      "📊 ESTRUCTURA DE OUTPUTS:\n",
      "\n",
      "EXCEL (6.2[suffix]_dm_proceso_completo.xlsx):\n",
      "  Hoja 0: Metodología\n",
      "  Hoja 1: 420 escenarios únicos (Paso, Config, Dist, Var)\n",
      "  Hoja 2: 420 × 6 p-valores (cada columna = 1 comparación)\n",
      "  Hoja 2b: 420 × 6 estadísticos DM\n",
      "  Hoja 2c: 420 × 12 medias (A y B por comparación)\n",
      "  Hoja 3: 420 × 6 significancia (SÍ/NO)\n",
      "  Hoja 4: Resumen reducido (6 comparaciones)\n",
      "  Hoja 5: Matriz NxN % significancia\n",
      "  Hoja 6: Matriz NxN ECRPS medio\n",
      "\n",
      "GRÁFICA (6.2[suffix]_dm_matriz_comparativa.png):\n",
      "  Panel izquierdo: Heatmap % significancia\n",
      "  Panel derecho: Heatmap ECRPS medio\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración general mejorada\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Crear carpeta de resultados\n",
    "output_dir = Path(\"./Resultados_analisis/Simulacion_h\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Crear carpeta de interacciones\n",
    "interactions_dir = output_dir / \"Interacciones\"\n",
    "interactions_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_excel(\"./datos/Simulacion_h/dataframe_consolidado.xlsx\")\n",
    "\n",
    "# 1) CAMBIO DE NOMBRES DE ESCENARIOS\n",
    "df['ESCENARIO'] = df['ESCENARIO'].replace({\n",
    "    \"Lineal Estacionario\": \"Lineal Estacionario (ARMA)\",\n",
    "    \"Lineal No estacionario\": \"Lineal No Estacionario (ARIMA)\",\n",
    "    \"No lineal Estacionario\": \"No lineal Estacionario (SETAR)\"\n",
    "})\n",
    "\n",
    "# Identificar columnas de modelos\n",
    "var_cols = ['Paso', 'Config', 'Dist', 'Var', 'ESCENARIO']\n",
    "original_model_cols = [col for col in df.columns if col not in var_cols]\n",
    "\n",
    "# 2) ORGANIZAR MODELOS POR RENDIMIENTO EN \"Lineal No Estacionario (ARIMA)\" (Menor a mayor)\n",
    "target_scenario = \"Lineal No Estacionario (ARIMA)\"\n",
    "model_order_scores = df[df['ESCENARIO'] == target_scenario][original_model_cols].mean().sort_values()\n",
    "model_cols = list(model_order_scores.index)\n",
    "\n",
    "print(\"Nuevo orden de modelos (basado en Lineal No Estacionario (ARIMA)):\")\n",
    "for i, m in enumerate(model_cols, 1):\n",
    "    print(f\"{i}. {m}: {model_order_scores[m]:.4f}\")\n",
    "\n",
    "# Mapeo de escenarios\n",
    "escenarios_map = {\n",
    "    'Lineal Estacionario (ARMA)': 'Lineal Estacionario (ARMA)',\n",
    "    'Lineal No Estacionario (ARIMA)': 'Lineal No Estacionario (ARIMA)',\n",
    "    'No lineal Estacionario (SETAR)': 'No lineal Estacionario (SETAR)'\n",
    "}\n",
    "\n",
    "# Definir colores para cada modelo\n",
    "palette = sns.color_palette(\"husl\", len(model_cols))\n",
    "model_colors = {model: palette[i] for i, model in enumerate(model_cols)}\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 1: RENDIMIENTO POR ESCENARIOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_performance_by_scenario():\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    scenarios = [\"Lineal Estacionario (ARMA)\", \"Lineal No Estacionario (ARIMA)\", \"No lineal Estacionario (SETAR)\"]\n",
    "    x = np.arange(len(model_cols))\n",
    "    width = 0.25 \n",
    "    \n",
    "    scenario_colors = {\n",
    "        'Lineal Estacionario (ARMA)': '#5D3FD3',    \n",
    "        'Lineal No Estacionario (ARIMA)': '#808080', \n",
    "        'No lineal Estacionario (SETAR)': '#00A36C'  \n",
    "    }\n",
    "    \n",
    "    for idx, scenario in enumerate(scenarios):\n",
    "        means = [df[df['ESCENARIO'] == scenario][model].mean() for model in model_cols]\n",
    "        position = x + (idx - 1) * width\n",
    "        \n",
    "        bars = ax.bar(position, means, width, label=scenario, \n",
    "                     color=scenario_colors[scenario], alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.2f}', ha='center', va='bottom', fontsize=7, rotation=0)\n",
    "    \n",
    "    ax.set_xlabel('Modelo (Ordenados por desempeño en ARIMA)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Rendimiento de Modelos por Escenario (ECRPS)', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_cols, rotation=45, ha='right', fontsize=9)\n",
    "    ax.legend(loc='upper left', ncol=1, fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '1.1_rendimiento_por_escenario.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 1.1 guardada\")\n",
    "\n",
    "plot_performance_by_scenario()\n",
    "\n",
    "def plot_relative_performance():\n",
    "    base_scenario = 'Lineal Estacionario (ARMA)'\n",
    "    scenarios_compare = ['Lineal No Estacionario (ARIMA)', 'No lineal Estacionario (SETAR)']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    y = np.arange(len(model_cols))\n",
    "    height = 0.35  \n",
    "    \n",
    "    for idx, scenario in enumerate(scenarios_compare):\n",
    "        changes = []\n",
    "        for model in model_cols:\n",
    "            base_value = df[df['ESCENARIO'] == base_scenario][model].mean()\n",
    "            scenario_value = df[df['ESCENARIO'] == scenario][model].mean()\n",
    "            pct_change = ((scenario_value - base_value) / base_value) * 100\n",
    "            changes.append(pct_change)\n",
    "        \n",
    "        position = y + idx * height\n",
    "        bars = ax.barh(position, changes, height, label=scenario, alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        for bar, val in zip(bars, changes):\n",
    "            width = bar.get_width()\n",
    "            ax.text(width + (1 if width > 0 else -1), bar.get_y() + bar.get_height()/2.,\n",
    "                   f'{val:+.1f}%', ha='left' if val > 0 else 'right', \n",
    "                   va='center', fontsize=7)\n",
    "    \n",
    "    ax.set_yticks(y + height / 2)\n",
    "    ax.set_yticklabels(model_cols, fontsize=10)\n",
    "    ax.set_xlabel('Cambio Relativo (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Cambio Relativo en ECRPS vs. {base_scenario}', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=1.5)\n",
    "    ax.legend(loc='best', fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '1.2_cambio_relativo_escenario_base.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 1.2 guardada\")\n",
    "\n",
    "plot_relative_performance()\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 2: ANÁLISIS POR CONFIG\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 2: ANÁLISIS POR CONFIG\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_zscore_heatmap_config(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Z-scores de ECRPS por Configuración\\n{scenario}'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Z-scores de ECRPS por Configuración\\n(General)'\n",
    "    \n",
    "    pivot_data = data_filtered.groupby('Config')[model_cols].mean()\n",
    "    z_scores = pivot_data.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(z_scores.T, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, cbar_kws={'label': 'Z-score'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=13, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Configuración', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'2.1{suffix}_zscore_config.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 2.1{suffix} guardada\")\n",
    "\n",
    "plot_zscore_heatmap_config()\n",
    "plot_zscore_heatmap_config('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_zscore_heatmap_config('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_zscore_heatmap_config('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_config(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Configuración\\n{scenario}'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Configuración\\n(General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Config')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    fmt = '.2f' if suffix == '' else '.4f'\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt=fmt, cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=13, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Configuración', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'2.2{suffix}_variabilidad_config.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 2.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_config()\n",
    "plot_variability_config('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_config('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_config('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 3: ANÁLISIS POR DIST\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 3: ANÁLISIS POR DIST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_zscore_heatmap_dist(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Z-scores de ECRPS por Distribución\\n{scenario}'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Z-scores de ECRPS por Distribución\\n(General)'\n",
    "    \n",
    "    pivot_data = data_filtered.groupby('Dist')[model_cols].mean()\n",
    "    z_scores = pivot_data.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(z_scores.T, annot=True, fmt='.2f', cmap='RdYlGn_r', \n",
    "                center=0, cbar_kws={'label': 'Z-score'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=13, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Distribución', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'3.1{suffix}_zscore_dist.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 3.1{suffix} guardada\")\n",
    "\n",
    "plot_zscore_heatmap_dist()\n",
    "plot_zscore_heatmap_dist('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_zscore_heatmap_dist('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_zscore_heatmap_dist('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_dist(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Distribución\\n{scenario}'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Distribución\\n(General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Dist')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=13, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Distribución', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'3.2{suffix}_variabilidad_dist.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 3.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_dist()\n",
    "plot_variability_dist('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_dist('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_dist('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 4: ANÁLISIS POR VAR\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 4: ANÁLISIS POR VAR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_evolution_var(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Evolución de ECRPS por Varianza\\n{scenario}'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Evolución de ECRPS por Varianza\\n(General)'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    var_values = sorted(data_filtered['Var'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means = []\n",
    "        for var in var_values:\n",
    "            mean_val = data_filtered[data_filtered['Var'] == var][model].mean()\n",
    "            means.append(mean_val)\n",
    "        \n",
    "        ax.plot(var_values, means, marker='o', label=model, color=model_colors[model],\n",
    "                linewidth=2.5, markersize=7, alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('Varianza', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=13, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', fontsize=9, ncol=2, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'4.1{suffix}_evolucion_var.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 4.1{suffix} guardada\")\n",
    "\n",
    "plot_evolution_var()\n",
    "plot_evolution_var('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_evolution_var('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_evolution_var('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_var(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Varianza\\n{scenario}'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Varianza\\n(General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Var')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=13, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Varianza', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'4.2{suffix}_variabilidad_var.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 4.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_var()\n",
    "plot_variability_var('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_var('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_var('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 5: ANÁLISIS POR PASO (HORIZONTE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_evolution_paso(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Evolución de ECRPS por Horizonte de Pronóstico\\n{scenario}'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Evolución de ECRPS por Horizonte de Pronóstico\\n(General)'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    \n",
    "    for model in model_cols:\n",
    "        means = []\n",
    "        for paso in pasos:\n",
    "            mean_val = data_filtered[data_filtered['Paso'] == paso][model].mean()\n",
    "            means.append(mean_val)\n",
    "        \n",
    "        ax.plot(pasos, means, marker='o', label=model, color=model_colors[model],\n",
    "                linewidth=2.5, markersize=7, alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('Horizonte de Pronóstico', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ECRPS Promedio', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=13, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', fontsize=9, ncol=2, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'5.1{suffix}_evolucion_paso.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.1{suffix} guardada\")\n",
    "\n",
    "plot_evolution_paso()\n",
    "plot_evolution_paso('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_evolution_paso('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_evolution_paso('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "def plot_variability_paso(scenario=None, suffix=''):\n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "        title = f'Desv. Estándar de ECRPS por Horizonte\\n{scenario}'\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "        title = 'Desv. Estándar de ECRPS por Horizonte\\n(General)'\n",
    "    \n",
    "    pivot_std = data_filtered.groupby('Paso')[model_cols].std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_std.T, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Desv. Estándar'}, ax=ax,\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    \n",
    "    ax.set_title(title, fontsize=13, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Horizonte de Pronóstico', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'5.2{suffix}_variabilidad_paso.png'\n",
    "    plt.savefig(output_dir / filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.2{suffix} guardada\")\n",
    "\n",
    "plot_variability_paso()\n",
    "plot_variability_paso('Lineal Estacionario (ARMA)', '.a')\n",
    "plot_variability_paso('Lineal No Estacionario (ARIMA)', '.b')\n",
    "plot_variability_paso('No lineal Estacionario (SETAR)', '.c')\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES (FORMATO 2x2 MEJORADO)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 5.5: ANÁLISIS DE INTERACCIONES (FORMATO 2x2)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# INTERACCIÓN CONFIG × VAR - Formato 2x2\n",
    "def plot_interaction_config_var_2x2(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title_base = 'General' if not scenario else scenario\n",
    "    \n",
    "    configs = sorted(data_filtered['Config'].unique())\n",
    "    vars_val = sorted(data_filtered['Var'].unique())\n",
    "    \n",
    "    # Seleccionar 4 modelos representativos (mejor, peor, y dos intermedios)\n",
    "    model_means = data_filtered[model_cols].mean().sort_values()\n",
    "    n_models = len(model_cols)\n",
    "    selected_models = [\n",
    "        model_cols[0],  # Mejor\n",
    "        model_cols[n_models // 3],  # Intermedio bajo\n",
    "        model_cols[2 * n_models // 3],  # Intermedio alto\n",
    "        model_cols[-1]  # Peor\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors_config = sns.color_palette(\"Set2\", len(configs))\n",
    "    \n",
    "    for idx, model in enumerate(selected_models):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        for c_idx, config in enumerate(configs):\n",
    "            means = []\n",
    "            for var in vars_val:\n",
    "                mean_val = data_filtered[\n",
    "                    (data_filtered['Config'] == config) & \n",
    "                    (data_filtered['Var'] == var)\n",
    "                ][model].mean()\n",
    "                means.append(mean_val)\n",
    "            \n",
    "            ax.plot(vars_val, means, marker='o', label=f'Config {config}', \n",
    "                   color=colors_config[c_idx], linewidth=2.5, markersize=8, alpha=0.85)\n",
    "        \n",
    "        # Personalización de cada subplot\n",
    "        ax.set_title(f'{model}', fontsize=11, fontweight='bold', pad=10)\n",
    "        ax.set_xlabel('Varianza', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('ECRPS Promedio', fontsize=10, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.legend(fontsize=8, loc='best', framealpha=0.9)\n",
    "    \n",
    "    plt.suptitle(f'Interacción Config × Var - Modelos Representativos\\n{title_base}', \n",
    "                fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.3{suffix}_interaccion_config_var_2x2.png', \n",
    "                bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.3{suffix} guardada (Config × Var 2x2)\")\n",
    "\n",
    "# INTERACCIÓN CONFIG × DIST - Formato 2x2\n",
    "def plot_interaction_config_dist_2x2(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title_base = 'General' if not scenario else scenario\n",
    "    \n",
    "    configs = sorted(data_filtered['Config'].unique())\n",
    "    dists = sorted(data_filtered['Dist'].unique())\n",
    "    \n",
    "    # Seleccionar 4 modelos representativos\n",
    "    n_models = len(model_cols)\n",
    "    selected_models = [\n",
    "        model_cols[0],\n",
    "        model_cols[n_models // 3],\n",
    "        model_cols[2 * n_models // 3],\n",
    "        model_cols[-1]\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors_config = sns.color_palette(\"Set1\", len(configs))\n",
    "    \n",
    "    for idx, model in enumerate(selected_models):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        x_pos = np.arange(len(dists))\n",
    "        width = 0.25\n",
    "        \n",
    "        for c_idx, config in enumerate(configs):\n",
    "            means = []\n",
    "            for dist in dists:\n",
    "                mean_val = data_filtered[\n",
    "                    (data_filtered['Config'] == config) & \n",
    "                    (data_filtered['Dist'] == dist)\n",
    "                ][model].mean()\n",
    "                means.append(mean_val)\n",
    "            \n",
    "            offset = (c_idx - 1) * width\n",
    "            bars = ax.bar(x_pos + offset, means, width, label=f'Config {config}',\n",
    "                         color=colors_config[c_idx], alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "            \n",
    "            # Añadir valores en las barras\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{height:.2f}', ha='center', va='bottom', fontsize=7)\n",
    "        \n",
    "        ax.set_title(f'{model}', fontsize=11, fontweight='bold', pad=10)\n",
    "        ax.set_xlabel('Distribución', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('ECRPS Promedio', fontsize=10, fontweight='bold')\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(dists, fontsize=9)\n",
    "        ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        ax.legend(fontsize=8, loc='best', framealpha=0.9)\n",
    "    \n",
    "    plt.suptitle(f'Interacción Config × Dist - Modelos Representativos\\n{title_base}', \n",
    "                fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.4{suffix}_interaccion_config_dist_2x2.png', \n",
    "                bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.4{suffix} guardada (Config × Dist 2x2)\")\n",
    "\n",
    "# INTERACCIÓN DIST × PASO - Formato 2x2\n",
    "def plot_interaction_dist_paso_2x2(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title_base = 'General' if not scenario else scenario\n",
    "    \n",
    "    dists = sorted(data_filtered['Dist'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    \n",
    "    # Seleccionar 4 modelos representativos\n",
    "    n_models = len(model_cols)\n",
    "    selected_models = [\n",
    "        model_cols[0],\n",
    "        model_cols[n_models // 3],\n",
    "        model_cols[2 * n_models // 3],\n",
    "        model_cols[-1]\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors_dist = sns.color_palette(\"viridis\", len(dists))\n",
    "    \n",
    "    for idx, model in enumerate(selected_models):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        for d_idx, dist in enumerate(dists):\n",
    "            means = []\n",
    "            for paso in pasos:\n",
    "                mean_val = data_filtered[\n",
    "                    (data_filtered['Dist'] == dist) & \n",
    "                    (data_filtered['Paso'] == paso)\n",
    "                ][model].mean()\n",
    "                means.append(mean_val)\n",
    "            \n",
    "            ax.plot(pasos, means, marker='o', label=f'Dist {dist}',\n",
    "                   color=colors_dist[d_idx], linewidth=2.5, markersize=8, alpha=0.85)\n",
    "        \n",
    "        ax.set_title(f'{model}', fontsize=11, fontweight='bold', pad=10)\n",
    "        ax.set_xlabel('Horizonte (Paso)', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('ECRPS Promedio', fontsize=10, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.legend(fontsize=8, loc='best', framealpha=0.9)\n",
    "    \n",
    "    plt.suptitle(f'Interacción Dist × Paso - Modelos Representativos\\n{title_base}', \n",
    "                fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.5{suffix}_interaccion_dist_paso_2x2.png', \n",
    "                bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.5{suffix} guardada (Dist × Paso 2x2)\")\n",
    "\n",
    "# INTERACCIÓN DIST × VAR - Formato 2x2\n",
    "def plot_interaction_dist_var_2x2(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title_base = 'General' if not scenario else scenario\n",
    "    \n",
    "    dists = sorted(data_filtered['Dist'].unique())\n",
    "    vars_val = sorted(data_filtered['Var'].unique())\n",
    "    \n",
    "    # Seleccionar 4 modelos representativos\n",
    "    n_models = len(model_cols)\n",
    "    selected_models = [\n",
    "        model_cols[0],\n",
    "        model_cols[n_models // 3],\n",
    "        model_cols[2 * n_models // 3],\n",
    "        model_cols[-1]\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors_dist = sns.color_palette(\"magma\", len(dists))\n",
    "    \n",
    "    for idx, model in enumerate(selected_models):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        for d_idx, dist in enumerate(dists):\n",
    "            means = []\n",
    "            for var in vars_val:\n",
    "                mean_val = data_filtered[\n",
    "                    (data_filtered['Dist'] == dist) & \n",
    "                    (data_filtered['Var'] == var)\n",
    "                ][model].mean()\n",
    "                means.append(mean_val)\n",
    "            \n",
    "            ax.plot(vars_val, means, marker='s', label=f'Dist {dist}',\n",
    "                   color=colors_dist[d_idx], linewidth=2.5, markersize=8, alpha=0.85)\n",
    "        \n",
    "        ax.set_title(f'{model}', fontsize=11, fontweight='bold', pad=10)\n",
    "        ax.set_xlabel('Varianza', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('ECRPS Promedio', fontsize=10, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.legend(fontsize=8, loc='best', framealpha=0.9)\n",
    "    \n",
    "    plt.suptitle(f'Interacción Dist × Var - Modelos Representativos\\n{title_base}', \n",
    "                fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.6{suffix}_interaccion_dist_var_2x2.png', \n",
    "                bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.6{suffix} guardada (Dist × Var 2x2)\")\n",
    "\n",
    "# INTERACCIÓN CONFIG × PASO - Formato 2x2\n",
    "def plot_interaction_config_paso_2x2(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title_base = 'General' if not scenario else scenario\n",
    "    \n",
    "    configs = sorted(data_filtered['Config'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    \n",
    "    # Seleccionar 4 modelos representativos\n",
    "    n_models = len(model_cols)\n",
    "    selected_models = [\n",
    "        model_cols[0],\n",
    "        model_cols[n_models // 3],\n",
    "        model_cols[2 * n_models // 3],\n",
    "        model_cols[-1]\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors_config = sns.color_palette(\"tab10\", len(configs))\n",
    "    \n",
    "    for idx, model in enumerate(selected_models):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        for c_idx, config in enumerate(configs):\n",
    "            means = []\n",
    "            for paso in pasos:\n",
    "                mean_val = data_filtered[\n",
    "                    (data_filtered['Config'] == config) & \n",
    "                    (data_filtered['Paso'] == paso)\n",
    "                ][model].mean()\n",
    "                means.append(mean_val)\n",
    "            \n",
    "            ax.plot(pasos, means, marker='^', label=f'Config {config}',\n",
    "                   color=colors_config[c_idx], linewidth=2.5, markersize=8, alpha=0.85)\n",
    "        \n",
    "        ax.set_title(f'{model}', fontsize=11, fontweight='bold', pad=10)\n",
    "        ax.set_xlabel('Horizonte (Paso)', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('ECRPS Promedio', fontsize=10, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.legend(fontsize=8, loc='best', framealpha=0.9)\n",
    "    \n",
    "    plt.suptitle(f'Interacción Config × Paso - Modelos Representativos\\n{title_base}', \n",
    "                fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.7{suffix}_interaccion_config_paso_2x2.png', \n",
    "                bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.7{suffix} guardada (Config × Paso 2x2)\")\n",
    "\n",
    "# INTERACCIÓN VAR × HORIZONTE - Formato 2x2\n",
    "def plot_interaction_var_horizonte_2x2(scenario=None, suffix=''):\n",
    "    data_filtered = df[df['ESCENARIO'] == scenario].copy() if scenario else df.copy()\n",
    "    title_base = 'General' if not scenario else scenario\n",
    "    \n",
    "    vars_val = sorted(data_filtered['Var'].unique())\n",
    "    pasos = sorted(data_filtered['Paso'].unique())\n",
    "    \n",
    "    # Seleccionar 4 modelos representativos\n",
    "    n_models = len(model_cols)\n",
    "    selected_models = [\n",
    "        model_cols[0],\n",
    "        model_cols[n_models // 3],\n",
    "        model_cols[2 * n_models // 3],\n",
    "        model_cols[-1]\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors_var = sns.color_palette(\"rocket\", len(vars_val))\n",
    "    \n",
    "    for idx, model in enumerate(selected_models):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        for v_idx, var in enumerate(vars_val):\n",
    "            means = []\n",
    "            for paso in pasos:\n",
    "                mean_val = data_filtered[\n",
    "                    (data_filtered['Var'] == var) & \n",
    "                    (data_filtered['Paso'] == paso)\n",
    "                ][model].mean()\n",
    "                means.append(mean_val)\n",
    "            \n",
    "            ax.plot(pasos, means, marker='d', label=f'Var {var}',\n",
    "                   color=colors_var[v_idx], linewidth=2.5, markersize=8, alpha=0.85)\n",
    "        \n",
    "        ax.set_title(f'{model}', fontsize=11, fontweight='bold', pad=10)\n",
    "        ax.set_xlabel('Horizonte (Paso)', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('ECRPS Promedio', fontsize=10, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.legend(fontsize=8, loc='best', framealpha=0.9)\n",
    "    \n",
    "    plt.suptitle(f'Interacción Var × Horizonte - Modelos Representativos\\n{title_base}', \n",
    "                fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(interactions_dir / f'5.8{suffix}_interaccion_var_horizonte_2x2.png', \n",
    "                bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"✓ Gráfica 5.8{suffix} guardada (Var × Horizonte 2x2)\")\n",
    "\n",
    "# Ejecutar todas las interacciones para todos los escenarios\n",
    "for sc_name, sc_suf in [(None, ''), \n",
    "                        ('Lineal Estacionario (ARMA)', '.a'), \n",
    "                        ('Lineal No Estacionario (ARIMA)', '.b'), \n",
    "                        ('No lineal Estacionario (SETAR)', '.c')]:\n",
    "    plot_interaction_config_var_2x2(sc_name, sc_suf)\n",
    "    plot_interaction_config_dist_2x2(sc_name, sc_suf)\n",
    "    plot_interaction_dist_paso_2x2(sc_name, sc_suf)\n",
    "    plot_interaction_dist_var_2x2(sc_name, sc_suf)\n",
    "    plot_interaction_config_paso_2x2(sc_name, sc_suf)\n",
    "    plot_interaction_var_horizonte_2x2(sc_name, sc_suf)\n",
    "\n",
    "# ====================================================================================\n",
    "# SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO (CON PROCESO PASO A PASO)\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECCIÓN 6: ROBUSTEZ Y TEST DIEBOLD-MARIANO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def plot_robustness():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    cv_data = []\n",
    "    for model in model_cols:\n",
    "        cv = df[model].std() / df[model].mean()\n",
    "        cv_data.append((model, cv))\n",
    "    \n",
    "    cv_df = pd.DataFrame(cv_data, columns=['Modelo', 'CV'])\n",
    "    cv_df = cv_df.sort_values('CV')\n",
    "    \n",
    "    colors_cv = ['#2ecc71' if cv < cv_df['CV'].median() else '#e74c3c' \n",
    "                 for cv in cv_df['CV']]\n",
    "    \n",
    "    bars = ax.barh(cv_df['Modelo'], cv_df['CV'], color=colors_cv, alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    for bar, cv in zip(bars, cv_df['CV']):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.001, bar.get_y() + bar.get_height()/2.,\n",
    "               f'{cv:.4f}', ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Coeficiente de Variación', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Robustez: Coeficiente de Variación\\n(Menor valor = Mayor estabilidad)', \n",
    "                  fontsize=13, fontweight='bold', pad=20)\n",
    "    ax.axvline(x=cv_df['CV'].median(), color='black', linestyle='--', \n",
    "              linewidth=1.5, alpha=0.5, label='Mediana')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / '6.1_robustez_coeficiente_variacion.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Gráfica 6.1 guardada\")\n",
    "\n",
    "plot_robustness()\n",
    "\n",
    "def modified_diebold_mariano_test(errors1, errors2, h=1):\n",
    "    \"\"\"\n",
    "    Test Diebold-Mariano con fixed-smoothing asymptotics\n",
    "    \"\"\"\n",
    "    d = errors1 - errors2\n",
    "    d_bar = np.mean(d)\n",
    "    T = len(d)\n",
    "    \n",
    "    if T < 2:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    u = d - d_bar\n",
    "    m = max(1, int(np.floor(T**(1/3))))\n",
    "    \n",
    "    from scipy.fft import fft\n",
    "    fft_u = fft(u)\n",
    "    periodogram = np.abs(fft_u)**2 / (2 * np.pi * T)\n",
    "    \n",
    "    if m >= len(periodogram) - 1:\n",
    "        m = len(periodogram) - 2\n",
    "    \n",
    "    sigma_hat_sq = 2 * np.pi * np.mean(periodogram[1:m+1])\n",
    "    \n",
    "    if sigma_hat_sq <= 0:\n",
    "        sigma_hat_sq = np.var(d, ddof=1) / T\n",
    "        if sigma_hat_sq <= 0:\n",
    "            return 0, 1.0\n",
    "    \n",
    "    dm_stat = np.sqrt(T) * d_bar / np.sqrt(sigma_hat_sq)\n",
    "    df = 2 * m\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(dm_stat), df))\n",
    "    \n",
    "    return dm_stat, p_value\n",
    "\n",
    "def compute_dm_tests_step_by_step(scenario=None, suffix=''):\n",
    "    \"\"\"\n",
    "    PROCESO PASO A PASO VISIBLE EN EXCEL:\n",
    "    PASO 1: Tabla de escenarios únicos (420 filas)\n",
    "    PASO 2: Para cada escenario, calcular p-valores para cada par de modelos (6 columnas)\n",
    "    PASO 3: Clasificar si es significativo o no\n",
    "    PASO 4: Reducir a tablas resumen\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"CÁLCULO TEST DIEBOLD-MARIANO - PROCESO PASO A PASO\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Determinar tipo de análisis\n",
    "    analysis_type = {\n",
    "        '': 'GENERAL',\n",
    "        '.a': 'ARMA',\n",
    "        '.b': 'ARIMA',\n",
    "        '.c': 'SETAR'\n",
    "    }\n",
    "    tipo = analysis_type.get(suffix, 'GENERAL')\n",
    "    \n",
    "    if scenario:\n",
    "        data_filtered = df[df['ESCENARIO'] == scenario].copy()\n",
    "    else:\n",
    "        data_filtered = df.copy()\n",
    "    \n",
    "    print(f\"Tipo de análisis: {tipo}\")\n",
    "    \n",
    "    # PASO 1: Identificar escenarios únicos\n",
    "    scenario_cols = ['Paso', 'Config', 'Dist', 'Var']\n",
    "    unique_scenarios = data_filtered[scenario_cols].drop_duplicates().reset_index(drop=True)\n",
    "    n_scenarios = len(unique_scenarios)\n",
    "    \n",
    "    print(f\"PASO 1: Escenarios únicos identificados: {n_scenarios}\")\n",
    "    \n",
    "    # Generar pares de modelos\n",
    "    from itertools import combinations\n",
    "    model_pairs = list(combinations(model_cols, 2))\n",
    "    n_comparisons = len(model_pairs)\n",
    "    \n",
    "    print(f\"Número de comparaciones por escenario: {n_comparisons}\")\n",
    "    \n",
    "    # Calcular alpha con Bonferroni\n",
    "    alpha = 0.05\n",
    "    alpha_bonferroni = alpha / n_comparisons\n",
    "    \n",
    "    print(f\"α nominal: {alpha}\")\n",
    "    print(f\"α Bonferroni: {alpha_bonferroni:.6f}\")\n",
    "    \n",
    "    # PASO 2: Crear tabla 420 × 6 con p-valores\n",
    "    print(\"\\nPASO 2: Calculando p-valores para cada escenario y par de modelos...\")\n",
    "    \n",
    "    # Crear columnas para cada comparación\n",
    "    comparison_names = [f\"{m1}_vs_{m2}\" for m1, m2 in model_pairs]\n",
    "    pvalue_columns = [f\"pval_{comp}\" for comp in comparison_names]\n",
    "    dmstat_columns = [f\"dmstat_{comp}\" for comp in comparison_names]\n",
    "    mean_diff_columns = [f\"meandiff_{comp}\" for comp in comparison_names]\n",
    "    \n",
    "    # DataFrame para almacenar resultados por escenario\n",
    "    scenario_results = unique_scenarios.copy()\n",
    "    scenario_results['Escenario_ID'] = range(1, n_scenarios + 1)\n",
    "    \n",
    "    # Añadir columnas de p-valores, estadísticos DM y diferencias de medias\n",
    "    for comp_name in comparison_names:\n",
    "        scenario_results[f'pval_{comp_name}'] = np.nan\n",
    "        scenario_results[f'dmstat_{comp_name}'] = np.nan\n",
    "        scenario_results[f'meandiff_{comp_name}'] = np.nan\n",
    "        scenario_results[f'mean_A_{comp_name}'] = np.nan\n",
    "        scenario_results[f'mean_B_{comp_name}'] = np.nan\n",
    "    \n",
    "    # Calcular para cada escenario\n",
    "    for idx, scenario_row in unique_scenarios.iterrows():\n",
    "        # Filtrar datos para este escenario\n",
    "        scenario_data = data_filtered[\n",
    "            (data_filtered['Paso'] == scenario_row['Paso']) &\n",
    "            (data_filtered['Config'] == scenario_row['Config']) &\n",
    "            (data_filtered['Dist'] == scenario_row['Dist']) &\n",
    "            (data_filtered['Var'] == scenario_row['Var'])\n",
    "        ]\n",
    "        \n",
    "        paso_h = int(scenario_row['Paso'])\n",
    "        \n",
    "        # Para cada par de modelos\n",
    "        for (model_a, model_b), comp_name in zip(model_pairs, comparison_names):\n",
    "            errors_a = scenario_data[model_a].values\n",
    "            errors_b = scenario_data[model_b].values\n",
    "            \n",
    "            if len(errors_a) > 0 and len(errors_b) > 0:\n",
    "                # Calcular test DM\n",
    "                dm_stat, p_value = modified_diebold_mariano_test(errors_a, errors_b, h=paso_h)\n",
    "                \n",
    "                # Calcular medias\n",
    "                mean_a = np.mean(errors_a)\n",
    "                mean_b = np.mean(errors_b)\n",
    "                mean_diff = mean_a - mean_b\n",
    "                \n",
    "                # Guardar en tabla\n",
    "                scenario_results.loc[idx, f'pval_{comp_name}'] = p_value\n",
    "                scenario_results.loc[idx, f'dmstat_{comp_name}'] = dm_stat\n",
    "                scenario_results.loc[idx, f'meandiff_{comp_name}'] = mean_diff\n",
    "                scenario_results.loc[idx, f'mean_A_{comp_name}'] = mean_a\n",
    "                scenario_results.loc[idx, f'mean_B_{comp_name}'] = mean_b\n",
    "    \n",
    "    print(f\"✓ Tabla de {n_scenarios} escenarios × {n_comparisons} comparaciones completada\")\n",
    "    \n",
    "    # PASO 3: Clasificar significancia\n",
    "    print(\"\\nPASO 3: Clasificando significancia estadística...\")\n",
    "    \n",
    "    significance_table = scenario_results[['Escenario_ID', 'Paso', 'Config', 'Dist', 'Var']].copy()\n",
    "    \n",
    "    for comp_name in comparison_names:\n",
    "        pval_col = f'pval_{comp_name}'\n",
    "        sig_col = f'sig_{comp_name}'\n",
    "        \n",
    "        significance_table[sig_col] = scenario_results[pval_col] < alpha_bonferroni\n",
    "        significance_table[sig_col] = significance_table[sig_col].map({True: 'SÍ', False: 'NO'})\n",
    "    \n",
    "    print(f\"✓ Tabla de significancia creada\")\n",
    "    \n",
    "    # PASO 4: Reducir a resumen\n",
    "    print(\"\\nPASO 4: Creando tablas resumen...\")\n",
    "    \n",
    "    # Tabla resumen por comparación\n",
    "    summary_by_comparison = []\n",
    "    \n",
    "    for (model_a, model_b), comp_name in zip(model_pairs, comparison_names):\n",
    "        pval_col = f'pval_{comp_name}'\n",
    "        dmstat_col = f'dmstat_{comp_name}'\n",
    "        mean_a_col = f'mean_A_{comp_name}'\n",
    "        mean_b_col = f'mean_B_{comp_name}'\n",
    "        \n",
    "        n_tests = scenario_results[pval_col].notna().sum()\n",
    "        n_significant = (scenario_results[pval_col] < alpha_bonferroni).sum()\n",
    "        pct_significant = (n_significant / n_tests * 100) if n_tests > 0 else 0\n",
    "        \n",
    "        mean_ecrps_a = scenario_results[mean_a_col].mean()\n",
    "        mean_ecrps_b = scenario_results[mean_b_col].mean()\n",
    "        \n",
    "        # A es mejor cuando tiene menor ECRPS\n",
    "        n_a_better = (scenario_results[mean_a_col] < scenario_results[mean_b_col]).sum()\n",
    "        pct_a_better = (n_a_better / n_tests * 100) if n_tests > 0 else 0\n",
    "        \n",
    "        summary_by_comparison.append({\n",
    "            'Modelo_A': model_a,\n",
    "            'Modelo_B': model_b,\n",
    "            'Comparación': f'{model_a} vs {model_b}',\n",
    "            'N_Escenarios_Evaluados': n_tests,\n",
    "            'N_Significativos': n_significant,\n",
    "            'Pct_Significativos': pct_significant,\n",
    "            'ECRPS_Medio_A': mean_ecrps_a,\n",
    "            'ECRPS_Medio_B': mean_ecrps_b,\n",
    "            'Diferencia_Media': mean_ecrps_a - mean_ecrps_b,\n",
    "            'N_A_Mejor_que_B': n_a_better,\n",
    "            'Pct_A_Mejor_que_B': pct_a_better\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_by_comparison)\n",
    "    \n",
    "    print(f\"✓ Tabla resumen por comparación creada ({len(summary_df)} filas)\")\n",
    "    \n",
    "    # Matriz modelo vs modelo\n",
    "    n_models = len(model_cols)\n",
    "    sig_matrix = np.zeros((n_models, n_models))\n",
    "    ecrps_matrix = np.zeros((n_models, n_models))\n",
    "    \n",
    "    for idx_a, model_a in enumerate(model_cols):\n",
    "        for idx_b, model_b in enumerate(model_cols):\n",
    "            if idx_a == idx_b:\n",
    "                # Diagonal: ECRPS medio del modelo\n",
    "                model_data = data_filtered[model_a]\n",
    "                ecrps_matrix[idx_a, idx_b] = model_data.mean()\n",
    "            else:\n",
    "                # Buscar comparación\n",
    "                comp_found = False\n",
    "                for row in summary_by_comparison:\n",
    "                    if row['Modelo_A'] == model_a and row['Modelo_B'] == model_b:\n",
    "                        sig_matrix[idx_a, idx_b] = row['Pct_Significativos']\n",
    "                        ecrps_matrix[idx_a, idx_b] = row['ECRPS_Medio_A']\n",
    "                        comp_found = True\n",
    "                        break\n",
    "                    elif row['Modelo_A'] == model_b and row['Modelo_B'] == model_a:\n",
    "                        sig_matrix[idx_a, idx_b] = row['Pct_Significativos']\n",
    "                        ecrps_matrix[idx_a, idx_b] = row['ECRPS_Medio_B']\n",
    "                        comp_found = True\n",
    "                        break\n",
    "    \n",
    "    sig_matrix_df = pd.DataFrame(sig_matrix, index=model_cols, columns=model_cols)\n",
    "    ecrps_matrix_df = pd.DataFrame(ecrps_matrix, index=model_cols, columns=model_cols)\n",
    "    \n",
    "    print(f\"✓ Matrices modelo vs modelo creadas\")\n",
    "    \n",
    "    # GUARDAR EN EXCEL CON MÚLTIPLES HOJAS\n",
    "    excel_filename = f'6.2{suffix}_dm_proceso_completo.xlsx'\n",
    "    \n",
    "    with pd.ExcelWriter(output_dir / excel_filename, engine='openpyxl') as writer:\n",
    "        # Hoja 0: Metodología\n",
    "        method_info = pd.DataFrame({\n",
    "            'Parámetro': ['Tipo de análisis', 'Alpha nominal', 'Alpha Bonferroni', \n",
    "                          'Número de modelos', 'Comparaciones por escenario', \n",
    "                          'Número de escenarios únicos', 'Total de tests',\n",
    "                          'Test estadístico', 'Distribución'],\n",
    "            'Valor': [tipo, alpha, alpha_bonferroni, len(model_cols), n_comparisons,\n",
    "                      n_scenarios, n_scenarios * n_comparisons, \n",
    "                      'Diebold-Mariano (HLN)', 't-Student']\n",
    "        })\n",
    "        method_info.to_excel(writer, sheet_name='0_Metodologia', index=False)\n",
    "        \n",
    "        # Hoja 1: PASO 1 - Escenarios únicos (420 filas)\n",
    "        unique_scenarios_display = unique_scenarios.copy()\n",
    "        unique_scenarios_display.insert(0, 'Escenario_ID', range(1, n_scenarios + 1))\n",
    "        unique_scenarios_display.to_excel(writer, sheet_name='1_Escenarios_Unicos', index=False)\n",
    "        \n",
    "        # Hoja 2: PASO 2 - Tabla 420×6 con P-valores\n",
    "        pvalue_table = scenario_results[['Escenario_ID', 'Paso', 'Config', 'Dist', 'Var'] + \n",
    "                                        [f'pval_{comp}' for comp in comparison_names]].copy()\n",
    "        pvalue_table.to_excel(writer, sheet_name='2_PValores_Por_Escenario', index=False)\n",
    "        \n",
    "        # Hoja 2b: Estadísticos DM\n",
    "        dmstat_table = scenario_results[['Escenario_ID', 'Paso', 'Config', 'Dist', 'Var'] + \n",
    "                                        [f'dmstat_{comp}' for comp in comparison_names]].copy()\n",
    "        dmstat_table.to_excel(writer, sheet_name='2b_DMStats_Por_Escenario', index=False)\n",
    "        \n",
    "        # Hoja 2c: Medias por modelo\n",
    "        means_table = scenario_results[['Escenario_ID', 'Paso', 'Config', 'Dist', 'Var']].copy()\n",
    "        for comp_name in comparison_names:\n",
    "            means_table[f'mean_A_{comp_name}'] = scenario_results[f'mean_A_{comp_name}']\n",
    "            means_table[f'mean_B_{comp_name}'] = scenario_results[f'mean_B_{comp_name}']\n",
    "        means_table.to_excel(writer, sheet_name='2c_Medias_Por_Escenario', index=False)\n",
    "        \n",
    "        # Hoja 3: PASO 3 - Clasificación de significancia\n",
    "        significance_table.to_excel(writer, sheet_name='3_Clasificacion_Significancia', index=False)\n",
    "        \n",
    "        # Hoja 4: PASO 4 - Resumen por comparación\n",
    "        summary_df.to_excel(writer, sheet_name='4_Resumen_Por_Comparacion', index=False)\n",
    "        \n",
    "        # Hoja 5: Matriz de % Significancia\n",
    "        sig_matrix_df.to_excel(writer, sheet_name='5_Matriz_Pct_Significancia')\n",
    "        \n",
    "        # Hoja 6: Matriz de ECRPS Medio\n",
    "        ecrps_matrix_df.to_excel(writer, sheet_name='6_Matriz_ECRPS_Medio')\n",
    "    \n",
    "    print(f\"\\n✓ Excel guardado: {excel_filename}\")\n",
    "    print(f\"  - Hoja 1: {n_scenarios} escenarios únicos\")\n",
    "    print(f\"  - Hoja 2: {n_scenarios} × {n_comparisons} p-valores\")\n",
    "    print(f\"  - Hoja 3: {n_scenarios} × {n_comparisons} clasificaciones\")\n",
    "    print(f\"  - Hoja 4: {n_comparisons} resúmenes por comparación\")\n",
    "    print(f\"  - Hojas 5-6: Matrices {n_models}×{n_models}\")\n",
    "    \n",
    "    # CREAR VISUALIZACIÓN\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 10))\n",
    "    \n",
    "    # Heatmap 1: % Significancia\n",
    "    sns.heatmap(sig_matrix_df, annot=True, fmt='.1f', cmap='RdYlGn', \n",
    "                center=50, vmin=0, vmax=100, ax=ax1,\n",
    "                cbar_kws={'label': '% Tests Significativos'},\n",
    "                linewidths=0.5, linecolor='gray', annot_kws={'fontsize': 9})\n",
    "    \n",
    "    ax1.set_title(f'% de Tests Significativos\\n(α Bonferroni = {alpha_bonferroni:.6f}) [{tipo}]', \n",
    "                  fontsize=12, fontweight='bold', pad=15)\n",
    "    ax1.set_xlabel('Modelo B', fontsize=11, fontweight='bold')\n",
    "    ax1.set_ylabel('Modelo A', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Heatmap 2: ECRPS Medio\n",
    "    sns.heatmap(ecrps_matrix_df, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                ax=ax2, cbar_kws={'label': 'ECRPS Promedio'},\n",
    "                linewidths=0.5, linecolor='gray', annot_kws={'fontsize': 9})\n",
    "    \n",
    "    ax2.set_title(f'ECRPS Promedio por Modelo\\n[{tipo}]', \n",
    "                  fontsize=12, fontweight='bold', pad=15)\n",
    "    ax2.set_xlabel('Modelo B', fontsize=11, fontweight='bold')\n",
    "    ax2.set_ylabel('Modelo A', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle(f'Test Diebold-Mariano: Proceso Completo\\n{n_scenarios} escenarios × {n_comparisons} comparaciones = {n_scenarios * n_comparisons} tests', \n",
    "                 fontsize=14, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f'6.2{suffix}_dm_matriz_comparativa.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Gráfica guardada: 6.2{suffix}_dm_matriz_comparativa.png\")\n",
    "    \n",
    "    return scenario_results, summary_df, sig_matrix_df, ecrps_matrix_df\n",
    "\n",
    "# Ejecutar análisis DM para cada tipo de escenario\n",
    "for scenario_name, suffix in [(None, ''), \n",
    "                               ('Lineal Estacionario (ARMA)', '.a'),\n",
    "                               ('Lineal No Estacionario (ARIMA)', '.b'),\n",
    "                               ('No lineal Estacionario (SETAR)', '.c')]:\n",
    "    compute_dm_tests_step_by_step(scenario_name, suffix)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESO COMPLETADO CON ÉXITO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n📊 ESTRUCTURA DE OUTPUTS:\")\n",
    "print(\"\\nEXCEL (6.2[suffix]_dm_proceso_completo.xlsx):\")\n",
    "print(\"  Hoja 0: Metodología\")\n",
    "print(\"  Hoja 1: 420 escenarios únicos (Paso, Config, Dist, Var)\")\n",
    "print(\"  Hoja 2: 420 × 6 p-valores (cada columna = 1 comparación)\")\n",
    "print(\"  Hoja 2b: 420 × 6 estadísticos DM\")\n",
    "print(\"  Hoja 2c: 420 × 12 medias (A y B por comparación)\")\n",
    "print(\"  Hoja 3: 420 × 6 significancia (SÍ/NO)\")\n",
    "print(\"  Hoja 4: Resumen reducido (6 comparaciones)\")\n",
    "print(\"  Hoja 5: Matriz NxN % significancia\")\n",
    "print(\"  Hoja 6: Matriz NxN ECRPS medio\")\n",
    "print(\"\\nGRÁFICA (6.2[suffix]_dm_matriz_comparativa.png):\")\n",
    "print(\"  Panel izquierdo: Heatmap % significancia\")\n",
    "print(\"  Panel derecho: Heatmap ECRPS medio\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b4784b",
   "metadata": {},
   "source": [
    "### DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "892d9a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  DM TEST — GENERAL\n",
      "=================================================================\n",
      "  Grupos (Config × Dist × Var): 420\n",
      "  Pasos por grupo             : 12  (serie temporal)\n",
      "  Pares de modelos            : 6\n",
      "  α Bonferroni                : 0.008333\n",
      "  Tamaño tabla de resultados  : 420 × 6\n",
      "  ✓ Heatmap guardado → 6.4_matriz_DM.png\n",
      "  ✓ Excel guardado    → 6.4_dm_resultados.xlsx\n",
      "    Hoja 1: 420 filas × 6 pares (p-valores)\n",
      "    Hojas 7-8: matrices 4×4\n",
      "\n",
      "=================================================================\n",
      "  DM TEST — ARMA\n",
      "=================================================================\n",
      "  Grupos (Config × Dist × Var): 140\n",
      "  Pasos por grupo             : 12  (serie temporal)\n",
      "  Pares de modelos            : 6\n",
      "  α Bonferroni                : 0.008333\n",
      "  Tamaño tabla de resultados  : 140 × 6\n",
      "  ✓ Heatmap guardado → 6.4.a_matriz_DM.png\n",
      "  ✓ Excel guardado    → 6.4.a_dm_resultados.xlsx\n",
      "    Hoja 1: 140 filas × 6 pares (p-valores)\n",
      "    Hojas 7-8: matrices 4×4\n",
      "\n",
      "=================================================================\n",
      "  DM TEST — ARIMA\n",
      "=================================================================\n",
      "  Grupos (Config × Dist × Var): 140\n",
      "  Pasos por grupo             : 12  (serie temporal)\n",
      "  Pares de modelos            : 6\n",
      "  α Bonferroni                : 0.008333\n",
      "  Tamaño tabla de resultados  : 140 × 6\n",
      "  ✓ Heatmap guardado → 6.4.b_matriz_DM.png\n",
      "  ✓ Excel guardado    → 6.4.b_dm_resultados.xlsx\n",
      "    Hoja 1: 140 filas × 6 pares (p-valores)\n",
      "    Hojas 7-8: matrices 4×4\n",
      "\n",
      "=================================================================\n",
      "  DM TEST — SETAR\n",
      "=================================================================\n",
      "  Grupos (Config × Dist × Var): 140\n",
      "  Pasos por grupo             : 12  (serie temporal)\n",
      "  Pares de modelos            : 6\n",
      "  α Bonferroni                : 0.008333\n",
      "  Tamaño tabla de resultados  : 140 × 6\n",
      "  ✓ Heatmap guardado → 6.4.c_matriz_DM.png\n",
      "  ✓ Excel guardado    → 6.4.c_dm_resultados.xlsx\n",
      "    Hoja 1: 140 filas × 6 pares (p-valores)\n",
      "    Hojas 7-8: matrices 4×4\n",
      "\n",
      "=================================================================\n",
      "  PROCESO COMPLETADO\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TEST DIEBOLD-MARIANO — LÓGICA CORRECTA\n",
    "=======================================\n",
    "Para cada grupo (Config × Dist × Var) dentro de un ESCENARIO:\n",
    "  - Ordenar por Paso (1..12)\n",
    "  - Serie A = ECRPS del Modelo A en esos 12 pasos  → vector de longitud 12\n",
    "  - Serie B = ECRPS del Modelo B en esos 12 pasos  → vector de longitud 12\n",
    "  - d_t = A_t - B_t  (t = 1..12)\n",
    "  - Aplicar DM → 1 p-valor por par de modelos por grupo\n",
    "\n",
    "Resultado: tabla 105 × 6  (por escenario) ó 315 × 6 (general)\n",
    "           → resumen en heatmap con % Significancia y % Fila < Columna\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# CONFIGURACIÓN\n",
    "# ------------------------------------------------------------------ #\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 300, 'savefig.dpi': 300,\n",
    "    'font.size': 10, 'font.family': 'sans-serif',\n",
    "    'axes.labelweight': 'bold', 'axes.titleweight': 'bold'\n",
    "})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "output_dir = Path(\"./Resultados_analisis/Simulacion_h\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# CARGAR DATOS\n",
    "# ------------------------------------------------------------------ #\n",
    "df = pd.read_excel(\"./datos/Simulacion_h/dataframe_consolidado.xlsx\")\n",
    "\n",
    "df['ESCENARIO'] = df['ESCENARIO'].replace({\n",
    "    \"Lineal Estacionario\":    \"Lineal Estacionario (ARMA)\",\n",
    "    \"Lineal No estacionario\": \"Lineal No Estacionario (ARIMA)\",\n",
    "    \"No lineal Estacionario\": \"No lineal Estacionario (SETAR)\"\n",
    "})\n",
    "\n",
    "var_cols   = ['Paso', 'Config', 'Dist', 'Var', 'ESCENARIO']\n",
    "model_cols = [c for c in df.columns if c not in var_cols]\n",
    "\n",
    "# Ordenar modelos por desempeño en ARIMA (menor ECRPS primero)\n",
    "arima_means = df[df['ESCENARIO'] == \"Lineal No Estacionario (ARIMA)\"][model_cols].mean()\n",
    "model_cols  = list(arima_means.sort_values().index)\n",
    "\n",
    "ESCENARIOS = {\n",
    "    '':   None,                               # General (todos)\n",
    "    '.a': 'Lineal Estacionario (ARMA)',\n",
    "    '.b': 'Lineal No Estacionario (ARIMA)',\n",
    "    '.c': 'No lineal Estacionario (SETAR)',\n",
    "}\n",
    "\n",
    "LABEL = {\n",
    "    '': 'GENERAL', '.a': 'ARMA', '.b': 'ARIMA', '.c': 'SETAR'\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# FUNCIÓN DM — Newey-West + HLN\n",
    "# ------------------------------------------------------------------ #\n",
    "def dm_hln(ea: np.ndarray, eb: np.ndarray, h: int = 1):\n",
    "    \"\"\"\n",
    "    Diebold-Mariano con Newey-West (kernel Bartlett) y corrección HLN.\n",
    "\n",
    "    ea, eb : arrays de ECRPS alineados por Paso (misma longitud T).\n",
    "    h      : horizonte de pronóstico del test. Para pronósticos multi-paso\n",
    "             donde cada elemento de la serie es un horizonte distinto (Paso 1..12),\n",
    "             se usa h=1 (interpretación: comparamos forecasters, no h-step-ahead).\n",
    "             NO debe pasarse len(ea) porque con h=T el factor HLN se anula.\n",
    "\n",
    "    Retorna (dm_stat, p_value) o (NaN, NaN) si T < 3.\n",
    "    \"\"\"\n",
    "    d  = np.asarray(ea, float) - np.asarray(eb, float)\n",
    "    T  = len(d)\n",
    "    if T < 3:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    d_bar = d.mean()\n",
    "\n",
    "    # --- Varianza de largo plazo: Newey-West con kernel Bartlett ---\n",
    "    m       = max(1, int(np.floor(T ** (1.0 / 3.0))))\n",
    "    gamma   = np.array([\n",
    "        np.mean((d[:T-k] - d_bar) * (d[k:] - d_bar))\n",
    "        for k in range(m + 1)\n",
    "    ])\n",
    "    weights = 1.0 - np.arange(1, m + 1) / (m + 1)\n",
    "    var_d   = gamma[0] + 2.0 * np.dot(weights, gamma[1:])\n",
    "\n",
    "    # --- Fallback si var_d es nula (serie d perfectamente constante) ---\n",
    "    # Esto ocurre cuando los errores de ambos modelos siguen exactamente\n",
    "    # el mismo patrón: la diferencia es sistemática y estable.\n",
    "    # En ese caso usamos varianza empírica muestral como estimador mínimo.\n",
    "    if var_d <= 1e-15:\n",
    "        var_d = np.var(d, ddof=1)\n",
    "    if var_d <= 1e-15:\n",
    "        # d constante y diferente de 0: diferencia perfectamente sistemática\n",
    "        # -> el test es máximamente significativo\n",
    "        direction = np.sign(d_bar) if d_bar != 0 else 1.0\n",
    "        return float(direction * np.inf), 0.0\n",
    "\n",
    "    # --- Estadístico DM base ---\n",
    "    dm_raw = d_bar / np.sqrt(var_d / T)\n",
    "\n",
    "    # --- Corrección HLN (Harvey, Leybourne & Newbold 1997) ---\n",
    "    # IMPORTANTE: h es el horizonte del forecast (Paso), NO len(serie).\n",
    "    # Si se pasa h = T, el numerador (T+1-2T+T(T-1)/T) = 0 -> DM = 0 -> p = 1.\n",
    "    hln_num = T + 1.0 - 2.0 * h + h * (h - 1.0) / T\n",
    "    hln_num = max(hln_num, 1.0)   # mínimo: equivalente a no corregir (h=1 aprox)\n",
    "    dm_stat = dm_raw * np.sqrt(hln_num / T)\n",
    "\n",
    "    p_val = 2.0 * stats.t.sf(abs(dm_stat), df=T - 1)\n",
    "    return float(dm_stat), float(p_val)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# FUNCIÓN PRINCIPAL\n",
    "# ------------------------------------------------------------------ #\n",
    "def run_dm_analysis(suffix: str = ''):\n",
    "    scenario_filter = ESCENARIOS[suffix]\n",
    "    label           = LABEL[suffix]\n",
    "\n",
    "    # ── Filtrar datos ───────────────────────────────────────────────\n",
    "    data = df.copy() if scenario_filter is None else \\\n",
    "           df[df['ESCENARIO'] == scenario_filter].copy()\n",
    "\n",
    "    # ── Grupos: (Config, Dist, Var) [+ ESCENARIO si es general] ────\n",
    "    # El Paso se usa como eje temporal DENTRO de cada grupo.\n",
    "    group_keys = ['Config', 'Dist', 'Var'] if scenario_filter else \\\n",
    "                 ['ESCENARIO', 'Config', 'Dist', 'Var']\n",
    "\n",
    "    groups     = data[group_keys].drop_duplicates().reset_index(drop=True)\n",
    "    n_groups   = len(groups)\n",
    "\n",
    "    model_pairs  = list(combinations(model_cols, 2))\n",
    "    n_pairs      = len(model_pairs)\n",
    "    pair_names   = [f\"{a} vs {b}\" for a, b in model_pairs]\n",
    "\n",
    "    alpha            = 0.05\n",
    "    alpha_bonferroni = alpha / n_pairs\n",
    "\n",
    "    print(f\"\\n{'='*65}\")\n",
    "    print(f\"  DM TEST — {label}\")\n",
    "    print(f\"{'='*65}\")\n",
    "    print(f\"  Grupos (Config × Dist × Var): {n_groups}\")\n",
    "    print(f\"  Pasos por grupo             : {data['Paso'].nunique()}  (serie temporal)\")\n",
    "    print(f\"  Pares de modelos            : {n_pairs}\")\n",
    "    print(f\"  α Bonferroni                : {alpha_bonferroni:.6f}\")\n",
    "    print(f\"  Tamaño tabla de resultados  : {n_groups} × {n_pairs}\")\n",
    "\n",
    "    # ── PASO 1 — Tabla detallada: n_groups × n_pairs ───────────────\n",
    "    # Columnas: group_keys + [DM_stat, P_valor, Mean_A, Mean_B]  × n_pairs\n",
    "    records = []\n",
    "\n",
    "    for _, grp in groups.iterrows():\n",
    "        # Filtrar las filas del grupo y ordenar por Paso\n",
    "        mask = pd.Series([True] * len(data), index=data.index)\n",
    "        for k in group_keys:\n",
    "            mask &= (data[k] == grp[k])\n",
    "        grp_data = data[mask].sort_values('Paso')\n",
    "\n",
    "        row = {k: grp[k] for k in group_keys}\n",
    "\n",
    "        for (ma, mb), pname in zip(model_pairs, pair_names):\n",
    "            ea = grp_data[ma].values\n",
    "            eb = grp_data[mb].values\n",
    "\n",
    "            # h=1: cada elemento de la serie es un horizonte distinto (Paso 1..12).\n",
    "            # No es un forecast h-step-ahead del mismo origen, sino un\n",
    "            # forecast 1-step-ahead repetido en distintos horizontes.\n",
    "            # Pasar h=len(ea)=12 anularía el factor HLN -> DM=0 -> p=1.\n",
    "            dm_stat, p_val = dm_hln(ea, eb, h=1)\n",
    "\n",
    "            row[f'DM_stat | {pname}']  = round(dm_stat, 6) if not np.isnan(dm_stat) else np.nan\n",
    "            row[f'P_valor | {pname}']  = round(p_val,   6) if not np.isnan(p_val)   else np.nan\n",
    "            row[f'Sig_Bonf | {pname}'] = ('SÍ' if (not np.isnan(p_val) and p_val < alpha_bonferroni)\n",
    "                                          else 'NO')\n",
    "            row[f'Mean_A | {pname}']   = round(float(ea.mean()), 6)\n",
    "            row[f'Mean_B | {pname}']   = round(float(eb.mean()), 6)\n",
    "            row[f'A<B | {pname}']      = 'SÍ' if ea.mean() < eb.mean() else 'NO'\n",
    "\n",
    "        records.append(row)\n",
    "\n",
    "    detail_df = pd.DataFrame(records)\n",
    "\n",
    "    # ── PASO 2 — Tabla de p-valores limpia (n_groups × n_pairs) ────\n",
    "    pval_cols = [f'P_valor | {p}' for p in pair_names]\n",
    "    dm_cols   = [f'DM_stat | {p}' for p in pair_names]\n",
    "    sig_cols  = [f'Sig_Bonf | {p}' for p in pair_names]\n",
    "    mA_cols   = [f'Mean_A | {p}' for p in pair_names]\n",
    "    mB_cols   = [f'Mean_B | {p}' for p in pair_names]\n",
    "    ab_cols   = [f'A<B | {p}' for p in pair_names]\n",
    "\n",
    "    # ── PASO 3 — Matrices resumen NxN ──────────────────────────────\n",
    "    n_mod = len(model_cols)\n",
    "    sig_pct_mat  = np.zeros((n_mod, n_mod))   # % grupos donde p < α_bonf\n",
    "    mean_pct_mat = np.zeros((n_mod, n_mod))   # % grupos donde mean_fila < mean_col\n",
    "\n",
    "    for (ma, mb), pname in zip(model_pairs, pair_names):\n",
    "        ia, ib = model_cols.index(ma), model_cols.index(mb)\n",
    "\n",
    "        pvals  = detail_df[f'P_valor | {pname}'].dropna()\n",
    "        meansA = detail_df[f'Mean_A | {pname}']\n",
    "        meansB = detail_df[f'Mean_B | {pname}']\n",
    "\n",
    "        n_val   = len(pvals)\n",
    "        n_sig   = (pvals < alpha_bonferroni).sum()\n",
    "        pct_sig = 100.0 * n_sig / n_val if n_val > 0 else 0.0\n",
    "\n",
    "        n_A_lt_B = (meansA < meansB).sum()\n",
    "        n_B_lt_A = (meansB < meansA).sum()\n",
    "        pct_A_lt_B = 100.0 * n_A_lt_B / len(meansA)\n",
    "        pct_B_lt_A = 100.0 * n_B_lt_A / len(meansB)\n",
    "\n",
    "        # Sig es simétrica\n",
    "        sig_pct_mat[ia, ib] = pct_sig\n",
    "        sig_pct_mat[ib, ia] = pct_sig\n",
    "\n",
    "        # % fila < columna (asimétrica):  [ia,ib] = A<B,  [ib,ia] = B<A\n",
    "        mean_pct_mat[ia, ib] = pct_A_lt_B\n",
    "        mean_pct_mat[ib, ia] = pct_B_lt_A\n",
    "\n",
    "    sig_df  = pd.DataFrame(sig_pct_mat,  index=model_cols, columns=model_cols)\n",
    "    mean_df = pd.DataFrame(mean_pct_mat, index=model_cols, columns=model_cols)\n",
    "\n",
    "    # Diagonal: NaN (no aplica)\n",
    "    np.fill_diagonal(sig_pct_mat,  np.nan)\n",
    "    np.fill_diagonal(mean_pct_mat, np.nan)\n",
    "\n",
    "    # ── PASO 4 — Heatmap combinado ──────────────────────────────────\n",
    "    annot = np.empty((n_mod, n_mod), dtype=object)\n",
    "    for i in range(n_mod):\n",
    "        for j in range(n_mod):\n",
    "            if i == j:\n",
    "                annot[i, j] = f'{data[model_cols[i]].mean():.4f}'\n",
    "            else:\n",
    "                annot[i, j] = (\n",
    "                    f'Sig: {sig_pct_mat[i,j]:.0f}%\\n'\n",
    "                    f'F<C: {mean_pct_mat[i,j]:.0f}%'\n",
    "                )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(max(14, n_mod * 2), max(12, n_mod * 1.8)))\n",
    "\n",
    "    # Base del heatmap = % Significancia\n",
    "    heat_data = pd.DataFrame(sig_pct_mat, index=model_cols, columns=model_cols)\n",
    "\n",
    "    sns.heatmap(\n",
    "        heat_data, annot=annot, fmt='', cmap='RdYlGn',\n",
    "        center=50, vmin=0, vmax=100, ax=ax,\n",
    "        cbar_kws={'label': '% Tests Significativos (Bonferroni)'},\n",
    "        linewidths=0.6, linecolor='gray',\n",
    "        annot_kws={'fontsize': 8}\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        f'Matriz DM — {label}\\n'\n",
    "        f'Sig: % grupos (de {n_groups}) con p < α Bonf ({alpha_bonferroni:.5f})  |  '\n",
    "        f'F<C: % grupos con media fila < media columna',\n",
    "        fontsize=12, fontweight='bold', pad=15\n",
    "    )\n",
    "    ax.set_xlabel('Modelo (Columna C)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Modelo (Fila F)',    fontsize=11, fontweight='bold')\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "    ax.tick_params(axis='y', rotation=0,  labelsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    png_path = output_dir / f'6.4{suffix}_matriz_DM.png'\n",
    "    plt.savefig(png_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"  ✓ Heatmap guardado → {png_path.name}\")\n",
    "\n",
    "    # ── PASO 5 — Excel con todas las hojas ─────────────────────────\n",
    "    excel_path = output_dir / f'6.4{suffix}_dm_resultados.xlsx'\n",
    "\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "\n",
    "        # Hoja 0: Metodología\n",
    "        pd.DataFrame({\n",
    "            'Parámetro': [\n",
    "                'Análisis', 'Alpha nominal', 'Alpha Bonferroni',\n",
    "                'Modelos comparados', 'Pares totales',\n",
    "                'Grupos (Config×Dist×Var)', 'Pasos por grupo (serie DM)',\n",
    "                'Tabla de resultados', 'Test', 'Corrección varianza', 'Corrección estadístico'\n",
    "            ],\n",
    "            'Valor': [\n",
    "                label, alpha, round(alpha_bonferroni, 8),\n",
    "                len(model_cols), n_pairs,\n",
    "                n_groups, data['Paso'].nunique(),\n",
    "                f'{n_groups} filas × {n_pairs} pares',\n",
    "                'Diebold-Mariano', 'Newey-West Bartlett (BW = floor(T^1/3))',\n",
    "                'HLN 1997 — t(T-1)'\n",
    "            ]\n",
    "        }).to_excel(writer, sheet_name='0_Metodologia', index=False)\n",
    "\n",
    "        # Hoja 1: P-valores  (n_grupos × n_pares)\n",
    "        detail_df[group_keys + pval_cols].to_excel(\n",
    "            writer, sheet_name='1_PValores', index=False)\n",
    "\n",
    "        # Hoja 2: Estadísticos DM\n",
    "        detail_df[group_keys + dm_cols].to_excel(\n",
    "            writer, sheet_name='2_DM_Stats', index=False)\n",
    "\n",
    "        # Hoja 3: Significancia (SÍ/NO)\n",
    "        detail_df[group_keys + sig_cols].to_excel(\n",
    "            writer, sheet_name='3_Significancia_SiNo', index=False)\n",
    "\n",
    "        # Hoja 4: Medias A y B\n",
    "        detail_df[group_keys + mA_cols + mB_cols].to_excel(\n",
    "            writer, sheet_name='4_Medias_A_B', index=False)\n",
    "\n",
    "        # Hoja 5: A<B (SÍ/NO)\n",
    "        detail_df[group_keys + ab_cols].to_excel(\n",
    "            writer, sheet_name='5_A_menor_B', index=False)\n",
    "\n",
    "        # Hoja 6: Tabla completa\n",
    "        detail_df.to_excel(writer, sheet_name='6_Tabla_Completa', index=False)\n",
    "\n",
    "        # Hoja 7: Matriz % Significancia\n",
    "        sig_df.to_excel(writer, sheet_name='7_Matriz_Pct_Significancia')\n",
    "\n",
    "        # Hoja 8: Matriz % F<C\n",
    "        mean_df.to_excel(writer, sheet_name='8_Matriz_Pct_FilaMenusCol')\n",
    "\n",
    "        # Hoja 9: Resumen por modelo\n",
    "        resumen = []\n",
    "        for m in model_cols:\n",
    "            i = model_cols.index(m)\n",
    "            off_diag_sig  = [sig_pct_mat[i,j]  for j in range(n_mod) if j != i and not np.isnan(sig_pct_mat[i,j])]\n",
    "            off_diag_mean = [mean_pct_mat[i,j] for j in range(n_mod) if j != i and not np.isnan(mean_pct_mat[i,j])]\n",
    "            resumen.append({\n",
    "                'Modelo'                    : m,\n",
    "                'ECRPS_promedio'            : round(data[m].mean(), 6),\n",
    "                'Sig_promedio_%'            : round(np.mean(off_diag_sig),  2),\n",
    "                'F<C_promedio_%'            : round(np.mean(off_diag_mean), 2),\n",
    "                'F<C_mediana_%'             : round(np.median(off_diag_mean), 2),\n",
    "            })\n",
    "        pd.DataFrame(resumen).sort_values('ECRPS_promedio').to_excel(\n",
    "            writer, sheet_name='9_Resumen_por_Modelo', index=False)\n",
    "\n",
    "    print(f\"  ✓ Excel guardado    → {excel_path.name}\")\n",
    "    print(f\"    Hoja 1: {n_groups} filas × {n_pairs} pares (p-valores)\")\n",
    "    print(f\"    Hojas 7-8: matrices {n_mod}×{n_mod}\")\n",
    "\n",
    "    return detail_df, sig_df, mean_df\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# EJECUTAR PARA TODOS LOS ESCENARIOS\n",
    "# ------------------------------------------------------------------ #\n",
    "for suf in ['', '.a', '.b', '.c']:\n",
    "    run_dm_analysis(suf)\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"  PROCESO COMPLETADO\")\n",
    "print(\"=\"*65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891694e2",
   "metadata": {},
   "source": [
    "# Revisión uso DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06b6b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATOS SIMULADOS (primeras 12 filas)\n",
      "================================================================================\n",
      "    Config       Dist  Var  Paso  Modelo_A  Modelo_B\n",
      "0        1     Normal  0.5     1  0.424836  0.493087\n",
      "1        1     Normal  0.5     2  0.432384  0.576151\n",
      "2        1     Normal  0.5     3  0.388292  0.488293\n",
      "3        1     Normal  1.0     1  0.478961  0.538372\n",
      "4        1     Normal  1.0     2  0.376526  0.527128\n",
      "5        1     Normal  1.0     3  0.376829  0.476714\n",
      "6        1  T-Student  0.5     1  0.412098  0.404336\n",
      "7        1  T-Student  0.5     2  0.313754  0.471886\n",
      "8        1  T-Student  0.5     3  0.349358  0.515712\n",
      "9        1  T-Student  1.0     1  0.354599  0.429385\n",
      "10       1  T-Student  1.0     2  0.473282  0.488711\n",
      "11       1  T-Student  1.0     3  0.403376  0.428763\n",
      "\n",
      "Total observaciones: 24\n",
      "\n",
      "================================================================================\n",
      "ENFOQUE 1: TEST D-M GLOBAL (COMO ESTÁ EN TU CÓDIGO)\n",
      "================================================================================\n",
      "\n",
      "Diferencias individuales (primeras 12):\n",
      "[-0.06825108 -0.14376707 -0.10000082 -0.0594111  -0.15060172 -0.0998844\n",
      "  0.00776213 -0.15813152 -0.16635392 -0.07478602 -0.01542875 -0.02538618]\n",
      "\n",
      "Media de diferencias: -0.0035\n",
      "Desv. Std de diferencias: 0.1792\n",
      "\n",
      "Estadístico D-M: -0.0951\n",
      "P-valor: 0.9242\n",
      "Conclusión: No hay diferencia significativa\n",
      "\n",
      "================================================================================\n",
      "ENFOQUE 2: TESTS D-M ESTRATIFICADOS POR CONDICIÓN\n",
      "================================================================================\n",
      "\n",
      "Tests por Config:\n",
      "  Config 1: media_dif=-0.0879, DM=-5.1703, p=0.0000\n",
      "  Config 2: media_dif=0.0809, DM=1.2773, p=0.2015\n",
      "\n",
      "Tests por Varianza:\n",
      "  Var 0.5: media_dif=-0.1077, DM=-5.7022, p=0.0000\n",
      "  Var 1.0: media_dif=0.1008, DM=1.7646, p=0.0776\n",
      "\n",
      "Tests por Config × Var (combinación crítica):\n",
      "  Config=1, Var=0.5: media_dif=-0.1048, DM=-3.8539, p=0.0001\n",
      "  Config=1, Var=1.0: media_dif=-0.0709, DM=-3.4758, p=0.0005\n",
      "  Config=2, Var=0.5: media_dif=-0.1107, DM=-3.8467, p=0.0001\n",
      "  Config=2, Var=1.0: media_dif=0.2725, DM=5.8855, p=0.0000\n",
      "\n",
      "================================================================================\n",
      "ENFOQUE 3: ANOVA MULTIFACTORIAL SOBRE DIFERENCIAS\n",
      "================================================================================\n",
      "\n",
      "Efecto de Config:\n",
      "  F=6.6223, p=0.0173\n",
      "\n",
      "Efecto de Var:\n",
      "  F=12.0147, p=0.0022\n",
      "\n",
      "Efecto de Dist:\n",
      "  F=0.0195, p=0.8902\n",
      "\n",
      "Efecto de interacción Config × Var:\n",
      "  F=33.1020, p=0.0000\n",
      "\n",
      "================================================================================\n",
      "RESUMEN: MEDIAS DE DIFERENCIAS POR CONDICIÓN\n",
      "================================================================================\n",
      "\n",
      "Tabla: Diferencia promedio (Modelo_A - Modelo_B)\n",
      "Dist        Normal  T-Student\n",
      "Config Var                   \n",
      "1      0.5 -0.1040    -0.1056\n",
      "       1.0 -0.1033    -0.0385\n",
      "2      0.5 -0.1415    -0.0798\n",
      "       1.0  0.3140     0.2309\n",
      "\n",
      "Interpretación:\n",
      "  - Valores negativos: Modelo A mejor (menor ECRPS)\n",
      "  - Valores positivos: Modelo B mejor\n",
      "  - Nota: Config=2 + Var=1.0 tiene diferencias positivas (A peor que B)\n",
      "\n",
      "================================================================================\n",
      "CONCLUSIONES COMPARATIVAS\n",
      "================================================================================\n",
      "\n",
      "1. TEST D-M GLOBAL (tu código actual):\n",
      "   → Conclusión: Modelo A peor que B en promedio\n",
      "   → Problema: NO detecta que en Config=2+Var=1.0 la situación se invierte\n",
      "\n",
      "2. TESTS D-M ESTRATIFICADOS:\n",
      "   → Conclusión: La superioridad de A depende de las condiciones\n",
      "   → Ventaja: Identifica dónde cada modelo es mejor\n",
      "   → Problema: Múltiples tests, ajuste de Bonferroni muy conservador\n",
      "\n",
      "3. ANOVA SOBRE DIFERENCIAS:\n",
      "   → Conclusión: Hay efectos significativos de Config, Var, y su interacción\n",
      "   → Ventaja: Cuantifica qué factores afectan las diferencias\n",
      "   → Limitación: No hace comparación pairwise directa entre modelos\n",
      "\n",
      "================================================================================\n",
      "RECOMENDACIÓN PARA TU ANÁLISIS\n",
      "================================================================================\n",
      "\n",
      "Deberías combinar los tres enfoques:\n",
      "\n",
      "1. Test D-M global → Responde: \"¿Quién es mejor en general?\"\n",
      "2. Tests D-M por escenario → Responde: \"¿Esa conclusión se mantiene en todos los escenarios?\"\n",
      "3. ANOVA sobre diferencias → Responde: \"¿Qué factores explican las diferencias?\"\n",
      "\n",
      "Esto te da una historia completa:\n",
      "- Modelo A es mejor en promedio (D-M global)\n",
      "- PERO esa ventaja desaparece cuando Config=2 y Var=1.0 (D-M estratificado)\n",
      "- Los factores Config y Var tienen efectos significativos (ANOVA)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# ============================================================================\n",
    "# SIMULACIÓN DE DATOS SIMPLIFICADA\n",
    "# ============================================================================\n",
    "# Supongamos solo 2 modelos, 2 configs, 2 distribuciones, 2 varianzas, 3 pasos\n",
    "# Total: 2×2×2×3 = 24 observaciones por modelo\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "configs = [1, 2]\n",
    "dists = ['Normal', 'T-Student']\n",
    "vars_val = [0.5, 1.0]\n",
    "pasos = [1, 2, 3]\n",
    "\n",
    "data = []\n",
    "for config in configs:\n",
    "    for dist in dists:\n",
    "        for var in vars_val:\n",
    "            for paso in pasos:\n",
    "                # Modelo A: mejor en general, pero peor con Config=2 + Var=1.0\n",
    "                if config == 2 and var == 1.0:\n",
    "                    ecrps_A = np.random.normal(0.8, 0.1)  # Peor\n",
    "                else:\n",
    "                    ecrps_A = np.random.normal(0.4, 0.05)  # Mejor\n",
    "                \n",
    "                # Modelo B: más estable, rendimiento medio\n",
    "                ecrps_B = np.random.normal(0.5, 0.05)\n",
    "                \n",
    "                data.append({\n",
    "                    'Config': config,\n",
    "                    'Dist': dist,\n",
    "                    'Var': var,\n",
    "                    'Paso': paso,\n",
    "                    'Modelo_A': ecrps_A,\n",
    "                    'Modelo_B': ecrps_B\n",
    "                })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"=\"*80)\n",
    "print(\"DATOS SIMULADOS (primeras 12 filas)\")\n",
    "print(\"=\"*80)\n",
    "print(df.head(12))\n",
    "print(f\"\\nTotal observaciones: {len(df)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ENFOQUE ACTUAL: UN SOLO TEST D-M CON TODAS LAS OBSERVACIONES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENFOQUE 1: TEST D-M GLOBAL (COMO ESTÁ EN TU CÓDIGO)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "errors_A = df['Modelo_A'].values\n",
    "errors_B = df['Modelo_B'].values\n",
    "diferencias = errors_A - errors_B\n",
    "\n",
    "print(f\"\\nDiferencias individuales (primeras 12):\")\n",
    "print(diferencias[:12])\n",
    "print(f\"\\nMedia de diferencias: {np.mean(diferencias):.4f}\")\n",
    "print(f\"Desv. Std de diferencias: {np.std(diferencias, ddof=1):.4f}\")\n",
    "\n",
    "# Test D-M simple\n",
    "d_bar = np.mean(diferencias)\n",
    "T = len(diferencias)\n",
    "se = np.std(diferencias, ddof=1) / np.sqrt(T)\n",
    "dm_stat = d_bar / se\n",
    "p_value_dm = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "\n",
    "print(f\"\\nEstadístico D-M: {dm_stat:.4f}\")\n",
    "print(f\"P-valor: {p_value_dm:.4f}\")\n",
    "print(f\"Conclusión: {'Modelo A significativamente diferente de B' if p_value_dm < 0.05 else 'No hay diferencia significativa'}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ENFOQUE ALTERNATIVO 1: TESTS D-M ESTRATIFICADOS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENFOQUE 2: TESTS D-M ESTRATIFICADOS POR CONDICIÓN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTests por Config:\")\n",
    "for config in configs:\n",
    "    subset = df[df['Config'] == config]\n",
    "    dif = subset['Modelo_A'].values - subset['Modelo_B'].values\n",
    "    d_bar = np.mean(dif)\n",
    "    se = np.std(dif, ddof=1) / np.sqrt(len(dif))\n",
    "    dm_stat = d_bar / se\n",
    "    p_val = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "    print(f\"  Config {config}: media_dif={d_bar:.4f}, DM={dm_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "print(\"\\nTests por Varianza:\")\n",
    "for var in vars_val:\n",
    "    subset = df[df['Var'] == var]\n",
    "    dif = subset['Modelo_A'].values - subset['Modelo_B'].values\n",
    "    d_bar = np.mean(dif)\n",
    "    se = np.std(dif, ddof=1) / np.sqrt(len(dif))\n",
    "    dm_stat = d_bar / se\n",
    "    p_val = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "    print(f\"  Var {var}: media_dif={d_bar:.4f}, DM={dm_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "print(\"\\nTests por Config × Var (combinación crítica):\")\n",
    "for config in configs:\n",
    "    for var in vars_val:\n",
    "        subset = df[(df['Config'] == config) & (df['Var'] == var)]\n",
    "        dif = subset['Modelo_A'].values - subset['Modelo_B'].values\n",
    "        d_bar = np.mean(dif)\n",
    "        se = np.std(dif, ddof=1) / np.sqrt(len(dif))\n",
    "        dm_stat = d_bar / se if se > 0 else 0\n",
    "        p_val = 2 * (1 - stats.norm.cdf(abs(dm_stat))) if se > 0 else 1.0\n",
    "        print(f\"  Config={config}, Var={var}: media_dif={d_bar:.4f}, DM={dm_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ENFOQUE ALTERNATIVO 2: ANOVA SOBRE LAS DIFERENCIAS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENFOQUE 3: ANOVA MULTIFACTORIAL SOBRE DIFERENCIAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df['Diferencia'] = df['Modelo_A'] - df['Modelo_B']\n",
    "\n",
    "# ANOVA de efectos principales\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "print(\"\\nEfecto de Config:\")\n",
    "grupos_config = [df[df['Config'] == c]['Diferencia'].values for c in configs]\n",
    "F_stat, p_val = f_oneway(*grupos_config)\n",
    "print(f\"  F={F_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "print(\"\\nEfecto de Var:\")\n",
    "grupos_var = [df[df['Var'] == v]['Diferencia'].values for v in vars_val]\n",
    "F_stat, p_val = f_oneway(*grupos_var)\n",
    "print(f\"  F={F_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "print(\"\\nEfecto de Dist:\")\n",
    "grupos_dist = [df[df['Dist'] == d]['Diferencia'].values for d in dists]\n",
    "F_stat, p_val = f_oneway(*grupos_dist)\n",
    "print(f\"  F={F_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "# Interacción Config × Var\n",
    "print(\"\\nEfecto de interacción Config × Var:\")\n",
    "grupos_interaccion = []\n",
    "for config in configs:\n",
    "    for var in vars_val:\n",
    "        subset = df[(df['Config'] == config) & (df['Var'] == var)]\n",
    "        grupos_interaccion.append(subset['Diferencia'].values)\n",
    "F_stat, p_val = f_oneway(*grupos_interaccion)\n",
    "print(f\"  F={F_stat:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# RESUMEN VISUAL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN: MEDIAS DE DIFERENCIAS POR CONDICIÓN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "pivot = df.pivot_table(values='Diferencia', \n",
    "                       index=['Config', 'Var'], \n",
    "                       columns='Dist', \n",
    "                       aggfunc='mean')\n",
    "print(\"\\nTabla: Diferencia promedio (Modelo_A - Modelo_B)\")\n",
    "print(pivot.round(4))\n",
    "print(\"\\nInterpretación:\")\n",
    "print(\"  - Valores negativos: Modelo A mejor (menor ECRPS)\")\n",
    "print(\"  - Valores positivos: Modelo B mejor\")\n",
    "print(\"  - Nota: Config=2 + Var=1.0 tiene diferencias positivas (A peor que B)\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONCLUSIÓN COMPARATIVA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSIONES COMPARATIVAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. TEST D-M GLOBAL (tu código actual):\")\n",
    "print(f\"   → Conclusión: Modelo A {'mejor' if d_bar < 0 else 'peor'} que B en promedio\")\n",
    "print(f\"   → Problema: NO detecta que en Config=2+Var=1.0 la situación se invierte\")\n",
    "\n",
    "print(\"\\n2. TESTS D-M ESTRATIFICADOS:\")\n",
    "print(\"   → Conclusión: La superioridad de A depende de las condiciones\")\n",
    "print(\"   → Ventaja: Identifica dónde cada modelo es mejor\")\n",
    "print(\"   → Problema: Múltiples tests, ajuste de Bonferroni muy conservador\")\n",
    "\n",
    "print(\"\\n3. ANOVA SOBRE DIFERENCIAS:\")\n",
    "print(\"   → Conclusión: Hay efectos significativos de Config, Var, y su interacción\")\n",
    "print(\"   → Ventaja: Cuantifica qué factores afectan las diferencias\")\n",
    "print(\"   → Limitación: No hace comparación pairwise directa entre modelos\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMENDACIÓN PARA TU ANÁLISIS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Deberías combinar los tres enfoques:\n",
    "\n",
    "1. Test D-M global → Responde: \"¿Quién es mejor en general?\"\n",
    "2. Tests D-M por escenario → Responde: \"¿Esa conclusión se mantiene en todos los escenarios?\"\n",
    "3. ANOVA sobre diferencias → Responde: \"¿Qué factores explican las diferencias?\"\n",
    "\n",
    "Esto te da una historia completa:\n",
    "- Modelo A es mejor en promedio (D-M global)\n",
    "- PERO esa ventaja desaparece cuando Config=2 y Var=1.0 (D-M estratificado)\n",
    "- Los factores Config y Var tienen efectos significativos (ANOVA)\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
